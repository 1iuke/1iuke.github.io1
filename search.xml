<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>Hello World</title>
    <url>/2021/03/13/hello-world/</url>
    <content><![CDATA[<p>Welcome to <a href="https://hexo.io/">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p>
<h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo new <span class="string">&quot;My New Post&quot;</span></span><br></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/writing.html">Writing</a></p>
<h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/server.html">Server</a></p>
<h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/generating.html">Generating</a></p>
<h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/one-command-deployment.html">Deployment</a></p>
]]></content>
  </entry>
  <entry>
    <title></title>
    <url>/2021/03/13/%E6%8C%87%E9%92%88/</url>
    <content><![CDATA[<ol>
<li><p>*号标识该变量为指针类型，当定义多个指针变量时，在每个指针变量名前面均需要加一个 *，不能省略，否则为非指针变量。</p>
</li>
<li><p>在使用已定义好的指针变量时，在变量名前面不能加 *。</p>
</li>
</ol>
]]></content>
  </entry>
  <entry>
    <title></title>
    <url>/2021/03/13/tf/</url>
    <content><![CDATA[<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">!jupyter nbconvert lesson07.ipynb --to slides --post serve</span><br></pre></td></tr></table></figure>

<h2 id="模型保存"><a href="#模型保存" class="headerlink" title="模型保存"></a>模型保存</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">network.save(<span class="string">&#x27;model.h5&#x27;</span>)</span><br><span class="line">print(<span class="string">&#x27;saved total model.&#x27;</span>)</span><br></pre></td></tr></table></figure>

<h2 id="权值保存"><a href="#权值保存" class="headerlink" title="权值保存"></a>权值保存</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">network.save_weights(<span class="string">&#x27;weights.ckpt&#x27;</span>)</span><br><span class="line">print(<span class="string">&#x27;saved weights.&#x27;</span>)</span><br></pre></td></tr></table></figure>

<h2 id="模型加载"><a href="#模型加载" class="headerlink" title="模型加载"></a>模型加载</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">network = tf.keras.models.load_model(<span class="string">&#x27;model.h5&#x27;</span>, <span class="built_in">compile</span>=<span class="literal">False</span>)</span><br><span class="line">print(<span class="string">&#x27;loaded model from file.&#x27;</span>)</span><br></pre></td></tr></table></figure>

<h2 id="权值加载"><a href="#权值加载" class="headerlink" title="权值加载"></a>权值加载</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">network.load_weights(<span class="string">&#x27;weights.ckpt&#x27;</span>)</span><br><span class="line">print(<span class="string">&#x27;loaded weights!&#x27;</span>)</span><br></pre></td></tr></table></figure>

<h2 id="TensorBoard"><a href="#TensorBoard" class="headerlink" title="TensorBoard"></a>TensorBoard</h2><h3 id="在Model-fit-中使用TensorBoard"><a href="#在Model-fit-中使用TensorBoard" class="headerlink" title="在Model.fit()中使用TensorBoard"></a>在Model.fit()中使用TensorBoard</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 定义日志目录，必须是启动web应用时指定目录的子目录，建议使用日期时间作为子目录名</span></span><br><span class="line">log_dir=<span class="string">&quot;logs/&quot;</span> + datetime.datetime.now().strftime(<span class="string">&quot;%Y%m%d-%H%M%S&quot;</span>)</span><br><span class="line"></span><br><span class="line">tensorboard_callback = tf.keras.callbacks.TensorBoard(</span><br><span class="line">    log_dir=<span class="string">&#x27;logs&#x27;</span>,</span><br><span class="line">    histogram_freq=<span class="number">1</span>, profile_batch=<span class="number">2</span>,</span><br><span class="line">    write_graph=<span class="literal">True</span>,write_images=<span class="literal">True</span>,</span><br><span class="line">    embeddings_freq=<span class="number">0</span>, embeddings_layer_names=<span class="literal">None</span>,</span><br><span class="line">    embeddings_metadata=<span class="literal">None</span>, embeddings_data=<span class="literal">None</span>, update_freq=<span class="number">500</span></span><br><span class="line">) <span class="comment"># 定义TensorBoard对象</span></span><br><span class="line"></span><br><span class="line">model.fit(x=x_train, </span><br><span class="line">          y=y_train, </span><br><span class="line">          epochs=<span class="number">5</span>, </span><br><span class="line">          validation_data=(x_test, y_test), </span><br><span class="line">          callbacks=[tensorboard_callback])  <span class="comment"># 将定义好的TensorBoard对象作为回调传给fit方法，这样就将TensorBoard嵌入了模型训练过程</span></span><br></pre></td></tr></table></figure>

<h3 id="在其他功能函数中嵌入TensorBoard"><a href="#在其他功能函数中嵌入TensorBoard" class="headerlink" title="在其他功能函数中嵌入TensorBoard"></a>在其他功能函数中嵌入TensorBoard</h3><h4 id="tf-summary的基本步骤"><a href="#tf-summary的基本步骤" class="headerlink" title="tf.summary的基本步骤"></a>tf.summary的基本步骤</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># （1）创建一个 SummaryWriter 对象，生成的日志将储存到 &quot;./mylogs&quot; 路径中</span></span><br><span class="line">writer = tf.summary.create_file_writer(<span class="string">&quot;./logs&quot;</span>)  <span class="comment">#</span></span><br><span class="line"><span class="comment"># （2）使用 writer_1 记录with包裹的context中，进行 summary 写入的操作</span></span><br><span class="line"><span class="keyword">with</span> writer.as_default():  </span><br><span class="line">    <span class="keyword">for</span> step <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">100</span>):    </span><br><span class="line">        <span class="comment"># other model code would go here    </span></span><br><span class="line">        <span class="comment"># （3）将scalar(&quot;loss&quot;, loss, step)写入 summary </span></span><br><span class="line">        tf.summary.scalar(<span class="string">&quot;loss&quot;</span>, loss, step=step)      </span><br><span class="line">        <span class="comment"># （4）强制 SummaryWriter 将缓存中的数据写入到日志</span></span><br><span class="line">        writer.flush()  </span><br></pre></td></tr></table></figure>

<h4 id="查看Graph和Profile信息"><a href="#查看Graph和Profile信息" class="headerlink" title="查看Graph和Profile信息"></a>查看Graph和Profile信息</h4><p>由于tensorflow2.0取消了sess和初始静态图，所以无法使用像1.x版本，直接将sess.graph添加进tensorboard，所以需要使用trace_on进行记录。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">writer = tf.summary.create_file_writer(log_dir)</span><br><span class="line">tf.summary.trace_on(graph=<span class="literal">True</span>, profiler=<span class="literal">True</span>)  <span class="comment"># 开启Trace，可以记录图结构和profile信息</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">进行训练</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="comment"># 最后将统计信息写入日志</span></span><br><span class="line"><span class="keyword">with</span> writer.as_default():</span><br><span class="line">    tf.summary.trace_export(name=<span class="string">&quot;model_trace&quot;</span>, step=<span class="number">0</span>, profiler_outdir=log_dir)    <span class="comment"># 保存Trace信息到文件</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>

]]></content>
  </entry>
  <entry>
    <title></title>
    <url>/2021/03/13/%E5%9F%BA%E4%BA%8E%E8%84%91%E7%94%B5%E7%9A%84%E8%84%91%E6%9C%BA%E6%8E%A5%E5%8F%A3%E8%BF%81%E7%A7%BB%E5%AD%A6%E4%B9%A0%EF%BC%9A2016%E5%B9%B4%E4%BB%A5%E6%9D%A5%E7%A0%94%E7%A9%B6%E8%BF%9B%E5%B1%95%E7%BB%BC%E8%BF%B0/</url>
    <content><![CDATA[<p>原文：Transfer Learning for EEG-Based Brain-Computer Interfaces: A Review of Progress Made Since 2016 <link> <a href="https://arxiv.org/abs/2004.06286v4">https://arxiv.org/abs/2004.06286v4</a> </link></p>
<p><strong>脑机接口</strong>(BCI)使用户能够使用大脑信号直接与计算机通信。</p>
<p><strong>脑电</strong>(EEG)是最常见的非侵入性脑机接口(BCI)，对噪声/伪影敏感，且存在受试者/受试者内部的非平稳性。很难建立一个通用的模式识别模型。</p>
<p><strong>迁移学习</strong>用于减少校准工作量。</p>
<p>本文讨论了<strong>运动想象</strong>、<strong>事件相关电位</strong>、<strong>稳态视觉诱发电位</strong>、<strong>情感脑机接口</strong>、<strong>回归问题</strong>和<strong>对抗性攻击</strong>等六种范式及其应用。</p>
<p>索引-<strong>脑机接口</strong>、<strong>脑电图</strong>、<strong>迁移学习</strong>、<strong>领域适应</strong>、<strong>情感脑机接口</strong>、<strong>对抗性攻击</strong></p>
<h2 id="I-Introduction"><a href="#I-Introduction" class="headerlink" title="I.Introduction"></a>I.Introduction</h2><p>脑机接口应用：游戏、情绪识别、精神疲劳评估、警觉评估。etc</p>
<p>BCI类型：<strong>Non-invasive BCIs</strong>；Invasive BCIs；Partially invasive (semi-invasive) BCIs</p>
<p>本文研究非侵入式BCIs，safety, low cost, and convenience. most popular</p>
<p><img src="%E5%9F%BA%E4%BA%8E%E8%84%91%E7%94%B5%E7%9A%84%E8%84%91%E6%9C%BA%E6%8E%A5%E5%8F%A3%E8%BF%81%E7%A7%BB%E5%AD%A6%E4%B9%A0%EF%BC%9A2016%E5%B9%B4%E4%BB%A5%E6%9D%A5%E7%A0%94%E7%A9%B6%E8%BF%9B%E5%B1%95%E7%BB%BC%E8%BF%B0.assets/image-20210215113147980.png" alt="image-20210215113147980"></p>
<ol>
<li><p>Signal acquisition ： Used：wired connections and gel 。Currently, wireless connections and dry electrodes </p>
</li>
<li><p>Signal processing ： temporal filtering and spatial filtering.</p>
</li>
</ol>
<p>常用的空间滤波器包括公共空间模式(CSP)、独立分量分析(ICA)、盲源分离、xDAWN等。</p>
<p>3）Feature extraction：时域、频域、时频域、黎曼空间和/或功能性大脑连通性特征</p>
<ol start="4">
<li><p>Pattern recognition：分类；回归</p>
</li>
<li><p>Controller：其输出命令以控制外部设备</p>
</li>
</ol>
<p>当使用深度学习时，特征提取和模式识别可以集成到单个神经网络中，并且这两个组件同时自动优化。</p>
<p>基于EEG的BCI中有三种经典的分类范型：Motor imagery (MI)；Event-related potentials (ERP)；Steady-state visual evoked potentials (SSVEP)</p>
<h2 id="II-迁移学习概念和场景"><a href="#II-迁移学习概念和场景" class="headerlink" title="II.迁移学习概念和场景"></a>II.迁移学习概念和场景</h2><p>定义1：</p>
<h2 id="III-TL-in-MI-Based-BCIs"><a href="#III-TL-in-MI-Based-BCIs" class="headerlink" title="III.TL in MI-Based BCIs"></a>III.TL in MI-Based BCIs</h2><p><strong>嵌入流形的知识转移</strong>(MEKT)方法:1.协方差矩阵质心对齐(CA)2.切线空间特征提取。3.映射矩阵识别。</p>
<p><strong>EEGNet</strong>。它可以应用于不同的脑机接口范例，用非常有限的数据进行训练，并产生神经生理学上可解释的特征。EEGNet在错误信息系统和事件相关事件的学科内和跨学科分类方面都取得了强劲的成果。</p>
<h2 id="IV-TL-IN-ERP-BASED-BCIs"><a href="#IV-TL-IN-ERP-BASED-BCIs" class="headerlink" title="IV. TL IN ERP-BASED BCIs"></a>IV. TL IN ERP-BASED BCIs</h2><p>SAN  GAN</p>
<p>数据对齐：<strong>Euclidean Alignment (EA)方法</strong>，完全无监督，运算代价低，适用于传统机器学习和深度学习</p>
]]></content>
  </entry>
</search>
