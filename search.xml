<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>基于典型相关分析方法的在线多通道SSVEP脑机接口</title>
    <url>/2021/03/15/3.%E5%9F%BA%E4%BA%8E%E5%85%B8%E5%9E%8B%E7%9B%B8%E5%85%B3%E5%88%86%E6%9E%90%E6%96%B9%E6%B3%95%E7%9A%84%E5%9C%A8%E7%BA%BF%E5%A4%9A%E9%80%9A%E9%81%93SSVEP%E8%84%91%E6%9C%BA%E6%8E%A5%E5%8F%A3/</url>
    <content><![CDATA[<h2 id="summary">0. Summary</h2>
<p>写完笔记之后最后填，概述文章的内容，以后查阅笔记的时候先看这一段。注：写文章summary切记需要通过自己的思考，用自己的语言描述。忌讳直接Ctrl + c原文。</p>
<h2 id="research-objectives">1. Research Objective(s)</h2>
<p>作者的研究目标是什么？</p>
<p>本文提出了一种在线多信道SSVEP BCI系统，采用典型相关分析（CCA）方法提取与SSVEP相关的频率信息。利用离线数据对系统的关键参数信道位置、窗长和谐波数进行了研究，为在线系统的设计提供了依据。</p>
<h2 id="background-problem-statement">2. Background / Problem Statement</h2>
<p>研究的背景以及问题陈述：作者需要解决的问题是什么？</p>
<ul>
<li>不同的SSVEP可以通过将我们的兴趣或注意力转移到其中一个频率编码的刺激上而产生</li>
<li>SSVEP的BCI有更高的信噪比（SNR）和信息传输率（ITR）</li>
</ul>
<h2 id="methods">3. Method(s)</h2>
<p>作者解决问题的方法/算法是什么？是否基于前人的方法？基于了哪些？</p>
<ul>
<li>MEC(minium energy method) 检测精度高, 无需校准数据</li>
<li><a href="./典型相关分析(CCA).md">CCA</a></li>
</ul>
<h2 id="evaluation">4. Evaluation</h2>
<p>作者如何评估自己的方法？实验的setup是什么样的？感兴趣实验数据和结果有哪些？有没有问题或者可以借鉴的地方？</p>
<h2 id="conclusion">5. Conclusion</h2>
<p>作者给出了哪些结论？哪些是strong conclusions, 哪些又是weak的conclusions（即作者并没有通过实验提供evidence，只在discussion中提到；或实验的数据并没有给出充分的evidence）?</p>
<ul>
<li>结果:来自30个BCI命令的正确计数的平均值为28.6。 BCI系统的平均ITR为58±9.6位min-1。</li>
</ul>
<h2 id="notes">6. Notes</h2>
<p>(optional) 不在以上列表中，但需要特别记录的笔记。</p>
<h2 id="references">References</h2>
<p>(optional) 列出相关性高的文献，以便之后可以继续track下去。</p>
]]></content>
      <categories>
        <category>论文</category>
      </categories>
      <tags>
        <tag>SSVEP</tag>
      </tags>
  </entry>
  <entry>
    <title>基于编码调制VEP的高速BCI</title>
    <url>/2021/03/15/2.%E5%9F%BA%E4%BA%8E%E7%BC%96%E7%A0%81%E8%B0%83%E5%88%B6VEP%E7%9A%84%E9%AB%98%E9%80%9FBCI/</url>
    <content><![CDATA[<h2 id="summary">0. Summary</h2>
<p>写完笔记之后最后填，概述文章的内容，以后查阅笔记的时候先看这一段。注：写文章summary切记需要通过自己的思考，用自己的语言描述。忌讳直接Ctrl + c原文。</p>
<p>通过编码调制与多通道处理提高ITR</p>
<h2 id="research-objectives">1. Research Objective(s)</h2>
<p>作者的研究目标是什么？</p>
<p>提高ITR</p>
<h2 id="background-problem-statement">2. Background / Problem Statement</h2>
<p>研究的背景以及问题陈述：作者需要解决的问题是什么？</p>
<p>BCI 通信系统传输速率低，提高ITR(信息传输率)</p>
<h2 id="methods">3. Method(s)</h2>
<p>作者解决问题的方法/算法是什么？是否基于前人的方法？基于了哪些？</p>
<ul>
<li><p>提出了基于c-VEP的调制系统，其中二进制伪随机码被用来调制不同的视觉刺激</p></li>
<li><p>提出了一种提高识别精度的多通道检测方法</p></li>
</ul>
<h2 id="evaluation">4. Evaluation</h2>
<p>作者如何评估自己的方法？实验的setup是什么样的？感兴趣实验数据和结果有哪些？有没有问题或者可以借鉴的地方？</p>
<figure>
<img src="/2021/03/15/2.%E5%9F%BA%E4%BA%8E%E7%BC%96%E7%A0%81%E8%B0%83%E5%88%B6VEP%E7%9A%84%E9%AB%98%E9%80%9FBCI/image-20210311110254896.png" alt="image-20210311110254896"><figcaption aria-hidden="true">image-20210311110254896</figcaption>
</figure>
<ol type="1">
<li>该系统由一个脑电图放大器和一台带CRT显示器的个人电脑（PC）组成。</li>
<li>不同目标的反应之间的圆移关系是目标识别的基础，一旦获得了T0的模板，其他目标的模板可以很容易地获得<img src="/2021/03/15/2.%E5%9F%BA%E4%BA%8E%E7%BC%96%E7%A0%81%E8%B0%83%E5%88%B6VEP%E7%9A%84%E9%AB%98%E9%80%9FBCI/image-20210311110915610-1615775581553.png" title="园移 Principle of equivalent neighbors" alt="image-20210311110915610"></li>
<li>在获得所有目标的模板后，可以采用模板匹配的方法进行目标识别，通过选择相关系数最大的目标来确定固定目标</li>
<li>多通道处理，由于双极通道。实验分为训练阶段和测试阶段。在训练阶段，要求被试者固定在参考目标上约200个刺激周期。训练阶段的数据用于离线分析，以计算空间滤波权重和在线使用的参考模板.在测试阶段，每个受试者被要求输入一个64个字符的序列。 在测试阶段，每个受试者都被要求输入64个字符序列，在线准确率和相应的ITR用于评估系统性能。 在计算ITR时，每次选择的时间成本为2.1s(包括两个刺激期，一个用于数据采集，一个用于目标识别、反馈展示和凝视)。</li>
</ol>
<h2 id="conclusion">5. Conclusion</h2>
<p>作者给出了哪些结论？哪些是strong conclusions, 哪些又是weak的conclusions（即作者并没有通过实验提供evidence，只在discussion中提到；或实验的数据并没有给出充分的evidence）?</p>
<p>本文对高速c-VEP BCI系统的基本原理和实现方法进行了详细的介绍,提出的c-VEP BCI具有108±12.0比特/分钟-1的高ITR,超过了以往基于脑电图的BCI的记录。</p>
<h2 id="notes">6. Notes</h2>
<p>(optional) 不在以上列表中，但需要特别记录的笔记。</p>
<h2 id="references">References</h2>
<p>(optional) 列出相关性高的文献，以便之后可以继续track下去。</p>
]]></content>
      <categories>
        <category>论文</category>
      </categories>
      <tags>
        <tag>VEP</tag>
      </tags>
  </entry>
  <entry>
    <title>基于EEG脑-机接口的黎曼几何；入门和综述</title>
    <url>/2021/03/15/1.%E5%9F%BA%E4%BA%8EEEG%E8%84%91-%E6%9C%BA%E6%8E%A5%E5%8F%A3%E7%9A%84%E9%BB%8E%E6%9B%BC%E5%87%A0%E4%BD%95%EF%BC%9B%E5%85%A5%E9%97%A8%E5%92%8C%E7%BB%BC%E8%BF%B0/</url>
    <content><![CDATA[<h2 id="summary">0. Summary</h2>
<p>写完笔记之后最后填，概述文章的内容，以后查阅笔记的时候先看这一段。注：写文章summary切记需要通过自己的思考，用自己的语言描述。忌讳直接Ctrl + c原文。</p>
<hr>
<p>黎曼几何在脑机接口的应用，简述了黎曼分类的原理，优缺点。</p>
<h2 id="research-objectives">1. Research Objective(s)</h2>
<p>作者的研究目标是什么？</p>
<hr>
<p>比较黎曼几何与</p>
<h2 id="background-problem-statement">2. Background / Problem Statement</h2>
<p>研究的背景以及问题陈述：作者需要解决的问题是什么？</p>
<hr>
<p>国际预测建模BCI数据竞赛中获得的优胜分数，引起关注</p>
<p>黎曼几何的优点：simplicity,accuracy,robustness,transfer learning capabilities</p>
<p>新一代BCI解码器的要求:</p>
<ol type="1">
<li>accuracy</li>
<li>reliable</li>
<li>initialized with generic parameters</li>
<li>quick learning</li>
<li>universal</li>
<li>algorithmically simple</li>
<li>computationally efficient</li>
<li>multi-user</li>
</ol>
<p>基于</p>
<h2 id="methods">3. Method(s)</h2>
<p>作者解决问题的方法/算法是什么？是否基于前人的方法？基于了哪些？</p>
<hr>
<p>传统解码器：预处理，特征提取，分类</p>
<p>模式：MI，ERP，SSEP</p>
<p>目前都有专门的预处理，信号处理和分类模块</p>
<table>
<thead>
<tr class="header">
<th>两大范式</th>
<th>优点</th>
<th>缺点</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>hard machine learning</td>
<td>泛化性能好</td>
<td>需要大量数据，计算密集型</td>
</tr>
<tr class="even">
<td>利用信号处理提高信噪比，然后分类（空间滤波等）</td>
<td>快速训练，成本低</td>
<td>泛化差</td>
</tr>
</tbody>
</table>
<p>黎曼分类：</p>
<p>MDM(Minimum Distance to Mean)：到平均数的最小距离</p>
<h2 id="evaluation">4. Evaluation</h2>
<p>作者如何评估自己的方法？实验的setup是什么样的？感兴趣实验数据和结果有哪些？有没有问题或者可以借鉴的地方？</p>
<figure>
<img src="/2021/03/15/1.%E5%9F%BA%E4%BA%8EEEG%E8%84%91-%E6%9C%BA%E6%8E%A5%E5%8F%A3%E7%9A%84%E9%BB%8E%E6%9B%BC%E5%87%A0%E4%BD%95%EF%BC%9B%E5%85%A5%E9%97%A8%E5%92%8C%E7%BB%BC%E8%BF%B0/image-20210311103033549.png" title="算术均值与几何均值比较" alt="image-20210311103033549"><figcaption aria-hidden="true">image-20210311103033549</figcaption>
</figure>
<figure>
<img src="/2021/03/15/1.%E5%9F%BA%E4%BA%8EEEG%E8%84%91-%E6%9C%BA%E6%8E%A5%E5%8F%A3%E7%9A%84%E9%BB%8E%E6%9B%BC%E5%87%A0%E4%BD%95%EF%BC%9B%E5%85%A5%E9%97%A8%E5%92%8C%E7%BB%BC%E8%BF%B0/image-20210311103013598.png" title="黎曼MDM分类与传统CSP分类的迁移学习比较" alt="image-20210311103013598"><figcaption aria-hidden="true">image-20210311103013598</figcaption>
</figure>
<p>LDA 线性判别分析</p>
<h2 id="conclusion">5. Conclusion</h2>
<p>作者给出了哪些结论？哪些是strong conclusions, 哪些又是weak的conclusions（即作者并没有通过实验提供evidence，只在discussion中提到；或实验的数据并没有给出充分的evidence）?</p>
<hr>
<ol type="1">
<li>提供了一个更简单的黎曼分类方法，</li>
<li>最小距离到平均数（MDM）的初步介绍，我们主要依靠直观的（几何）解释。Riemannian MDM方法完全基于两个简单的概念：两个数据点之间的距离和其中若干点的平均值。</li>
<li>黎曼几何学提供了处理对称正定矩阵的天然框架，许多种类的结构协方差矩阵都是这种类型。不管协方差矩阵是如何定义的，MDM黎曼分类器对于所有三种BCI模式，即运动想象、事件相关电位和稳态诱发电位都是一样的。</li>
<li>基于切线空间映射的黎曼方法的总体性能优于MDM方法，而且性能明显优于最新的技术水平，但由于分类器继承了算法复杂度的增加和可能需要高强度的学习，它们不太适合在线操作</li>
<li>空间滤波器的改进只能为分类目的带来适度的改进，而且这种改进并不容易转化为可靠性和鲁棒性的显著提高。</li>
</ol>
<h2 id="notes">6. Notes</h2>
<p>(optional) 不在以上列表中，但需要特别记录的笔记。</p>
<hr>
<p>附录1中给出了三种主要BCI模式的正式定义。 这些定义还可以改进，并期待对这一课题的进一步研究。</p>
<h2 id="references">References</h2>
<p>(optional) 列出相关性高的文献，以便之后可以继续track下去。</p>
]]></content>
      <categories>
        <category>论文</category>
      </categories>
      <tags>
        <tag>黎曼几何</tag>
      </tags>
  </entry>
  <entry>
    <title>Tensorflow 模型保存</title>
    <url>/2021/03/13/Tensorflow%20%E6%A8%A1%E5%9E%8B%E4%BF%9D%E5%AD%98/</url>
    <content><![CDATA[<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">!jupyter nbconvert lesson07.ipynb --to slides --post serve</span><br></pre></td></tr></table></figure>
<h2 id="模型保存">模型保存</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">network.save(<span class="string">&#x27;model.h5&#x27;</span>)</span><br><span class="line">print(<span class="string">&#x27;saved total model.&#x27;</span>)</span><br></pre></td></tr></table></figure>
<h2 id="权值保存">权值保存</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">network.save_weights(<span class="string">&#x27;weights.ckpt&#x27;</span>)</span><br><span class="line">print(<span class="string">&#x27;saved weights.&#x27;</span>)</span><br></pre></td></tr></table></figure>
<h2 id="模型加载">模型加载</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">network = tf.keras.models.load_model(<span class="string">&#x27;model.h5&#x27;</span>, <span class="built_in">compile</span>=<span class="literal">False</span>)</span><br><span class="line">print(<span class="string">&#x27;loaded model from file.&#x27;</span>)</span><br></pre></td></tr></table></figure>
<h2 id="权值加载">权值加载</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">network.load_weights(<span class="string">&#x27;weights.ckpt&#x27;</span>)</span><br><span class="line">print(<span class="string">&#x27;loaded weights!&#x27;</span>)</span><br></pre></td></tr></table></figure>
<h2 id="tensorboard">TensorBoard</h2>
<h3 id="在model.fit中使用tensorboard">在Model.fit()中使用TensorBoard</h3>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 定义日志目录，必须是启动web应用时指定目录的子目录，建议使用日期时间作为子目录名</span></span><br><span class="line">log_dir=<span class="string">&quot;logs/&quot;</span> + datetime.datetime.now().strftime(<span class="string">&quot;%Y%m%d-%H%M%S&quot;</span>)</span><br><span class="line"></span><br><span class="line">tensorboard_callback = tf.keras.callbacks.TensorBoard(</span><br><span class="line">    log_dir=<span class="string">&#x27;logs&#x27;</span>,</span><br><span class="line">    histogram_freq=<span class="number">1</span>, profile_batch=<span class="number">2</span>,</span><br><span class="line">    write_graph=<span class="literal">True</span>,write_images=<span class="literal">True</span>,</span><br><span class="line">    embeddings_freq=<span class="number">0</span>, embeddings_layer_names=<span class="literal">None</span>,</span><br><span class="line">    embeddings_metadata=<span class="literal">None</span>, embeddings_data=<span class="literal">None</span>, update_freq=<span class="number">500</span></span><br><span class="line">) <span class="comment"># 定义TensorBoard对象</span></span><br><span class="line"></span><br><span class="line">model.fit(x=x_train, </span><br><span class="line">          y=y_train, </span><br><span class="line">          epochs=<span class="number">5</span>, </span><br><span class="line">          validation_data=(x_test, y_test), </span><br><span class="line">          callbacks=[tensorboard_callback])  <span class="comment"># 将定义好的TensorBoard对象作为回调传给fit方法，这样就将TensorBoard嵌入了模型训练过程</span></span><br></pre></td></tr></table></figure>
<h3 id="在其他功能函数中嵌入tensorboard">在其他功能函数中嵌入TensorBoard</h3>
<h4 id="tf.summary的基本步骤">tf.summary的基本步骤</h4>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># （1）创建一个 SummaryWriter 对象，生成的日志将储存到 &quot;./mylogs&quot; 路径中</span></span><br><span class="line">writer = tf.summary.create_file_writer(<span class="string">&quot;./logs&quot;</span>)  <span class="comment">#</span></span><br><span class="line"><span class="comment"># （2）使用 writer_1 记录with包裹的context中，进行 summary 写入的操作</span></span><br><span class="line"><span class="keyword">with</span> writer.as_default():  </span><br><span class="line">    <span class="keyword">for</span> step <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">100</span>):    </span><br><span class="line">        <span class="comment"># other model code would go here    </span></span><br><span class="line">        <span class="comment"># （3）将scalar(&quot;loss&quot;, loss, step)写入 summary </span></span><br><span class="line">        tf.summary.scalar(<span class="string">&quot;loss&quot;</span>, loss, step=step)      </span><br><span class="line">        <span class="comment"># （4）强制 SummaryWriter 将缓存中的数据写入到日志</span></span><br><span class="line">        writer.flush()  </span><br></pre></td></tr></table></figure>
<h4 id="查看graph和profile信息">查看Graph和Profile信息</h4>
<p>由于tensorflow2.0取消了sess和初始静态图，所以无法使用像1.x版本，直接将sess.graph添加进tensorboard，所以需要使用trace_on进行记录。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">writer = tf.summary.create_file_writer(log_dir)</span><br><span class="line">tf.summary.trace_on(graph=<span class="literal">True</span>, profiler=<span class="literal">True</span>)  <span class="comment"># 开启Trace，可以记录图结构和profile信息</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">进行训练</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="comment"># 最后将统计信息写入日志</span></span><br><span class="line"><span class="keyword">with</span> writer.as_default():</span><br><span class="line">    tf.summary.trace_export(name=<span class="string">&quot;model_trace&quot;</span>, step=<span class="number">0</span>, profiler_outdir=log_dir)    <span class="comment"># 保存Trace信息到文件</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>tensorflow</tag>
      </tags>
  </entry>
  <entry>
    <title>基于黎曼几何的新一代脑机接口</title>
    <url>/2021/03/15/4.%E5%9F%BA%E4%BA%8E%E9%BB%8E%E6%9B%BC%E5%87%A0%E4%BD%95%E7%9A%84%E6%96%B0%E4%B8%80%E4%BB%A3%E8%84%91%E6%9C%BA%E6%8E%A5%E5%8F%A3/</url>
    <content><![CDATA[<h2 id="summary">0. Summary</h2>
<p>写完笔记之后最后填，概述文章的内容，以后查阅笔记的时候先看这一段。注：写文章summary切记需要通过自己的思考，用自己的语言描述。忌讳直接Ctrl + c原文。</p>
<h2 id="research-objectives">1. Research Objective(s)</h2>
<p>作者的研究目标是什么？</p>
<h2 id="background-problem-statement">2. Background / Problem Statement</h2>
<p>研究的背景以及问题陈述：作者需要解决的问题是什么？</p>
<h2 id="methods">3. Method(s)</h2>
<p>作者解决问题的方法/算法是什么？是否基于前人的方法？基于了哪些？</p>
<h2 id="evaluation">4. Evaluation</h2>
<p>作者如何评估自己的方法？实验的setup是什么样的？感兴趣实验数据和结果有哪些？有没有问题或者可以借鉴的地方？</p>
<h2 id="conclusion">5. Conclusion</h2>
<p>作者给出了哪些结论？哪些是strong conclusions, 哪些又是weak的conclusions（即作者并没有通过实验提供evidence，只在discussion中提到；或实验的数据并没有给出充分的evidence）?</p>
<h2 id="notes">6. Notes</h2>
<p>(optional) 不在以上列表中，但需要特别记录的笔记。</p>
<h2 id="references">References</h2>
<p>(optional) 列出相关性高的文献，以便之后可以继续track下去。</p>
]]></content>
      <categories>
        <category>论文</category>
      </categories>
      <tags>
        <tag>黎曼几何</tag>
      </tags>
  </entry>
  <entry>
    <title>典型相关分析</title>
    <url>/2021/03/14/%E5%85%B8%E5%9E%8B%E7%9B%B8%E5%85%B3%E5%88%86%E6%9E%90(CCA)/</url>
    <content><![CDATA[<p>典型相关分析(Canonical Correction Analysis)是最常用的数据挖掘关联算法之一。</p>
<p>比如我们拿到两组数据，第一组是人身高和体重的数据，第二组是对应的跑步能力和跳远能力的数据。那么我们能不能说这两组数据是相关的呢？CCA可以帮助我们分析这个问题。</p>
<h2 id="cca概述">1.CCA概述</h2>
<p>在数理统计里面，假设有两组一维的数据集X和Y，则==相关系数==ρ的定义为: <span class="math display">\[
\rho(X,Y) = \frac{cov(X,Y)}{\sqrt{D(X)}\sqrt{D(Y)}}
\]</span> ​ 其中<span class="math inline">\(cov(X,Y)\)</span> 是X，Y的协方差，<span class="math inline">\(D(X),D(Y)\)</span> 分别为<span class="math inline">\(X,Y\)</span> 的方差。相关系数<span class="math inline">\(\rho\)</span> 的取值为[-1,1]。<span class="math inline">\(\rho\)</span>的绝对值越接近于1，则<span class="math inline">\(X,Y\)</span>的线性相关性越高。越接近于0，则<span class="math inline">\(X,Y\)</span>的线性相关性越低。</p>
<p>​ 虽然相关系数可以很好的帮我们分析一维数据的相关性，但是对于高维数据就不能直接使用了。拿上面我们提到的，如果X是包括人身高和体重两个维度的数据，而Y是包括跑步能力和跳远能力两个维度的数据，就不能直接使用相关系数的方法。那我们能不能变通一下呢？CCA给了我们变通的方法。</p>
<p>​ CCA使用的方法是将多维的<span class="math inline">\(X,Y\)</span>都用<strong>线性变换</strong>为1维的<span class="math inline">\(X&#39;,Y&#39;\)</span>，然后再使用相关系数来看<span class="math inline">\(X&#39;,Y&#39;\)</span>'的相关性。将数据从多维变到一维，也可以理解为CCA是在进行<strong>降维</strong>，将高维数据降到一维，然后再用相关系数进行相关性的分析。下面我们看看CCA的算法思想。</p>
<h2 id="cca的算法思想">2.CCA的算法思想</h2>
<p>​ 降维的标准是如何选择的呢？回想下主成分分析PCA，降维的原则是投影方差最大；再回想下线性判别分析LDA，降维的原则是同类的投影方差小，异类间的投影方差大。对于我们的CCA，它选择的投影标准是降维到1维后，两组数据的相关系数最大。</p>
<p>​ 假设我们的数据集是<span class="math inline">\(X,Y\)</span>，<span class="math inline">\(X\)</span>为<span class="math inline">\(n_1×m\)</span>的样本矩阵。<span class="math inline">\(Y\)</span>为<span class="math inline">\(n_2×m\)</span>的样本矩阵.其中<span class="math inline">\(m\)</span>为样本个数，而<span class="math inline">\(n1,n2\)</span>分别为<span class="math inline">\(X,Y\)</span>的特征维度。</p>
<p>​ 对于X矩阵，我们将其投影到1维，或者说进行线性表示，对应的投影向量或者说线性系数向量为a, 对于Y矩阵，我们将其投影到1维，或者说进行线性表示，对应的投影向量或者说线性系数向量为b, 这样X ,Y投影后得到的一维向量分别为X',Y'。我们有 <span class="math display">\[
X&#39; = a^TX, Y&#39;=b^TY
\]</span></p>
<p>​ 我们CCA的优化目标是最大化<span class="math display">\[ρ(X′,Y′)\]</span>得到对应的投影向量<span class="math inline">\(a,b\)</span>，即 <span class="math display">\[
\underbrace{arg\;max}_{a,b}\frac{cov(X&#39;,Y&#39;)}{\sqrt{D(X&#39;)}\sqrt{D(Y&#39;)}}
\]</span> 　　在投影前，我们一般会把原始数据进行==标准化==，得到均值为0而方差为1的数据<span class="math inline">\(X,Y\)</span>。这样我们有： <span class="math display">\[
cov(X&#39;,Y&#39;) = cov(a^TX, b^TY) = E(&lt;a^TX, b^TY&gt;) = E((a^TX)(b^TY)^T) = a^TE(XY^T)b
\]</span></p>
<p><span class="math display">\[
D(X&#39;) = D(a^TX) = a^TE(XX^T)a
\]</span></p>
<p><span class="math display">\[
D(Y&#39;) = D(b^TY) = b^TE(YY^T)b
\]</span></p>
<p>​ 由于我们的<span class="math display">\[X，Y\]</span>的均值均为0，则 <span class="math display">\[
D(X) = cov(X,X) = E(XX^T), D(Y)= cov(Y,Y) = E(YY^T)
\]</span></p>
<p><span class="math display">\[
cov(X,Y) = E(XY^T),  cov(Y,X) = E(YX^T)
\]</span></p>
<p>​ 令<span class="math inline">\(cov(X,Y)=S_{XY}\)</span>,则优化目标可以转化为: <span class="math display">\[
\underbrace{arg\;max}_{a,b}\frac{a^TS_{XY}b}{\sqrt{ a^TS_{XX}a}\sqrt{b^TS_{YY}b}}
\]</span> 　　由于分子分母增大相同的倍数，优化目标结果不变，我们可以采用和==SVM==类似的优化方法，固定分母，优化分子，具体的转化为： <span class="math display">\[
\underbrace{arg\;max}_{a,b}\;\;{a^TS_{XY}b} \\ s.t. a^TS_{XX}a =1,\; b^TS_{YY}b =1
\]</span> ​ 也就是说，我们的CCA算法的目标最终转化为一个==凸优化==过程，只要我们求出了这个优化目标的最大值，就是我们前面提到的多维X和Y的相关性度量，而对应的<span class="math inline">\(a,b\)</span>则为降维时的投影向量，或者说线性系数。</p>
<p>　　　　这个函数优化一般有两种方法，第一种是奇异值分解==SVD==，第二种是==特征分解==，两者得到的结果一样，下面我们分别讲解。</p>
<h2 id="cca算法的svd求解">3.CCA算法的SVD求解</h2>
<p>​ 首先，令<span class="math inline">\(a=S_{XX}^{-1/2}u, b=S_{YY}^{-1/2}v\)</span> ,则有： <span class="math display">\[
a^TS_{XX}a =1 \Rightarrow u^TS_{XX}^{-1/2}S_{XX}S_{XX}^{-1/2}u =1  \Rightarrow  u^Tu=1
\]</span></p>
<p><span class="math display">\[
b^TS_{YY}b =1 \Rightarrow v^TS_{YY}^{-1/2}S_{YY}S_{YY}^{-1/2}v=1  \Rightarrow  v^Tv=1
\]</span></p>
<p><span class="math display">\[
a^TS_{XY}b = u^TS_{XX}^{-1/2}S_{XY}S_{YY}^{-1/2}v
\]</span></p>
<p>​ 也就是说，我们的优化目标变成下式： <span class="math display">\[
\underbrace{arg\;max}_{u,v}u^TS_{XX}^{-1/2}S_{XY}S_{YY}^{-1/2}v\\
s.t. u^Tu =1,\; v^Tv =1
\]</span> ​ 将<span class="math inline">\(u,v\)</span>看作矩阵 <span class="math inline">\(M=S_{XX}^{-1/2}S_{XY}S_{YY}^{-1/2}\)</span> 的某一奇异值的左右奇异向量。得到<span class="math inline">\(M=U\Sigma V^T\)</span></p>
<p>那么利用奇异值分解，我们可以得到<span class="math inline">\(M=UΣV^T\)</span>其中<span class="math inline">\(U,V\)</span>分别为M的左奇异向量和右奇异向量组成的矩阵，而<span class="math display">\[Σ\]</span>为M的奇异值组成的对角矩阵。由于<span class="math display">\[U,V\]</span>所有的列都为标准正交基，则<span class="math display">\[u^TU\]</span>和<span class="math inline">\(V^Tv\)</span>得到一个只有一个标量值为1，其余标量值为0的向量。此时我们有 <span class="math display">\[
u^TS_{XX}^{-1/2}S_{XY}S_{YY}^{-1/2}v = u^TU\Sigma V^Tv = \sigma_{uv}
\]</span> ​ 也就是说我们最大化<span class="math inline">\(u^TS_{XX}^{-1/2}S_{XY}S_{YY}^{-1/2}v\)</span>,其实对应的最大值就是某一组左右奇异向量所对应的奇异值的最大值。也就是将M做了奇异值分解后，最大的奇异值就是我们优化目标的最大值，或者说我们的X和Y之间的最大相关系数。利用对应的左右奇异向量<span class="math inline">\(u,v\)</span>我们也可以求出我们原始的X和Y的线性系数<span class="math inline">\(a=S_{XX}^{-1/2}u, b=S_{YY}^{-1/2}v\)</span>。</p>
<p>　　　　可以看出，SVD的求解方式非常简洁方便。但是如果你不熟悉SVD的话，我们也可以用传统的拉格朗日函数加上特征分解来完成这个函数的优化。</p>
<h2 id="cca算法的特征分解求解">4.CCA算法的特征分解求解</h2>
<p>​ 利用拉格朗日函数，优化目标转化为最大化下式： <span class="math display">\[
J(a,b) = a^TS_{XY}b -\frac{\lambda}{2}(a^TS_{XX}a-1)-\frac{\theta}{2}(b^TS_{YY}b-1)
\]</span> ​ 分别对<span class="math inline">\(a,b\)</span>求导并令结果为0，我们得到： <span class="math display">\[
S_{XY}b-\lambda S_{XX}a=0\\
S_{YX}a-\theta S_{YY}b=0
\]</span> ​ 将上面第一个式子左乘<span class="math inline">\(a^T\)</span>,第二个式子左乘<span class="math inline">\(b^T\)</span>，并利用<span class="math inline">\(a^TS_{XX}a =1,\; b^TS_{YY}b =1\)</span>，我们得到 <span class="math display">\[
\lambda = \theta = a^TS_{XY}b
\]</span> ​ 也就是说我们的拉格朗日系数就是我们要优化的目标。我们继续将上面的(17)两个式子做整理，第一个式子左乘<span class="math inline">\(S_{XX}^{-1}\)</span>,第二个式子左乘<span class="math inline">\(S_{YY}^{-1}\)</span>，我们得到： <span class="math display">\[
S_{XX}^{-1}S_{XY}b=\lambda a\\
S_{YY}^{-1}S_{YX}a = \lambda b
\]</span> 由(19)得: <span class="math display">\[
S_{XX}^{-1}S_{XY}S_{YY}^{-1}S_{YX}a=\lambda^2a
\]</span> ​ 这个式子就是特征分解！要求最大的相关系数λλ,我们只需要对矩阵<span class="math inline">\(N=S_{XX}^{-1}S_{XY}S_{YY}^{-1}S_{YX}\)</span>做特征分解，找出最大的特征值取平方根即可，此时最大特征值对应的特征向量即为X的线性系数a。</p>
<p>同样： <span class="math display">\[
S_{YY}^{-1}S_{YX}S_{XX}^{-1}S_{XY}b=\lambda^2b
\]</span> ​ 对矩阵<span class="math inline">\(N’=S_{YY}^{-1}S_{YX}S_{XX}^{-1}S_{XY}\)</span>做特征分解，找出最大的特征值取平方根即可，此时最大特征值对应的特征向量即为Y的线性系数b。</p>
<p>​ 可以看出特征分解的方法要比SVD复杂，但是两者求得的结果其实是等价的，只要利用SVD和特征分解之间的关系就很容易发现两者最后的结果相同</p>
<h2 id="cca算法流程">5.CCA算法流程</h2>
<p>​ 以SVD方法为准。</p>
<p>　　　　输入：各为<span class="math inline">\(m\)</span>个的样本<span class="math inline">\(X\)</span>和<span class="math inline">\(Y\)</span>，<span class="math inline">\(X\)</span>和<span class="math inline">\(Y\)</span>的维度都大于1</p>
<p>　　　　输出：X,Y的相关系数<span class="math inline">\(ρ\)</span>,<span class="math inline">\(X\)</span>和<span class="math inline">\(Y\)</span>的线性系数向量<span class="math inline">\(a\)</span>和<span class="math inline">\(b\)</span></p>
<p>　　　　1）计算X的方差<span class="math inline">\(S_{XX}\)</span>, Y的方差<span class="math inline">\(S_{YY}\)</span>，X和Y的协方差<span class="math inline">\(S_{XY}\)</span>, <span class="math inline">\(Y\)</span>和<span class="math inline">\(X\)</span>的协方差<span class="math inline">\(S_{YX}=S_{XY}^T\)</span></p>
<p>　　　　2) 计算矩阵<span class="math inline">\(M=S_{XX}^{-1/2}S_{XY}S_{YY}^{-1/2}\)</span></p>
<p>　　　　3）对矩阵<span class="math inline">\(M\)</span>进行奇异值分解，得到最大的奇异值<span class="math inline">\(ρ\)</span>，和最大奇异值对应的左右奇异向量<span class="math inline">\(u,v\)</span></p>
<p>　　　　4) 计算X和Y的线性系数向量a和b, <span class="math inline">\(a=S_{XX}^{-1/2}u, b=S_{YY}^{-1/2}v\)</span></p>
<p>　　　　</p>
<h2 id="cca算法小结">6.CCA算法小结</h2>
<p>​ CCA算法广泛的应用于数据相关度的分析，同时还是偏最小二乘法的基础。但是由于它依赖于数据的线性表示，当我们的数据无法线性表示时，CCA就无法使用，此时我们可以利用核函数的思想，将数据映射到高维后，再利用CCA的思想降维到1维，求对应的相关系数和线性关系，这个算法一般称为KCCA。</p>
<p>　　此外，我们在算法里只找了相关度最大的奇异值或者特征值，作为数据的相关系数，实际上我们也可以像PCA一样找出第二大奇异值，第三大奇异值，。。。得到第二相关系数和第三相关系数。然后对数据做进一步的相关性分析。但是一般的应用来说，找出第一相关系数就可以了。</p>
<p>　　有时候我们的矩阵<span class="math inline">\(S_{XX},S_{YY}\)</span>不可逆，此时我们得不到对应的逆矩阵，一般遇到这种情况可以对<span class="math inline">\(S_{XX},S_{YY}\)</span>进行正则化，将<span class="math inline">\(S_{XX},S_{YY}\)</span>变化为<span class="math inline">\(S_{XX}+\gamma I,S_{YY}+\gamma I\)</span>,然后继续求逆。其中<span class="math inline">\(γ\)</span>为正则化系数。</p>
]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>降维</tag>
      </tags>
  </entry>
  <entry>
    <title>论文&lt;基于脑电的脑机接口迁移学习&gt;</title>
    <url>/2021/03/13/%E5%9F%BA%E4%BA%8E%E8%84%91%E7%94%B5%E7%9A%84%E8%84%91%E6%9C%BA%E6%8E%A5%E5%8F%A3%E8%BF%81%E7%A7%BB%E5%AD%A6%E4%B9%A0%EF%BC%9A2016%E5%B9%B4%E4%BB%A5%E6%9D%A5%E7%A0%94%E7%A9%B6%E8%BF%9B%E5%B1%95%E7%BB%BC%E8%BF%B0/</url>
    <content><![CDATA[<p>原文：Transfer Learning for EEG-Based Brain-Computer Interfaces: A Review of Progress Made Since 2016 <link> https://arxiv.org/abs/2004.06286v4 </p>
<p><strong>脑机接口</strong>(BCI)使用户能够使用大脑信号直接与计算机通信。</p>
<p><strong>脑电</strong>(EEG)是最常见的非侵入性脑机接口(BCI)，对噪声/伪影敏感，且存在受试者/受试者内部的非平稳性。很难建立一个通用的模式识别模型。</p>
<p><strong>迁移学习</strong>用于减少校准工作量。</p>
<p>本文讨论了<strong>运动想象</strong>、<strong>事件相关电位</strong>、<strong>稳态视觉诱发电位</strong>、<strong>情感脑机接口</strong>、<strong>回归问题</strong>和<strong>对抗性攻击</strong>等六种范式及其应用。</p>
<p>索引-<strong>脑机接口</strong>、<strong>脑电图</strong>、<strong>迁移学习</strong>、<strong>领域适应</strong>、<strong>情感脑机接口</strong>、<strong>对抗性攻击</strong></p>
<h2 id="i.introduction">I.Introduction</h2>
<p>脑机接口应用：游戏、情绪识别、精神疲劳评估、警觉评估。etc</p>
<p>BCI类型：<strong>Non-invasive BCIs</strong>；Invasive BCIs；Partially invasive (semi-invasive) BCIs</p>
<p>本文研究非侵入式BCIs，safety, low cost, and convenience. most popular</p>
<p><img src="/2021/03/13/%E5%9F%BA%E4%BA%8E%E8%84%91%E7%94%B5%E7%9A%84%E8%84%91%E6%9C%BA%E6%8E%A5%E5%8F%A3%E8%BF%81%E7%A7%BB%E5%AD%A6%E4%B9%A0%EF%BC%9A2016%E5%B9%B4%E4%BB%A5%E6%9D%A5%E7%A0%94%E7%A9%B6%E8%BF%9B%E5%B1%95%E7%BB%BC%E8%BF%B0/image-20210215113147980.png"></p>
<ol type="1">
<li><p>Signal acquisition ： Used：wired connections and gel 。Currently, wireless connections and dry electrodes</p></li>
<li><p>Signal processing ： temporal filtering and spatial filtering.</p></li>
</ol>
<p>常用的空间滤波器包括公共空间模式(CSP)、独立分量分析(ICA)、盲源分离、xDAWN等。</p>
<p>3）Feature extraction：时域、频域、时频域、黎曼空间和/或功能性大脑连通性特征</p>
<ol start="4" type="1">
<li><p>Pattern recognition：分类；回归</p></li>
<li><p>Controller：其输出命令以控制外部设备</p></li>
</ol>
<p>当使用深度学习时，特征提取和模式识别可以集成到单个神经网络中，并且这两个组件同时自动优化。</p>
<p>基于EEG的BCI中有三种经典的分类范型：Motor imagery (MI)；Event-related potentials (ERP)；Steady-state visual evoked potentials (SSVEP)</p>
<h2 id="ii.迁移学习概念和场景">II.迁移学习概念和场景</h2>
<p>定义1：</p>
<h2 id="iii.tl-in-mi-based-bcis">III.TL in MI-Based BCIs</h2>
<p><strong>嵌入流形的知识转移</strong>(MEKT)方法:1.协方差矩阵质心对齐(CA)2.切线空间特征提取。3.映射矩阵识别。</p>
<p><strong>EEGNet</strong>。它可以应用于不同的脑机接口范例，用非常有限的数据进行训练，并产生神经生理学上可解释的特征。EEGNet在错误信息系统和事件相关事件的学科内和跨学科分类方面都取得了强劲的成果。</p>
<h2 id="iv.-tl-in-erp-based-bcis">IV. TL IN ERP-BASED BCIs</h2>
<p>SAN GAN</p>
<p>数据对齐：<strong>Euclidean Alignment (EA)方法</strong>，完全无监督，运算代价低，适用于传统机器学习和深度学习</p>
]]></content>
      <categories>
        <category>论文</category>
      </categories>
      <tags>
        <tag>脑电，迁移学习</tag>
      </tags>
  </entry>
  <entry>
    <title>卷积神经网络</title>
    <url>/2021/03/13/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/</url>
    <content><![CDATA[<hr>
<h1 id="卷积神经网络">卷积神经网络</h1>
]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>tensorflow</tag>
      </tags>
  </entry>
  <entry>
    <title>C指针</title>
    <url>/2021/03/13/%E6%8C%87%E9%92%88/</url>
    <content><![CDATA[<ol type="1">
<li><p><em>号标识该变量为指针类型，当定义多个指针变量时，在每个指针变量名前面均需要加一个 </em>，不能省略，否则为非指针变量。</p></li>
<li><p>在使用已定义好的指针变量时，在变量名前面不能加 *。</p></li>
</ol>
]]></content>
      <categories>
        <category>C/C++</category>
      </categories>
      <tags>
        <tag>指针</tag>
      </tags>
  </entry>
  <entry>
    <title>循环神经网络</title>
    <url>/2021/03/13/%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/</url>
    <content><![CDATA[
]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>tensorflow</tag>
      </tags>
  </entry>
  <entry>
    <title>概率论</title>
    <url>/2021/03/15/%E6%A6%82%E7%8E%87%E8%AE%BA/</url>
    <content><![CDATA[<h2 id="sum-rule">sum rule</h2>
<p><span class="math display">\[
p(X) = \sum_{Y}{}p(X,Y)
\]</span></p>
<h2 id="product-rule">product rule</h2>
<p><span class="math display">\[
p(X,Y) = p(Y|X)p(X)
\]</span></p>
<h2 id="对称性">对称性</h2>
<p><span class="math display">\[
p(X,Y) = p(Y,X)
\]</span> ## Bayes’ theorem</p>
<p><span class="math display">\[
p(Y|X) = \frac{p(X,Y)}{p(X)}\\
        =\frac{p(X|Y)p(X)}{p(X)}\\
        =\frac{p(X|Y)p(X)}{\sum_{Y}{}p(X,Y)}\\
        =\frac{p(X|Y)p(X)}{\sum_{Y}{}p(X|Y)p(Y)}
\]</span> 贝叶斯定理的分母<span class="math inline">\(p(X)=\sum_{Y}{}p(X|Y)p(Y)\)</span>看做归⼀化常数，⽤来确保公式（4）左侧的条件概率对于所有的Y 的取值之和为1。</p>
<hr>
<h2 id="概率密度probability-density">概率密度probability density</h2>
<p><img src="/2021/03/15/%E6%A6%82%E7%8E%87%E8%AE%BA/image-20210310210259698.png" alt="image-20210310210259698"> <span class="math display">\[
p(x\in(a,b)) = \int_{a}^{b}p(x) dx\\
p(x) \leq 0\\
\int_{-\infty}^{\infty}p(x)dx = 1
\]</span> ==概率密度–&gt;概率–&gt;累积分布==</p>
<p>考虑 变换<span class="math inline">\(x=g(y)\)</span> 区间<span class="math inline">\((x,x+\delta_x)\)</span> 变为 <span class="math inline">\((y,y+\delta_y)\)</span> 则有<span class="math inline">\(p_{x}{}(x) \delta_x \backsimeq p_{y}{}(y) \delta_y\)</span> <span class="math display">\[
p_y(y) = p_x(x)|\frac{dx}{dy}| = p_x(g(y))|g&#39;(y)|
\]</span> <strong>结论</strong>： 概率密度最⼤值的概念取决于变量的选择</p>
<h2 id="累积分布函数">累积分布函数</h2>
<p><span class="math display">\[
P(z) = \int_{-\infty}^{z} p(x)dx
\]</span> 满足 <span class="math inline">\(P&#39;(x)=p(x)\)</span></p>
<p>概率的<strong>加和规则</strong>和<strong>乘积规则</strong>以及<strong>贝叶斯规则</strong>，同样可以应⽤于<strong>概率密度函数</strong>的情形，也可以 应⽤于<strong>离散变量与连续变量相结合</strong>的情形</p>
<hr>
<h2 id="期望和协方差">期望和协方差</h2>
<p>期望：(加权平均值)</p>
<p>单变量</p>
<p>离散 <span class="math display">\[
E[f]=\sum_x p(x)f(x)
\]</span> 连续 <span class="math display">\[
E[f]=\int p(x)f(x) dx
\]</span> 估计 <span class="math display">\[
E[f]\backsimeq \frac{1}{N}\sum_{n=1}^{N}f(x_n)
\]</span></p>
<p>方差:度 量 了<span class="math inline">\(f(x)\)</span>在 均 值<span class="math inline">\(E[f(x)]\)</span>附 近 变 化 性 的 ⼤ ⼩ <span class="math display">\[
var[f] = E[(f(x)-E[f(x)])^2]\\
=E[f(x)^2]-E[f(x)]^2
\]</span> 协方差：(两个随机变量) <span class="math display">\[
cov[x,y]=E_{x,y}[ ( x-E[x])(y-E[y])] = E_{x,y}[xy]-E[x]E[y]
\]</span> ​ (两个随机向量) <span class="math display">\[
cov[x,y]=E_{x,y}[ ( x-E[x])(y^T-E[y^T])] = E_{x,y}[xy^T]-E[x]E[y^T]
\]</span></p>
<h2 id="贝叶斯概率">贝叶斯概率</h2>
<p>后验<span class="math inline">\(\backsimeq\)</span>似然x先验 <span class="math display">\[
p(w|D) = \frac{p(D|w)p(w)}{p(D)}
\]</span></p>
<p>后验概率$ p(w|D)$ 似然函数 <span class="math inline">\(p(D|w)\)</span> 先验概率<span class="math inline">\(p(w)\)</span> 归一化常数<span class="math inline">\(p(D)=\int p(D|w)p(w)dw\)</span></p>
<p>似然函数不是w的概率分布，并且它关于w的积分并不（⼀定）等于1.</p>
<h2 id="高斯分布">高斯分布</h2>
<figure>
<img src="/2021/03/15/%E6%A6%82%E7%8E%87%E8%AE%BA/image-20210311174121534.png" alt="image-20210311174121534"><figcaption aria-hidden="true">image-20210311174121534</figcaption>
</figure>
]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>概率论</tag>
      </tags>
  </entry>
  <entry>
    <title>线性表</title>
    <url>/2020/11/06/%E7%BA%BF%E6%80%A7%E8%A1%A8-1/</url>
    <content><![CDATA[<p>[toc]</p>
<h1 id="什么是线性表">1.什么是线性表</h1>
<p>把所有数据用一根线儿串起来，再存储到物理空间中</p>
<p>根据<strong>数据存储方式</strong>可分为</p>
<ul>
<li>顺序表</li>
<li>链表</li>
</ul>
<p><strong>前驱和后继</strong></p>
<figure>
<img src="/2020/11/06/%E7%BA%BF%E6%80%A7%E8%A1%A8-1/前驱和后继-1615645952176.gif" alt="前驱和后继"><figcaption aria-hidden="true">前驱和后继</figcaption>
</figure>
<h1 id="顺序表及初始化">2 顺序表及初始化</h1>
<p>数组<img src="/2020/11/06/%E7%BA%BF%E6%80%A7%E8%A1%A8-1/顺序表-1615645959375.gif" alt="顺序表"></p>
<p><strong>顺序表的初始化</strong></p>
<p>使用顺序表存储数据之前，除了要申请足够大小的物理空间之外，为了方便后期使用表中的数据，顺序表还需要实时记录以下 2 项数据：</p>
<ol type="1">
<li>顺序表申请的存储容量</li>
<li>顺序表的长度，元素个数</li>
</ol>
<p>自定义顺序表 代码</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span> <span class="title">Table</span>&#123;</span></span><br><span class="line">	<span class="keyword">int</span> *head;<span class="comment">//声明一个名为head的长度不确定的数组，动态数组</span></span><br><span class="line">	<span class="keyword">int</span> length;<span class="comment">//记录当前顺序表的长度</span></span><br><span class="line">	<span class="keyword">int</span> size;<span class="comment">//记录顺序表分配的存储容量</span></span><br><span class="line">&#125;table;</span><br></pre></td></tr></table></figure>
<p>接下来开始学习顺序表的初始化，也就是初步建立一个顺序表。建立顺序表需要做如下工作：</p>
<ul>
<li>给 head 动态数据申请足够大小的物理空间；</li>
<li>给 size 和 length 赋初值；</li>
</ul>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">define</span> Size 5<span class="comment">//申请空间大小</span></span></span><br><span class="line"><span class="function">table <span class="title">initTable</span><span class="params">()</span></span>&#123;</span><br><span class="line">    table t;</span><br><span class="line">    t.head=(<span class="keyword">int</span>*)<span class="built_in">malloc</span>(Size*<span class="keyword">sizeof</span>(<span class="keyword">int</span>));<span class="comment">//构造一个空的顺序表，动态申请存储空间</span></span><br><span class="line">    <span class="keyword">if</span>(!t.head)<span class="comment">//如果申请失败，退出程序&#123;</span></span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;初始化失败&quot;</span>)；</span><br><span class="line">        <span class="built_in">exit</span>(<span class="number">0</span>);</span><br><span class="line">	&#125;</span><br><span class="line">	t.length=<span class="number">0</span>;<span class="comment">//空表长度为0；</span></span><br><span class="line">	t.size=Size;<span class="comment">//空表的初始存储空间为Size</span></span><br><span class="line">	<span class="keyword">return</span> t;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>实例程序</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;stdlib.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> Size 5</span></span><br><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span> <span class="title">Table</span>&#123;</span></span><br><span class="line">    <span class="keyword">int</span> * head;</span><br><span class="line">    <span class="keyword">int</span> length;</span><br><span class="line">    <span class="keyword">int</span> size;</span><br><span class="line">&#125;table;</span><br><span class="line"><span class="function">table <span class="title">initTable</span><span class="params">()</span></span>&#123;</span><br><span class="line">    table t;</span><br><span class="line">    t.head=(<span class="keyword">int</span>*)<span class="built_in">malloc</span>(Size*<span class="keyword">sizeof</span>(<span class="keyword">int</span>));</span><br><span class="line">    <span class="keyword">if</span> (!t.head)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;初始化失败&quot;</span>);</span><br><span class="line">        <span class="built_in">exit</span>(<span class="number">0</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    t.length=<span class="number">0</span>;</span><br><span class="line">    t.size=Size;</span><br><span class="line">    <span class="keyword">return</span> t;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">//输出顺序表中元素的函数</span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">displayTable</span><span class="params">(table t)</span></span>&#123;</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i=<span class="number">0</span>;i&lt;t.length;i++) &#123;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;%d &quot;</span>,t.head[i]);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;\n&quot;</span>);</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span></span>&#123;</span><br><span class="line">    table t=initTable();</span><br><span class="line">    <span class="comment">//向顺序表中添加元素</span></span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i=<span class="number">1</span>; i&lt;=Size; i++) &#123;</span><br><span class="line">        t.head[i<span class="number">-1</span>]=i;</span><br><span class="line">        t.length++;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;顺序表中存储的元素分别是：\n&quot;</span>);</span><br><span class="line">    displayTable(t);</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><strong>输出：</strong></p>
<p>顺序表中存储的元素分别是： 1 2 3 4 5</p>
<h1 id="顺序表的基本操作">3.顺序表的基本操作</h1>
<h2 id="插入元素">3.1 插入元素</h2>
<p>根据插入位置不同：</p>
<ol type="1">
<li>插入表头</li>
<li>插入中间</li>
<li>插入表位</li>
</ol>
<p>解决方法：</p>
<ul>
<li>将要插入位置元素以及后续的元素整体向后移动一个位置；</li>
<li>将元素放到腾出来的位置上；</li>
</ul>
<p>例如：在{1 2 3 4 5}的第三个位置插入6</p>
<ul>
<li><img src="/2020/11/06/%E7%BA%BF%E6%80%A7%E8%A1%A8-1/找到目标元素位置-1615645975721.gif" title="fig:" alt="找到目标元素位置"></li>
<li><img src="/2020/11/06/%E7%BA%BF%E6%80%A7%E8%A1%A8-1/将插入位置腾出-1615645979073.gif" title="fig:" alt="将插入位置腾出"></li>
<li><img src="/2020/11/06/%E7%BA%BF%E6%80%A7%E8%A1%A8-1/插入目标元素-1604587218577-1615645980901.gif" title="fig:" alt="插入目标元素"></li>
</ul>
<p>代码</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="comment">//插入函数，其中，elem为插入的元素，add为插入到顺序表的位置</span></span><br><span class="line"><span class="function">table <span class="title">addTable</span><span class="params">(table t,<span class="keyword">int</span> elem,<span class="keyword">int</span> add)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="comment">//判断插入本身是否存在问题（如果插入元素位置比整张表的长度+1还大（如果相等，是尾随的情况），或者插入的位置本身不存在，程序作为提示并自动退出）</span></span><br><span class="line">    <span class="keyword">if</span> (add&gt;t.length+<span class="number">1</span>||add&lt;<span class="number">1</span>) &#123;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;插入位置有问题\n&quot;</span>);</span><br><span class="line">        <span class="keyword">return</span> t;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">//做插入操作时，首先需要看顺序表是否有多余的存储空间提供给插入的元素，如果没有，需要申请</span></span><br><span class="line">    <span class="keyword">if</span> (t.length==t.size) &#123;</span><br><span class="line">        t.head=(<span class="keyword">int</span> *)<span class="built_in">realloc</span>(t.head, (t.size+<span class="number">1</span>)*<span class="keyword">sizeof</span>(<span class="keyword">int</span>));</span><br><span class="line">        <span class="keyword">if</span> (!t.head) &#123;</span><br><span class="line">            <span class="built_in">printf</span>(<span class="string">&quot;存储分配失败\n&quot;</span>);</span><br><span class="line">            <span class="keyword">return</span> t;</span><br><span class="line">        &#125;</span><br><span class="line">        t.size+=<span class="number">1</span>;</span><br><span class="line">    &#125; </span><br><span class="line">    <span class="comment">//插入操作，需要将从插入位置开始的后续元素，逐个后移</span></span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i=t.length<span class="number">-1</span>; i&gt;=add<span class="number">-1</span>; i--) &#123;</span><br><span class="line">        t.head[i+<span class="number">1</span>]=t.head[i];</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">//后移完成后，直接将所需插入元素，添加到顺序表的相应位置</span></span><br><span class="line">    t.head[add<span class="number">-1</span>]=elem;</span><br><span class="line">    <span class="comment">//由于添加了元素，所以长度+1</span></span><br><span class="line">    t.length++;</span><br><span class="line">    <span class="keyword">return</span> t;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>注意，动态数组额外申请更多物理空间使用的是 realloc 函数。并且，在实现后续元素整体后移的过程，目标位置其实是有数据的，还是 3，只是下一步新插入元素时会把旧元素直接覆盖。</p>
<h2 id="删除元素">3.2 删除元素</h2>
<p>后续元素整体前移一个位置，会直接将目标元素删除，可间接实现删除元素的目的。</p>
<figure>
<img src="/2020/11/06/%E7%BA%BF%E6%80%A7%E8%A1%A8-1/后续元素前移-1615645985862.gif" alt="后续元素前移"><figcaption aria-hidden="true">后续元素前移</figcaption>
</figure>
<p>实现代码</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="function">table <span class="title">delTable</span><span class="params">(table t,<span class="keyword">int</span> add)</span></span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (add&gt;t.length || add&lt;<span class="number">1</span>) &#123;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;被删除元素的位置有误\n&quot;</span>);</span><br><span class="line">        <span class="keyword">return</span> t;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">//删除操作</span></span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i=add; i&lt;t.length; i++) &#123;</span><br><span class="line">        t.head[i<span class="number">-1</span>]=t.head[i];</span><br><span class="line">    &#125;</span><br><span class="line">    t.length--;</span><br><span class="line">    <span class="keyword">return</span> t;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="查找元素">3.3 查找元素</h2>
<p>顺序表中查找目标元素，可以使用多种查找算法实现，比如说<a href="http://c.biancheng.net/view/3428.html">二分查找算法</a>、插值查找算法等。</p>
<p>这里，我们选择<a href="http://c.biancheng.net/view/3427.html">顺序查找算法</a>，具体实现代码为：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="comment">//查找函数，其中，elem表示要查找的数据元素的值</span></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">selectTable</span><span class="params">(table t,<span class="keyword">int</span> elem)</span></span>&#123;</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i=<span class="number">0</span>; i&lt;t.length; i++) &#123;</span><br><span class="line">        <span class="keyword">if</span> (t.head[i]==elem) &#123;</span><br><span class="line">            <span class="keyword">return</span> i+<span class="number">1</span>;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">-1</span>;<span class="comment">//如果查找失败，返回-1</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="更改元素">3.4 更改元素</h2>
<p>顺序表更改元素的实现过程是：</p>
<ol type="1">
<li>找到目标元素；</li>
<li>直接修改该元素的值；</li>
</ol>
<p>顺序表更改元素的 C 语言实现代码为：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="comment">//更改函数，其中，elem为要更改的元素，newElem为新的数据元素</span></span><br><span class="line"><span class="function">table <span class="title">amendTable</span><span class="params">(table t,<span class="keyword">int</span> elem,<span class="keyword">int</span> newElem)</span></span>&#123;</span><br><span class="line">    <span class="keyword">int</span> add=selectTable(t, elem);</span><br><span class="line">    t.head[add<span class="number">-1</span>]=newElem;<span class="comment">//由于返回的是元素在顺序表中的位置，所以-1就是该元素在数组中的下标</span></span><br><span class="line">    <span class="keyword">return</span> t;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="实例">3.5 实例</h2>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;stdlib.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> Size 5</span></span><br><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span> <span class="title">Table</span>&#123;</span></span><br><span class="line">    <span class="keyword">int</span> * head;</span><br><span class="line">    <span class="keyword">int</span> length;</span><br><span class="line">    <span class="keyword">int</span> size;</span><br><span class="line">&#125;table;</span><br><span class="line"><span class="function">table <span class="title">initTable</span><span class="params">()</span></span>&#123;</span><br><span class="line">    table t;</span><br><span class="line">    t.head=(<span class="keyword">int</span>*)<span class="built_in">malloc</span>(Size*<span class="keyword">sizeof</span>(<span class="keyword">int</span>));</span><br><span class="line">    <span class="keyword">if</span> (!t.head)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;初始化失败\n&quot;</span>);</span><br><span class="line">        <span class="built_in">exit</span>(<span class="number">0</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    t.length=<span class="number">0</span>;</span><br><span class="line">    t.size=Size;</span><br><span class="line">    <span class="keyword">return</span> t;</span><br><span class="line">&#125;</span><br><span class="line"><span class="function">table <span class="title">addTable</span><span class="params">(table t,<span class="keyword">int</span> elem,<span class="keyword">int</span> add)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (add&gt;t.length+<span class="number">1</span>||add&lt;<span class="number">1</span>) &#123;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;插入位置有问题\n&quot;</span>);</span><br><span class="line">        <span class="keyword">return</span> t;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span> (t.length&gt;=t.size) &#123;</span><br><span class="line">        t.head=(<span class="keyword">int</span> *)<span class="built_in">realloc</span>(t.head, (t.size+<span class="number">1</span>)*<span class="keyword">sizeof</span>(<span class="keyword">int</span>));</span><br><span class="line">        <span class="keyword">if</span> (!t.head) &#123;</span><br><span class="line">            <span class="built_in">printf</span>(<span class="string">&quot;存储分配失败\n&quot;</span>);</span><br><span class="line">        &#125;</span><br><span class="line">        t.size+=<span class="number">1</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i=t.length<span class="number">-1</span>; i&gt;=add<span class="number">-1</span>; i--) &#123;</span><br><span class="line">        t.head[i+<span class="number">1</span>]=t.head[i];</span><br><span class="line">    &#125;</span><br><span class="line">    t.head[add<span class="number">-1</span>]=elem;</span><br><span class="line">    t.length++;</span><br><span class="line">    <span class="keyword">return</span> t;</span><br><span class="line">&#125;</span><br><span class="line"><span class="function">table <span class="title">delTable</span><span class="params">(table t,<span class="keyword">int</span> add)</span></span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (add&gt;t.length || add&lt;<span class="number">1</span>) &#123;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;被删除元素的位置有误\n&quot;</span>);</span><br><span class="line">        <span class="keyword">return</span> t;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i=add; i&lt;t.length; i++) &#123;</span><br><span class="line">        t.head[i<span class="number">-1</span>]=t.head[i];</span><br><span class="line">    &#125;</span><br><span class="line">    t.length--;</span><br><span class="line">    <span class="keyword">return</span> t;</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">selectTable</span><span class="params">(table t,<span class="keyword">int</span> elem)</span></span>&#123;</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i=<span class="number">0</span>; i&lt;t.length; i++) &#123;</span><br><span class="line">        <span class="keyword">if</span> (t.head[i]==elem) &#123;</span><br><span class="line">            <span class="keyword">return</span> i+<span class="number">1</span>;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">-1</span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="function">table <span class="title">amendTable</span><span class="params">(table t,<span class="keyword">int</span> elem,<span class="keyword">int</span> newElem)</span></span>&#123;</span><br><span class="line">    <span class="keyword">int</span> add=selectTable(t, elem);</span><br><span class="line">    t.head[add<span class="number">-1</span>]=newElem;</span><br><span class="line">    <span class="keyword">return</span> t;</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">displayTable</span><span class="params">(table t)</span></span>&#123;</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i=<span class="number">0</span>;i&lt;t.length;i++) &#123;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;%d &quot;</span>,t.head[i]);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;\n&quot;</span>);</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span></span>&#123;</span><br><span class="line">    table t1=initTable();</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i=<span class="number">1</span>; i&lt;=Size; i++) &#123;</span><br><span class="line">        t1.head[i<span class="number">-1</span>]=i;</span><br><span class="line">        t1.length++;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;原顺序表：\n&quot;</span>);</span><br><span class="line">    displayTable(t1);</span><br><span class="line">  </span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;删除元素1:\n&quot;</span>);</span><br><span class="line">    t1=delTable(t1, <span class="number">1</span>);</span><br><span class="line">    displayTable(t1);</span><br><span class="line">  </span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;在第2的位置插入元素5:\n&quot;</span>);</span><br><span class="line">    t1=addTable(t1, <span class="number">5</span>, <span class="number">2</span>);</span><br><span class="line">    displayTable(t1);</span><br><span class="line">  </span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;查找元素3的位置:\n&quot;</span>);</span><br><span class="line">    <span class="keyword">int</span> add=selectTable(t1, <span class="number">3</span>);</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;%d\n&quot;</span>,add);</span><br><span class="line">  </span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;将元素3改为6:\n&quot;</span>);</span><br><span class="line">    t1=amendTable(t1, <span class="number">3</span>, <span class="number">6</span>);</span><br><span class="line">    displayTable(t1);</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>运行结果：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">原顺序表：</span><br><span class="line">1 2 3 4 5</span><br><span class="line">删除元素1:</span><br><span class="line">2 3 4 5</span><br><span class="line">在第2的位置插入元素5:</span><br><span class="line">2 5 3 4 5</span><br><span class="line">查找元素3的位置:</span><br><span class="line">3</span><br><span class="line">将元素3改为6:</span><br><span class="line">2 5 6 4 5</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>数据结构</category>
      </categories>
      <tags>
        <tag>线性表</tag>
      </tags>
  </entry>
</search>
