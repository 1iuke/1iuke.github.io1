<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1"><title>边缘计算与深度学习的融合 | Mr.Liu</title><meta name="author" content="刘 可"><meta name="copyright" content="刘 可"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="科技论文写作作业：文献翻译">
<meta property="og:type" content="article">
<meta property="og:title" content="边缘计算与深度学习的融合">
<meta property="og:url" content="https://1iuke.github.io/2021/04/11/Paper/%E8%BE%B9%E7%BC%98%E8%AE%A1%E7%AE%97%E4%B8%8E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9A%84%E8%9E%8D%E5%90%88/index.html">
<meta property="og:site_name" content="Mr.Liu">
<meta property="og:description" content="科技论文写作作业：文献翻译">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://1iuke.github.io/img/002.jpg">
<meta property="article:published_time" content="2021-04-11T04:35:31.000Z">
<meta property="article:modified_time" content="2021-04-14T03:01:14.743Z">
<meta property="article:author" content="刘 可">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://1iuke.github.io/img/002.jpg"><link rel="shortcut icon" href="/img/avatar.gif"><link rel="canonical" href="https://1iuke.github.io/2021/04/11/Paper/%E8%BE%B9%E7%BC%98%E8%AE%A1%E7%AE%97%E4%B8%8E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9A%84%E8%9E%8D%E5%90%88/"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//hm.baidu.com"/><link rel="preconnect" href="//fonts.googleapis.com" crossorigin=""/><link rel="preconnect" href="//busuanzi.ibruce.info"/><meta name="google-site-verification" content="googlef811cf3092b9435a.html"/><meta name="baidu-site-verification" content="aaf92e4e610457deeceb4dbda4f59545"/><meta name="yandex-verification" content="{&quot;theme_color&quot;:{&quot;enable&quot;:true,&quot;main&quot;:&quot;#49B1F5&quot;,&quot;paginator&quot;:&quot;#00c4b6&quot;,&quot;button_hover&quot;:&quot;#FF7242&quot;,&quot;text_selection&quot;:&quot;#00c4b6&quot;,&quot;link_color&quot;:&quot;#99a9bf&quot;,&quot;meta_color&quot;:&quot;#858585&quot;,&quot;hr_color&quot;:&quot;#A4D8FA&quot;,&quot;code_foreground&quot;:&quot;#F47466&quot;,&quot;code_background&quot;:&quot;rgba(27, 31, 35, .05)&quot;,&quot;toc_color&quot;:&quot;#00c4b6&quot;,&quot;blockquote_padding_color&quot;:&quot;#49b1f5&quot;,&quot;blockquote_background_color&quot;:&quot;#49b1f5&quot;}}"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><script>var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?0ac6151ecf5087238476b9c52c29f00e";
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();
</script><link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Titillium+Web&amp;display=swap" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: {"path":"search.xml","languages":{"hits_empty":"找不到您查询的内容：${query}"}},
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: true,
    post: true
  },
  runtime: '',
  date_suffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: {"limitCount":50,"languages":{"author":"作者: 刘 可","link":"链接: ","source":"来源: Mr.Liu","info":"著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。"}},
  lightbox: 'null',
  Snackbar: undefined,
  source: {
    jQuery: 'https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js',
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/js/jquery.justifiedGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/css/justifiedGallery.min.css'
    },
    fancybox: {
      js: 'https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js',
      css: 'https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.css'
    }
  },
  isPhotoFigcaption: true,
  islazyload: true,
  isanchor: true
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = { 
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2021-04-14 11:01:14'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const fontSizeVal = saveToLocal.get('global-font-size')
    if (fontSizeVal !== undefined) {
      document.documentElement.style.setProperty('--global-font-size', fontSizeVal + 'px')
    }
    })(window)</script><link rel="stylesheet" href="/css/mycss.css"><link rel="stylesheet" href="/self/Kimbiedark.css"><meta name="generator" content="Hexo 5.4.0"><link rel="alternate" href="/atom.xml" title="Mr.Liu" type="application/atom+xml">
</head><body><div id="loading-box"><div class="loading-left-bg"></div><div class="loading-right-bg"></div><div class="spinner-box"><div class="configure-border-1"><div class="configure-core"></div></div><div class="configure-border-2"><div class="configure-core"></div></div><div class="loading-word">加载中...</div></div></div><div id="web_bg"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="author-avatar"><img class="avatar-img" data-lazy-src="/img/avatar.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="site-data"><div class="data-item is-center"><div class="data-item-link"><a href="/archives/"><div class="headline">文章</div><div class="length-num">33</div></a></div></div><div class="data-item is-center"><div class="data-item-link"><a href="/tags/"><div class="headline">标签</div><div class="length-num">22</div></a></div></div><div class="data-item is-center"><div class="data-item-link"><a href="/categories/"><div class="headline">分类</div><div class="length-num">8</div></a></div></div></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/messageboard"><i class="fa-fw fa-commenting-o"></i><span> 留言板</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('/img/002.jpg')"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">Mr.Liu</a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search"><i class="fas fa-search fa-fw"></i><span> 搜索</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/messageboard"><i class="fa-fw fa-commenting-o"></i><span> 留言板</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div><div id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">边缘计算与深度学习的融合</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2021-04-11T04:35:31.000Z" title="发表于 2021-04-11 12:35:31">2021-04-11</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2021-04-14T03:01:14.743Z" title="更新于 2021-04-14 11:01:14">2021-04-14</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E8%AE%BA%E6%96%87/">论文</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">字数总计:</span><span class="word-count">33.9k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">阅读时长:</span><span>102分钟</span></span><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="边缘计算与深度学习的融合"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><p>科技论文写作作业：文献翻译</p>
<span id="more"></span>
<p><strong>摘要</strong>-来自工厂和社区的无处不在的传感器和智能设备正在生成海量数据，不断增长的计算能力正在推动计算和服务的核心从云到网络的边缘。作为广泛改变人们生活的重要推动因素，从人脸识别到雄心勃勃的智能工厂和城市，基于人工智能(特别是深度学习，DL)的应用和服务的发展正在蓬勃发展。然而，由于效率和时延问题，当前的云计算服务架构阻碍了“随时随地为每个人、每个组织提供人工智能”的愿景。因此，利用数据源附近网络边缘的资源释放DL服务已成为一种理想的解决方案。因此，旨在通过边缘计算实现DL服务部署的边缘智能受到了广泛的关注。此外，DL作为人工智能的代表技术，可以集成到边缘计算框架中，构建智能边缘，实现动态、自适应的边缘维护和管理。对于互惠互利的边缘智能和智能边缘，本文进行了介绍和探讨：</p>
<p>1)两者的应用场景；2)实用的实现方法和使能技术，即定制边缘计算框架中的DL训练和推理；3)更加普适和细粒度智能的挑战和未来趋势。我们相信，通过整合分散在通信、网络和数字图书馆领域的信息，这项调查可以帮助读者了解使能技术之间的联系，同时促进关于边缘智能和智能边缘(即边缘数字图书馆)融合的进一步讨论。</p>
<p>索引术语-边缘计算、深度学习、无线通信、计算卸载、人工智能。</p>
<h1 id="一-导言">一 导言</h1>
<p>随着计算和存储设备的激增，从云数据中心(云)的服务器群集到个人计算机和智能手机，再到可穿戴设备和其他物联网(IoT)设备，我们现在正处于一个以信息为中心的时代，在这个时代，计算无处不在，计算服务从云向边缘溢出。根据思科白皮书[1]，到2020年，将有500亿台物联网设备连接到互联网。另一方面，思科估计，到2021年，云外每年将产生近850 ZB的数据，而全球数据中心流量仅为20.6 ZB[2]。这标志着大数据的数据源也在经历转型：从大规模的云数据中心向范围越来越广的边缘设备转变。然而，现有的云计算逐渐无法管理这些海量分布式计算能力并对其数据进行分析：1)大量的计算任务需要交付到云端进行处理[3]，这无疑对网络容量和云计算基础设施的计算能力构成了严峻的挑战；2)许多新型的应用，如协同自主驾驶，都有严格或严格的延迟要求，而这些要求是云计算很难满足的，因为它可能离用户很远[4]。</p>
<p>因此，边缘计算[5]、[6]成为一种有吸引力的替代方案，尤其是在尽可能靠近数据源和最终用户的情况下托管计算任务。当然，边缘计算和云计算并不是相互排斥的[7]、[8]。取而代之的是，边缘补充并延伸了云。与单纯云计算相比，边缘计算与云计算相结合的主要优势有三个方面：1)骨干网络缓解，分布式边缘计算节点无需与云交换相应数据，即可处理大量计算任务，减轻网络流量负荷；2)服务响应敏捷，边缘托管的服务可以显著降低数据传输时延，提高响应速度；3)强大的云备份能力，在边缘无法承受的情况下，云可以提供强大的处理能力和海量存储。</p>
<p>作为一种典型的、应用越来越广泛的新型应用形式[9]，各种基于深度学习的智能服务和应用改变了人们生活的方方面面，这得益于深度学习在计算机视觉(CV)和自然语言处理(NLP)领域的巨大优势[10]。这些成就不仅源于DL的发展，也与不断增长的数据和计算能力密不可分。然而，对于更广泛的应用场景，如智慧城市、车联网(IOVS)等，由于以下因素，提供的智能服务数量有限。</p>
<ul>
<li>成本：在云中训练和推断DL模型需要设备或用户将大量数据传输到云上，从而消耗大量网络带宽；</li>
<li>延迟：访问云服务的延迟一般不能得到保证，可能不足以满足协作自动驾驶等许多时间关键型应用的要求[11]；</li>
<li>可靠性：大多数云计算应用依赖无线通信和骨干网将用户连接到服务，但对于许多工业场景，即使在网络连接中断的情况下，智能服务也必须高度可靠；</li>
<li>隐私：DL所需的数据可能包含大量隐私信息，隐私问题对智能家居和城市等领域至关重要</li>
</ul>
<p>由于边缘比云更接近用户，边缘计算有望解决其中的许多问题。事实上，边缘计算正逐渐与人工智能(AI)相结合，在实现边缘智能和智能边缘方面互惠互利，如图1所示，边缘智能和智能边缘并不是相互独立的。边缘智能是目标，智能边缘中的DL服务也是边缘智能的一部分。反过来，智能边缘可以为边缘智能提供更高的服务吞吐量和资源利用率。</p>
<p><img src= "/img/loading.gif" data-lazy-src="/2021/04/11/Paper/%E8%BE%B9%E7%BC%98%E8%AE%A1%E7%AE%97%E4%B8%8E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9A%84%E8%9E%8D%E5%90%88/image-20210407123006452.png"></p>
<p>具体地说，一方面，边缘智能有望将DL计算从云端尽可能推向边缘，从而实现各种分布式、低时延、可靠的智能服务。如图2所示，优点包括：1)DL服务部署在请求用户附近，云只在需要额外处理时才参与[12]，从而显著降低了将数据发送到云进行处理的时延和成本；2)由于DL服务所需的原始数据本地存储在边缘或用户设备本身，而不是云上，因此增强了对用户隐私的保护；3)分层计算架构提供了更可靠的DL计算；2)由于DL服务所需的原始数据本地存储在边缘或用户设备本身而不是云上，因此增强了对用户隐私的保护；3)分层计算架构提供了更可靠的DL计算；4)凭借更丰富的数据和应用场景，边缘计算可以推动DL的普及应用，实现“随时随地为每个人、每个组织提供AI”的前景[13]；5)多样化、有价值的DL服务可以拓宽边缘计算的商业价值，加速其部署和增长。</p>
<p><img src= "/img/loading.gif" data-lazy-src="/2021/04/11/Paper/%E8%BE%B9%E7%BC%98%E8%AE%A1%E7%AE%97%E4%B8%8E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9A%84%E8%9E%8D%E5%90%88/image-20210407123019240.png"></p>
<p>另一方面，智能边缘的目标是将DL合并到边缘中，以实现动态、自适应的边缘维护和管理。随着通信技术的发展，网络接入方式越来越多样化。同时，边缘计算基础设施充当中间媒介，使无处不在的终端设备和云之间的连接更加可靠和持久[14]。因此，终端设备、边缘和云正逐渐融合为一个共享资源社区。然而，维护和管理如此庞大而复杂的整体架构(社区)，涉及无线通信、网络、计算、存储等，是一个重大挑战[15]。典型的网络优化方法依赖于固定的数学模型，但是很难对快速变化的边缘网络环境和系统进行精确建模。DL有望解决这个问题：当面对复杂繁琐的网络信息时，DL可以依靠其强大的学习和推理能力，从数据中提取有价值的信息并做出自适应决策，从而实现智能维护和管理。</p>
<p>因此，考虑到边缘智能和智能边缘，即Edge DL，在多个方面共同面临着一些相同的挑战和现实问题，我们确定了以下五项对Edge DL至关重要的技术：</p>
<ol type="1">
<li>基于Edge的DL应用，系统组织边缘计算和DL提供智能服务的技术框架；</li>
<li>Edge中的DL推理，侧重于DL在边缘计算体系结构中的实际部署和推理，以满足不同的需求，如精度和延迟；</li>
<li>DL的边缘计算，在网络体系结构、硬件和软件方面适应边缘计算平台以支持DL计算；</li>
<li>Edge的DL训练，在资源和隐私约束下训练分布式边缘设备的DL模型；</li>
<li>用于优化边缘的DL，用于维护和管理边缘计算网络(系统)的不同功能的DL的应用，例如边缘高速缓存[16]、计算卸载[17]。</li>
</ol>
<p>如图3所示，“边缘上的数字图书馆应用”和“优化边缘的数字图书馆”分别对应了边缘智能和智能边缘的理论目标。为了支持它们，首先需要通过密集的计算来训练各种DL模型。在这种情况下，对于利用边缘计算资源训练各种DL模型的相关工作，我们将其归类为“边缘DL训练”。其次，为了支持和加速Edge DL服务，我们重点研究了支持边缘计算框架和网络中DL模型的高效推理的各种技术，称为“Edge中的DL推理”。最后，我们将所有采用边缘计算框架和网络来更好地服务于Edge DL的技术归类为“面向DL的边缘计算”。</p>
<figure>
<img src= "/img/loading.gif" data-lazy-src="/2021/04/11/Paper/%E8%BE%B9%E7%BC%98%E8%AE%A1%E7%AE%97%E4%B8%8E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9A%84%E8%9E%8D%E5%90%88/image-20210407123433129.png" alt="image-20210407123433129"><figcaption aria-hidden="true">image-20210407123433129</figcaption>
</figure>
<p>据我们所知，现有的与我们工作最相关的文章包括[18]-[21]。与我们更广泛地介绍Edge DL不同，[18]的重点是在EDGE智能中使用机器学习(而不是DL)来实现无线通信，即在网络边缘训练机器学习以改进无线通信。此外，关于DL推理和训练的讨论是[19]-[21]的主要贡献。与这些工作不同的是，本调查集中在以下几个方面：1)从边缘计算、跨组网、通信和计算四个方面综合考虑DL的部署问题；2)从五个使能器的角度考察DL和边缘计算融合的整体技术谱；3)指出DL和边缘计算是互惠互利的，认为只在边缘部署DL是不完整的。</p>
<p>这篇论文组织如下(如图4所示)。我们已经在本节中介绍了本次调查的背景和动机。接下来，我们将分别在第二节和第三节中提供与边缘计算和DL相关的一些基础知识。下面几节介绍了五种使能技术，即EDGE上的DL应用(第四节)、EDGE中的DL推理(第五节)、用于DL服务的EDGE计算(第六节)、EDGE上的DL训练(第七节)和用于优化EDGE的DL(第八节)。最后，我们在第九节中介绍了吸取的经验教训，并在第十节中讨论了开放的挑战，并在第十节中得出了结论。所有相关的缩略语都列在表I中。</p>
<figure>
<img src= "/img/loading.gif" data-lazy-src="/2021/04/11/Paper/%E8%BE%B9%E7%BC%98%E8%AE%A1%E7%AE%97%E4%B8%8E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9A%84%E8%9E%8D%E5%90%88/image-20210407123549625.png" alt="image-20210407123549625"><figcaption aria-hidden="true">image-20210407123549625</figcaption>
</figure>
<figure>
<img src= "/img/loading.gif" data-lazy-src="/2021/04/11/Paper/%E8%BE%B9%E7%BC%98%E8%AE%A1%E7%AE%97%E4%B8%8E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9A%84%E8%9E%8D%E5%90%88/image-20210408093341172.png" alt="image-20210408093341172"><figcaption aria-hidden="true">image-20210408093341172</figcaption>
</figure>
<h1 id="二-边缘计算基础知识">二 边缘计算基础知识</h1>
<p>边缘计算凭借其在减少数据传输、改善服务时延、缓解云计算压力等方面的优势，成为破解新兴技术瓶颈的重要解决方案。边缘计算架构将成为云的重要补充，甚至在某些场景中取代云的角色。更详细的信息可以在[8]、[22]、[23]中找到。</p>
<h2 id="a.边缘计算的范例">A.边缘计算的范例</h2>
<p>在边缘计算的发展中，已经出现了各种新技术，它们都是针对网络边缘工作的，原理相同，但侧重点不同。例如Cloudlet[24]、微数据中心(MDC)[25]、雾计算[26]、[27]和移动边缘计算<a href="即现在的多路访问边缘计算%5B28%5D">5</a>。然而，边缘计算界尚未就边缘计算的标准化定义、体系结构和协议达成共识[23]。我们用一个通用的术语“边缘计算”来描述这套新兴技术。在这一部分中，对不同的边缘计算概念进行了介绍和区分。</p>
<ol type="1">
<li><strong>Cloudlet和微数据中心：</strong>Cloudlet是移动计算和云计算相结合的网络架构元素。它代表了三层架构的中间层，即移动设备、微云和云。它的亮点在于：1)定义系统并创建支持低延迟边缘云计算的算法；2)在开放源码中实现相关功能，作为Open Stack云管理软件的扩展[24]。与Cloudlet类似，MDC[25]也是为补充云而设计的。我们的想法是将运行客户应用程序所需的所有计算、存储和网络设备打包在一个机箱中，作为独立的安全计算环境，用于需要较低延迟的应用程序或电池寿命或计算能力有限的终端设备。</li>
<li><strong>雾计算：</strong>雾计算的亮点之一是，它假设了一个拥有数十亿设备和大规模云数据中心的全分布式多层云计算架构[26]、[27]。虽然云和雾范例共享一组类似的服务，如计算、存储和联网，但雾的部署针对特定的地理区域。此外，FOG专为需要延迟更小的实时响应的应用而设计，例如交互式和物联网应用。与Cloudlet、MDC和MEC不同，雾计算更关注物联网。</li>
<li><strong>移动(多路访问)边缘计算(MEC)：</strong>移动边缘计算将计算能力和服务环境置于蜂窝网络的边缘[5]。它旨在提供更低的延迟、情景和位置感知以及更高的带宽。通过在蜂窝基站(BSS)上部署边缘服务器，用户可以灵活、快速地部署新的应用和服务。欧洲电信标准协会(ETSI)通过适应更多的无线通信技术，如Wi-Fi[28]，进一步将MEC的术语从移动边缘计算扩展到多路访问边缘计算。</li>
<li><strong>边缘计算术语的定义：</strong>在大多数文献中，边缘设备的定义和划分是模棱两可的(边缘节点和终端设备之间的边界不明确)。为此，如图1所示，我们将常见的边缘设备进一步划分为终端设备和边缘节点：“终端设备”(End Level)是指移动边缘设备(包括智能手机、智能车辆等)。和各种物联网设备，边缘节点(边缘层)包括小云、路侧单元(RSU)、雾节点、边缘服务器、MEC服务器等，即部署在网络边缘的服务器。</li>
<li><strong>协作型终端边缘-云计算：</strong>云计算是为处理DL等计算密集型任务而创建的，但无法保证从数据生成到传输到执行的全过程的延迟需求。此外，终端或边缘设备上的独立处理受到其计算能力、功耗和成本瓶颈的限制。因此，如图6所示，用于DL[12]的协作端-边-云计算正成为图6所示的一个重要趋势。在这种新的计算范例中，由终端设备生成的计算强度较低的计算任务可以直接在终端设备上执行或卸载到边缘，从而避免了将数据发送到云所造成的延迟。在这种新的计算模式中，由终端设备生成的计算强度较低的计算任务可以直接在终端设备上执行或卸载到边缘，从而避免了向云发送数据所造成的延迟。对于计算密集型任务，合理分割，分别调度到端、边、云执行，在保证结果[12]、[49]、[50]准确性的同时，减少了任务的执行延迟。这种协作模式的重点不仅在于成功完成任务，还在于实现设备能耗、服务器负载、传输和执行延迟之间的最佳平衡。</li>
</ol>
<figure>
<img src= "/img/loading.gif" data-lazy-src="/2021/04/11/Paper/%E8%BE%B9%E7%BC%98%E8%AE%A1%E7%AE%97%E4%B8%8E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9A%84%E8%9E%8D%E5%90%88/image-20210408093407927.png" alt="image-20210408093407927"><figcaption aria-hidden="true">image-20210408093407927</figcaption>
</figure>
<figure>
<img src= "/img/loading.gif" data-lazy-src="/2021/04/11/Paper/%E8%BE%B9%E7%BC%98%E8%AE%A1%E7%AE%97%E4%B8%8E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9A%84%E8%9E%8D%E5%90%88/image-20210407124649729.png" alt="image-20210407124649729"><figcaption aria-hidden="true">image-20210407124649729</figcaption>
</figure>
<h2 id="b.用于边缘计算的硬件">B.用于边缘计算的硬件</h2>
<p>在本节中，我们将讨论边缘智能的潜在使能硬件，即针对终端设备和边缘节点的定制AI芯片和商品。此外，还介绍了用于DL的边缘云系统(如表II所示)。</p>
<ol type="1">
<li><p><strong>边缘计算的AI硬件：</strong>新兴的边缘AI硬件根据其技术架构可以分为三类：1)基于图形处理器(GPU)的硬件，其兼容性和性能较好，但一般能耗较高，如NVIDIA的基于图灵架构的GPU[37]；2)基于现场可编程门阵列(FPGA)的硬件[51]、[52]，其节能且需要较少的计算资源，但与GPU相比兼容性较差，编程能力有限；3)基于专用集成电路(ASIC)的硬件，如Google的TPU[38]和HiSilicon的Ascend系列[35]，通常采用在性能和功耗方面更稳定的定制设计。</p>
<p>由于智能手机代表着部署最广泛的边缘设备，智能手机芯片经历了快速发展，其能力已经扩展到AI计算的加速。举几个例子，高通首先将AI硬件加速[33]应用于骁龙，并发布了支持几乎所有主要DL框架的骁龙神经处理引擎(SNPE)SDK[53]。与高通相比，HiSilicon的600系列和900系列芯片[34]不依赖GPU。相反，它们加入了额外的神经处理单元(NPU)来实现向量和矩阵的快速计算，从而极大地提高了DL的效率。与HiSilicon和高通相比，联发科的Helio P60不仅使用了GPU，还引入了人工智能处理单元(APU)来进一步加速神经网络计算[36]。关于DL的大多数商用芯片的性能比较可以在[54]中找到，更多的EDGE器件的定制芯片将在后面详细讨论。</p></li>
<li><p><strong>可能用于边缘节点的集成产品：</strong>边缘节点应具有计算和缓存功能，并在终端设备附近提供高质量的网络连接和计算服务。与大多数终端设备相比，边缘节点具有更强大的计算能力来处理任务。另一方面，边缘节点可以比云更快地响应终端设备。因此，通过部署边缘节点来执行计算任务，可以在保证计算精度的同时加快任务处理速度。此外，边缘节点还具有缓存能力，可以通过缓存热门内容来提高响应时间。例如，包括华为的Atlas模块[32]和微软的Data Box Edge[29]在内的实用解决方案可以进行初步的DL推理，然后转移到云上进行进一步改进。</p></li>
<li><p><strong>边缘计算框架：</strong>边缘计算系统的解决方案正在蓬勃发展。对于配置复杂、资源需求密集的DL业务，拥有先进优秀微业务架构的边缘计算系统是未来的发展方向。目前，Kubernetes是一个主流的以容器为中心的系统，用于部署、维护和扩展云计算中的应用程序[55]。基于Kubernetes，华为开发了边缘计算解决方案“KubeEdge”[41]，用于云和边缘之间的联网、应用部署和元数据同步(Akraino Edge Stack[45]也支持)。“OpenEdge”[42]专注于屏蔽计算框架和简化应用程序生产。对于物联网，Azure IoT Edge[43]和EdgeX[44]旨在通过在跨平台物联网设备上部署和运行AI，为边缘提供云智能。</p></li>
</ol>
<h2 id="c.虚拟化边缘">C.虚拟化边缘</h2>
<p>虚拟化技术对边缘计算和DL集成的要求体现在以下几个方面：1)边缘计算资源有限。边缘计算不能像云那样为DL服务提供资源。虚拟化技术应在有限资源的约束下最大化资源利用率；2)DL服务严重依赖复杂的软件库。应仔细考虑这些软件库的版本和依赖关系。因此，迎合边缘DL服务的虚拟化应该能够隔离不同的服务。具体地说，单个服务的升级、关闭、崩溃和高资源消耗不应影响其他服务；3)服务响应速度对Edge DL至关重要。EDGE DL不仅需要边缘设备的计算能力，还需要边缘计算架构能够提供的敏捷服务响应。</p>
<p>边缘计算和数字图书馆的结合形成高性能的边缘数字图书馆服务，需要计算、网络和通信资源的协同集成，如图8所示，具体而言，计算虚拟化和网络虚拟化、管理技术的集成都是必要的。在本节中，我们将讨论适用于边缘的潜在虚拟化技术。</p>
<figure>
<img src= "/img/loading.gif" data-lazy-src="/2021/04/11/Paper/%E8%BE%B9%E7%BC%98%E8%AE%A1%E7%AE%97%E4%B8%8E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9A%84%E8%9E%8D%E5%90%88/image-20210407125241592.png" alt="image-20210407125241592"><figcaption aria-hidden="true">image-20210407125241592</figcaption>
</figure>
<ol type="1">
<li><p><strong>虚拟化技术：</strong>目前主要有两种虚拟化策略：虚拟机(VM)和容器。一般来说，VM在隔离方面做得更好，而CONTAINER则更容易部署重复性任务[69]。借助操作系统级别的虚拟机虚拟化，虚拟机管理程序可将物理服务器拆分成一个或多个虚拟机，并可轻松管理每个虚拟机以隔离执行任务。此外，通过创建包括多个独立虚拟计算设备的可扩展系统，VM管理程序可以更有效地分配和使用空闲计算资源。</p>
<p>​ 与VM相比，容器虚拟化是打包、交付和编排软件基础设施服务和应用程序的更灵活的工具。边缘计算的容器虚拟化可以有效地减少高性能和高存储要求的工作负载执行时间，还可以以可扩展和简单的方式部署大量服务[70]。容器由单个文件组成，该文件包括具有所有依赖关系的应用和执行环境，这使得它能够实现有效的服务切换以应对用户移动性[71]。由于容器中的应用程序的执行不像在VM虚拟化中那样依赖于额外的虚拟化层，因此显著减少了执行应用程序所需的处理器消耗和内存量。</p></li>
<li><p><strong>网络虚拟化：</strong>传统的网络功能与特定的硬件相结合，不足以按需管理边缘计算网络。为了将网络设备功能整合到行业标准的服务器、交换机和存储中，网络功能虚拟化(NFV)通过将网络功能和服务从专用网络硬件中分离出来，使虚拟网络功能(VNF)能够在软件中运行。此外，Edge DL服务通常需要高带宽、低延迟和动态网络配置，而软件定义网络(SDN)可通过三项关键创新[72]实现服务的快速部署、网络可编程性和多租户支持：1)控制平面和数据平面分离；2)集中式可编程控制平面；3)标准化应用编程接口。凭借这些优势，它支持高度定制的网络策略，该策略非常适合Edge DL服务的高带宽、动态特性。</p>
<p>​ 网络虚拟化和边缘计算互惠互利。一方面，NFV/SDN可以增强边缘计算基础设施的互操作性。例如，在NFV/SDN的支持下，边缘节点可以高效地与云数据中心[73]进行协调和集成。另一方面，VNF和Edge DL服务都可以托管在轻量级NFV框架上(部署在边缘)[74]，从而最大限度地重用NFV的基础设施和基础设施管理[75]。</p></li>
<li><p><strong>网络切片：</strong>网络切片是一种灵活的虚拟网络体系结构形式，是对网络的高级抽象，允许在公共共享物理基础设施之上创建多个网络实例，每个实例都针对特定服务进行了优化。随着服务和QoS需求的日益多样化，由NFV/SDN实现的网络切片自然与分布式边缘计算范式兼容。为了满足这些要求，网络切片可以与边缘计算网络中的计算和通信资源的联合优化相协调[76]。图8描述了基于边缘虚拟化的网络切片示例。为了在网络切片中实现服务定制，虚拟化技术和SDN必须结合在一起，以支持边缘节点上的资源分配和服务提供的紧密协调，同时允许灵活的服务控制。通过网络切片，可以为边缘DL服务提供定制和优化的资源，这有助于减少接入网络造成的延迟，并支持对这些服务的密集访问[77]。</p></li>
</ol>
<h1 id="三-深度学习的基础">三 深度学习的基础</h1>
<p>关于CV、NLP和AI，DL在众多应用中被采用，并证实了其卓越的性能[78]。目前，云中需要部署大量的GPU、TPU或FPGA来处理DL服务请求。然而，由于边缘计算架构覆盖了大量的分布式边缘设备，因此可以利用它来更好地服务于DL。当然，与云计算相比，边缘设备的计算能力或功耗通常有限。因此，DL和边缘计算的结合并不简单，在设计和部署时需要全面了解DL模型和边缘计算功能。在这一部分中，我们简要介绍DL和相关技术术语，为讨论DL和边缘计算的集成铺平道路(更多细节可以在[79]中找到)。</p>
<h2 id="a.深度学习中的神经网络">A.深度学习中的神经网络</h2>
<p>DL模型由各种类型的深度神经网络(DNNs)组成[79]。下面从基本结构和功能方面介绍DNN的基本原理。</p>
<ol type="1">
<li><strong>全连接神经网络(FCNN)：</strong>FCNN的每一层(即多层感知器(MLP))的输出前馈到下一层，如图7(A)所示。在相邻的FCNN层之间，神经元(细胞)的输出(输入或隐藏细胞)直接传递给属于下一层的神经元并由其激活[80]。FCNN可以用于特征提取和函数逼近，但是复杂度高，性能一般，收敛速度慢。</li>
<li><strong>自动编码器(AE)：</strong>自动编码器(AE)，如图7(B)所示，实际上是一个由两个NN组成的堆栈，它们以无监督的学习方式将输入复制到其输出。第一个神经网络学习输入(编码)的代表性特征。第二个神经网络将这些特征作为输入，并在匹配输入输出单元恢复原始输入的近似值，用于从输入到输出收敛到恒等式函数，作为最终输出(解码)。由于AE能够学习输入数据的低维有用特征来恢复输入数据，因此它通常用于分类和存储高维数据[81]</li>
<li><strong>卷积神经网络(CNN)：</strong>通过使用汇集操作和一组不同的移动过滤器，CNN捕获相邻数据片段之间的相关性，然后生成输入数据的连续更高级别的抽象，如图7(C)所示。与FCNN相比，CNN可以在降低模型复杂度的同时提取特征，从而降低了过度拟合的风险[82]。这些特点使得CNN在图像处理方面取得了显著的性能，在处理类似于图像的结构数据时也很有用。</li>
</ol>
<figure>
<img src= "/img/loading.gif" data-lazy-src="/2021/04/11/Paper/%E8%BE%B9%E7%BC%98%E8%AE%A1%E7%AE%97%E4%B8%8E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9A%84%E8%9E%8D%E5%90%88/image-20210407140854590.png" alt="image-20210407140854590"><figcaption aria-hidden="true">image-20210407140854590</figcaption>
</figure>
<ol start="4" type="1">
<li><p><strong>生成性对抗性网络(GAN)：</strong>GAN起源于博弈论。如图7(D)所示，GaN由发生器和鉴别器组成。生成器的目标是通过故意在反馈输入单元引入反馈来尽可能多地了解真实数据分布，而鉴别器则是正确地确定输入数据是来自真实数据还是来自生成器。这两个参与者需要不断优化他们在对抗性过程中产生和区分的能力，直到找到纳什均衡[83]。因此，训练有素的生成器可以根据从真实信息中学习到的特征来编造无法区分的信息。</p></li>
<li><p><strong>递归神经网络(RNN)：</strong>递归神经网络是为处理时序数据而设计的。如图7(E)所示，RNN中的每个神经元不仅从上层接收信息，而且还从它自己的前一个通道接收信息[10]。通常，RNN是预测未来信息或恢复序列数据缺失部分的自然选择。然而，RNN的一个严重问题是梯度爆炸。如图7(F)所示，LSTM通过添加栅极结构和定义明确的存储单元来改进RNN，可以通过控制(禁止或允许)信息流来克服该问题[84]。</p></li>
<li><p>迁移学习(TL)：迁移学习可以将知识从源域转移到目标域，如图7(G)所示，从而在目标域实现更好的学习性能[85]。通过使用TL，可以将从大量计算资源中学习到的现有知识转移到新的场景中，从而加快了训练过程，降低了模型开发成本。最近，出现了一种新的翻译形式，即知识蒸馏(Knowledge Distilation，KD)[86]。如图7(H)所示，KD可以从训练有素的模型(教师)中提取隐含知识，其推理具有良好的性能，但需要较高的开销。然后，通过设计目标DL模型的结构和目标函数，将知识“传递”到一个较小的DL模型(学生)，从而使显著减少(剪枝或量化)的目标DL模型获得尽可能高的性能。</p></li>
</ol>
<h2 id="b.深度强化学习drl">B.深度强化学习(DRL)</h2>
<p>如图9所示，RL的目标是使环境中的Agent能够在当前状态下采取最佳行动以最大化长期收益，其中Agent在环境中的行动和状态之间的交互被建模为马尔可夫决策过程(MDP)。DRL是DL和RL的结合，但它更侧重于RL，旨在解决决策问题。DL的作用是利用DNN强大的表示能力来拟合值函数或直接策略来解决状态-动作空间或连续状态-动作空间的爆炸问题。由于这些特点，DRL成为机器人、金融、推荐系统、无线通信等领域的强大解决方案。</p>
<figure>
<img src= "/img/loading.gif" data-lazy-src="/2021/04/11/Paper/%E8%BE%B9%E7%BC%98%E8%AE%A1%E7%AE%97%E4%B8%8E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9A%84%E8%9E%8D%E5%90%88/image-20210407140617800.png" alt="image-20210407140617800"><figcaption aria-hidden="true">image-20210407140617800</figcaption>
</figure>
<ol type="1">
<li><strong>基于值的DRL：</strong>作为基于值的DRL的代表，Deep Q-Learning(DQL)使用DNN来拟合动作值，成功地将高维输入数据映射到动作[88]。为了保证训练的稳定收敛，采用经验回放的方法打破过渡信息之间的相关性，并建立单独的目标网络来抑制不稳定性。此外，双重深度Q-学习(Double Deep Q-Learning，Double-DQL)可以处理DQL通常高估动作值的问题[89]，而决斗深度Q-学习(Dueling Deep Q-Learning，Dueling-DQL)[90]可以学习哪些状态是有价值的(或不有价值的)，而不必了解每个状态下每个动作的效果。</li>
<li><strong>基于策略梯度的DRL：</strong>策略梯度是另一种常用的策略优化方法，如深度确定性策略梯度(DDPG)[91]、异步优势执行者-批评者(A3C)[92]、近似策略优化(PPO)[93]等，它通过不断计算策略期望回报的梯度来更新策略参数，最终收敛到最优策略[94]。因此，在解决DRL问题时，可以使用DNN对策略进行参数化，然后用策略梯度法对其进行优化。此外，在基于策略梯度的DRL中，广泛采用了Actor-Critic(AC)框架，其中策略DNN用于更新策略，对应于Actor；值DNN用于逼近状态动作对的值函数，并提供对应于Critic的梯度信息。</li>
</ol>
<h2 id="c.分布式dl训练">C.分布式DL训练</h2>
<p>目前，集中训练DL模型耗费了大量的时间和计算资源，阻碍了算法性能的进一步提高。尽管如此，通过充分利用并行服务器，分布式培训可以简化培训过程。有两种常见的方法来执行分布式训练，即数据并行和模型并行[95]-[98]，如图10所示。</p>
<figure>
<img src= "/img/loading.gif" data-lazy-src="/2021/04/11/Paper/%E8%BE%B9%E7%BC%98%E8%AE%A1%E7%AE%97%E4%B8%8E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9A%84%E8%9E%8D%E5%90%88/image-20210407130048352.png" alt="image-20210407130048352"><figcaption aria-hidden="true">image-20210407130048352</figcaption>
</figure>
<p>模型并行首先将一个大的DL模型分成多个部分，然后提供数据样本用于并行训练这些分割后的模型。这样不仅可以提高训练速度，而且可以处理模型大于设备内存的情况。训练一个大型的DL模型通常需要大量的计算资源，甚至需要数千个CPU来训练一个大规模的DL模型。为了解决这个问题，可以利用分布式GPU进行模型并行训练[99]。数据并行是指将数据分成多个分区，然后将模型的副本分别与各自分配的数据样本并行训练。通过这种方式，可以提高模型训练的训练效率[100]。</p>
<p>巧合的是，大量终端设备、边缘节点和云数据中心分散在一起，并设想通过边缘计算网络进行连接。一旦DL培训跳出云，这些分布式设备可能成为强大的贡献者。</p>
<h2 id="d.边缘的潜在dl库">D.边缘的潜在DL库</h2>
<p>DL模型的开发和部署依赖于各种DL库的支持。但是，不同的DL库有各自的应用场景。要在边缘部署DL，需要高效的轻量级DL库。表III列出了可能支持未来边缘智能的DL框架的功能(不包括边缘设备不可用的库，如Theano[101])。</p>
<h1 id="四-边缘的深度学习应用">四 边缘的深度学习应用</h1>
<p>一般情况下，DL服务一般部署在云数据中心(云)来处理请求，因为大多数DL模型比较复杂，很难在资源受限的设备侧计算其推理结果。然而，这种端-云架构无法满足实时分析、智能制造等实时下行服务的需求，因此，在边缘部署下行应用可以拓宽下行的应用场景，尤其是在低延迟特性方面。下面，我们将介绍EDGE DL应用，并强调其相对于没有边缘计算的比较体系结构的优势。</p>
<h2 id="a.实时视频分析">A.实时视频分析</h2>
<p>实时视频分析在自动驾驶、VR与增强现实(AR)、智能监控等领域都具有重要的应用价值。一般情况下，应用DL进行实时视频分析需要较高的计算和存储资源。不幸的是，在云中执行这些任务通常会导致高带宽消耗、意外延迟和可靠性问题。随着边缘计算的发展，这些问题往往通过将视频分析移到数据源(即终端设备或边缘节点)附近作为云的补充来解决。在本节中，如图11所示，我们将相关工作总结为混合层次架构，该架构分为三个级别：端、边和云。</p>
<figure>
<img src= "/img/loading.gif" data-lazy-src="/2021/04/11/Paper/%E8%BE%B9%E7%BC%98%E8%AE%A1%E7%AE%97%E4%B8%8E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9A%84%E8%9E%8D%E5%90%88/image-20210408093434237.png" alt="image-20210408093434237"><figcaption aria-hidden="true">image-20210408093434237</figcaption>
</figure>
<figure>
<img src= "/img/loading.gif" data-lazy-src="/2021/04/11/Paper/%E8%BE%B9%E7%BC%98%E8%AE%A1%E7%AE%97%E4%B8%8E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9A%84%E8%9E%8D%E5%90%88/image-20210407131730682.png" alt="image-20210407131730682"><figcaption aria-hidden="true">image-20210407131730682</figcaption>
</figure>
<ol type="1">
<li><p><strong>末级：</strong>在末级，智能手机和监控摄像头等视频捕获设备负责视频捕获、媒体数据压缩[102]、图像预处理和图像分割[103]。通过与这些参与设备协调，当与域约束深度模型[104]一起使用时，协作性地训练域感知适配模型可以导致更好的对象识别准确性。此外，为了适当地将DL计算卸载到终端设备、边缘节点或云，终端设备应该综合考虑视频压缩和关键指标(例如，网络条件、数据使用、电池消耗、处理延迟、帧率和分析准确性)之间的权衡，从而确定最佳卸载策略[102]。</p>
<p>​ 如果在末级独立执行各种DL任务，则启用并行分析需要支持高效多租户DL的解决方案。通过模型剪枝和恢复方案，NestDNN[105]将DL模型转换为一组子代模型，其中资源需求较少的子代模型与需要更多资源的子代模型共享其模型参数，使其自身嵌套在需要更多资源的子代模型中，而不占用额外的存储空间。通过这种方式，多容量模型以紧凑的内存空间提供了可变的资源精度折衷，从而确保了终端级别的高效多租户DL。</p></li>
<li><p><strong>边缘层：</strong>众多分布在边缘层的边缘节点通常相互协作，提供更好的服务。例如，LA VEA[106]将边缘节点连接到相同的接入点或BS以及终端设备，从而确保服务可以像互联网接入一样无处不在。此外，对DL模型进行边缘压缩可以提高整体性能。通过减少CNN层中不必要的滤波器，可以在保证分析性能的同时大大降低边缘层的资源消耗[107]。此外，为了优化性能和效率，[108]提出了一个边缘服务框架EdgeEye，它实现了基于DL的实时视频分析功能的高层抽象。为了充分利用边缘的绑定功能，VideoEdge[109]实施了端-边-云分层架构，以帮助实现与分析任务相关的负载平衡，同时保持较高的分析精度。</p></li>
<li><p><strong>云级：</strong>在云级，云负责边缘层之间DL模型的集成和边缘节点上分布式DL模型的参数更新[102]。由于边缘节点上的分布式模型训练性能可能会因其局部知识而受到严重影响，因此云需要整合不同训练有素的DL模型来实现全局知识。当边缘无法自信地提供服务时(例如，以低置信度检测对象)，云可以利用其强大的计算能力和全局知识进行进一步处理，并协助边缘节点更新DL模型。</p></li>
</ol>
<h2 id="b.自主车联网iovs">B.自主车联网(IoVs)</h2>
<p>可以预见，车辆可以连接在交通系统中以提高安全性、提高效率、减少事故和减少交通拥堵[110]。有许多信息和通信技术，如网络、缓存、边缘计算等，都可以用来促进IoVs，尽管通常是分开研究的。一方面，边缘计算为车辆提供低延迟、高速通信和快速响应服务，使自动驾驶成为可能。另一方面，DL技术在各种智能车辆应用中也非常重要。此外，他们还有望优化复杂的IoVs系统。</p>
<p>[110]文中提出了一个集成这些技术的框架。该集成框架实现了网络、高速缓存和计算资源的动态协调，以满足不同车辆应用的需求[110]。由于该系统涉及多维控制，本文首先采用基于动态链接库的方法来求解优化问题，以提高系统的整体性能。类似地，在[111]中也使用DRL来获得车辆边缘计算中的最优任务卸载策略。此外，可以利用车辆到车辆(V2V)通信技术来进一步连接车辆，无论是作为边缘节点还是作为由基于DRL的控制策略管理的终端设备[112]。</p>
<h2 id="c.智能制造">C.智能制造</h2>
<p>智能制造时代最重要的两个原则是自动化和数据分析，前者是主要目标，后者是最有用的工具之一[113]。为了遵循这些原则，智能制造应该首先解决响应延迟、风险控制和隐私保护问题，因此需要DL和边缘计算。在智能工厂中，边缘计算有利于将云的计算资源、网络带宽和存储容量扩展到物联网边缘，实现制造和生产过程中的资源调度和数据处理[114]。对于自主制造检测，DeepIns[113]使用DL和边缘计算分别保证性能和处理延迟。该系统的主要思想是将用于检测的DL模型进行划分，分别部署在端层、边缘层和云层，以提高检测效率。</p>
<p>尽管如此，随着物联网边缘设备的指数级增长，1)如何远程管理不断发展的DL模型，以及2)如何为它们持续评估这些模型是必要的。[115]开发了一个框架来应对这些挑战，以支持智能制造过程中的复杂事件学习，从而促进物联网边缘设备上实时应用的开发。此外，还应考虑物联网边缘设备[116]的功耗、能效和内存占用限制。因此，可以集成缓存、与异构物联网设备的通信以及计算卸载[117]，以打破资源瓶颈。</p>
<h2 id="d.智能家居和城市">D.智能家居和城市</h2>
<p>物联网的普及将给家庭生活带来越来越多的智能应用，如智能照明控制系统、智能电视、智能空调等。但与此同时，智能家居需要在角落、楼层和墙壁部署大量无线物联网传感器和控制器。为了保护敏感的家庭数据，智能家居系统的数据处理必须依靠边缘计算。与[118]、[119]中的使用案例一样，部署边缘计算来优化室内定位系统和家庭入侵监控，以便它们可以获得比使用云计算更低的延迟以及更高的准确性。此外，DL和边缘计算的结合可以使这些智能服务变得更加多样化和强大。例如，它赋予机器人动态视觉服务的能力[120]，并使高效的音乐认知系统[121]成为可能。</p>
<p>如果将智能家居扩大到社区或城市，公共安全、健康数据、公共设施、交通等领域都可以受益。在智慧城市应用边缘计算的初衷，更多是出于成本和效率的考虑。城市中地理分布的数据源的自然特性要求基于边缘计算的范例来提供位置感知和延迟敏感的监控和智能控制。例如，[122]中的分层分布式边缘计算架构可以支持未来智慧城市中海量基础设施组件和服务的集成。该架构不仅可以支持终端设备上的延迟敏感型应用，还可以在边缘节点上高效地执行稍微容忍延迟的任务，而负责深度分析的大规模DL模型则托管在云上。此外，DL还可用于协调和调度基础设施，以实现城市区域(例如，在校园[123]内)或整个城市之间的整体负载平衡和最佳资源利用。</p>
<h1 id="五-edge中的深度学习推理">五 EDGE中的深度学习推理</h1>
<p>为了进一步提高精度，DNN的研究越来越深入，需要更大规模的数据集。通过这种方式，引入了巨大的计算成本。当然，DL机型的出色表现离不开高水平硬件的支持，在资源有限的情况下很难在边缘部署。因此，大规模的DL模型通常部署在云中，而终端设备只是将输入数据发送到云中，然后等待DL推理结果。然而，仅限云的推断限制了DL服务的无处不在的部署。具体地说，它不能保证实时业务的时延要求，例如对时延要求严格的实时检测。此外，对于重要的数据源，应该解决数据安全和隐私保护问题。为了解决这些问题，DL服务倾向于求助于边缘计算。因此，DL模型应该进一步定制，以适应资源受限的边缘，同时仔细考虑推理精度和执行延迟之间的权衡。</p>
<h2 id="a.边界上dl模型的优化">A.边界上DL模型的优化</h2>
<p>DL任务通常是计算密集型的，并且需要大量内存。但在边缘，没有足够的资源来支持原始的大规模DL模型。优化DL模型并量化其权重可以降低资源成本。事实上，模型冗余在DNN[124]、[125]中很常见，可以用来使模型优化成为可能。最重要的挑战是如何确保优化后的模型精度不会有明显损失。换句话说，优化方法应该转换或重新设计DL模型，并使其适合边缘设备，同时尽可能减少模型性能的损失。在这一部分中，讨论了不同场景下的优化方法：1)针对资源相对充足的边缘节点的通用优化方法；2)针对资源预算紧张的终端设备的细粒度优化方法。</p>
<ol type="1">
<li><strong>模型优化的一般方法：</strong>一方面，在计算开销几乎不变的情况下增加DL模型的深度和宽度是优化的一个方向，例如CNN的初始网络[126]和深度剩余网络[127]。另一方面，对于更一般的神经网络结构，现有的优化方法可以分为四类[128]：1)参数剪枝和共享[129]、[130]，也包括权重量化[131]-[133]；2)低阶分解[124]；3)转移/紧凑卷积滤波器[107]、[134]、[135]；4)知识提炼[136]。这些方法可以应用于不同类型的DNN，也可以组合成优化边缘的复杂DL模型。</li>
<li><strong>边缘设备的型号优化：</strong>除了有限的计算和内存占用外，还需要考虑网络带宽和功耗等其他因素。在本节中，我们将区分和讨论在边缘设备上运行DL的努力。</li>
</ol>
<ul>
<li><strong>模型输入：</strong>每个应用场景都有特定的优化空间。在目标检测方面，FFSVA使用两个前置流专用滤波器和一个小的全功能微YOLO模型来过滤掉巨大但非目标对象帧[137]。为了以低成本在线调整输入视频流的配置(如帧分辨率和采样率)，Chameleon[138]通过利用视频输入的时间和空间相关性大大节省了搜索最佳模型配置的成本，并允许成本随时间和跨多个视频源摊销。此外，如图12所示，缩小分类器的搜索空间[139]和动态感兴趣区域(RoI)编码[140]以聚焦于视频帧中的目标对象可以进一步降低带宽消耗和数据传输延迟。虽然这种方法可以在不改变DL模型结构的情况下显著压缩模型输入的大小，从而减少计算开销，但需要深入了解相关的应用场景，才能挖掘出潜在的优化空间。</li>
</ul>
<figure>
<img src= "/img/loading.gif" data-lazy-src="/2021/04/11/Paper/%E8%BE%B9%E7%BC%98%E8%AE%A1%E7%AE%97%E4%B8%8E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9A%84%E8%9E%8D%E5%90%88/image-20210407131630393.png" alt="image-20210407131630393"><figcaption aria-hidden="true">image-20210407131630393</figcaption>
</figure>
<ul>
<li><strong>模型结构：</strong>不关注具体应用，关注广泛使用的DNN结构也是可行的。例如，逐点分组卷积和信道混洗[142]、并行卷积和合并计算[143]、沿深度可分离卷积[107]可以在保持精度的同时大大降低计算成本。Noscope[144]利用两种类型的模型而不是标准模型(如YOLO[9])：专用模型(放弃标准模型的通用性以换取更快的推理)和差异检测器(用于识别输入数据之间的时间差异)。在对每个模型的模型架构和阈值执行基于成本的高效优化后，noscope可以通过级联这些模型来最大化DL服务的吞吐量。此外，如图13所示，参数剪枝也可以自适应地应用于模型结构优化[145]-[147]。此外，如果跨越算法、软件和硬件之间的边界，优化可以更高效。具体地说，通用硬件还不能适应模型优化带来的不规则计算模式。因此，硬件架构应设计为直接为优化模型工作[145]。</li>
</ul>
<figure>
<img src= "/img/loading.gif" data-lazy-src="/2021/04/11/Paper/%E8%BE%B9%E7%BC%98%E8%AE%A1%E7%AE%97%E4%B8%8E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9A%84%E8%9E%8D%E5%90%88/image-20210407131612169.png" alt="image-20210407131612169"><figcaption aria-hidden="true">image-20210407131612169</figcaption>
</figure>
<ul>
<li><strong>模型选择：</strong>对于不同的DL模型，从边缘可用的DL模型中选择一个最好的模型需要权衡精度和推理时间。[148]在文中，作者使用KNN自动构造一个预测器，该预测器由按顺序排列的DL模型组成。然后，模型选择可以由该预测器以及模型输入的一组自动调谐特征来确定。此外，结合不同的压缩技术(如模型剪枝)，可以推导出性能和资源需求之间权衡不同的多个压缩DL模型。AdaDeep[149]探索了性能和资源约束之间的理想平衡，并基于DRL，根据当前可用的资源自动选择各种压缩技术(如模型剪枝)来形成压缩模型，从而充分利用了它们的优势。</li>
<li><strong>模型框架：</strong>考虑到DL的高内存占用和计算需求，在边缘设备上运行它们需要专家量身定制的软硬件框架。如果软件框架1)提供优化的软件内核的库以实现DL[150]的部署；2)通过寻找最小数量的非冗余隐藏元素来自动将DL模型压缩成较小的密集矩阵[151]；3)对所有常用的DL结构执行量化和编码[146]、[151]、[152]；4)将DL模型专门用于上下文并在多个同时执行的DL模型之间共享资源[152]，则该软件框架是有价值的。关于硬件，与动态RAM(DRAM)相比，在静态随机存取存储器(SRAM)上运行DL模型实现了更好的节能[146]。因此，如果底层硬件直接支持在片上SRAM上运行优化的DL模型[153]，则DL性能可以受益。</li>
</ul>
<h2 id="b.dl模型的分段">B.DL模型的分段</h2>
<p>在[12]中，对目前最先进的DL机型在云设备和边缘设备上的时延和功耗进行了评估，发现上传数据到云端是当前DL服务方式的瓶颈(导致传输开销大)。划分DL模型并进行分布式计算可以获得更好的端到端延迟性能和能量效率。另外，通过将部分DL任务从云端推送到边缘，可以提高云端的吞吐量。因此，DL模型可以被分割成多个分区，然后被分配给1)终端设备[154]上的异构本地处理器(例如，GPU、CPU)，2)分布式边缘节点[155]、[156]，或3)协作“端-边-云”架构[12]、[49]、[157]、[158]。</p>
<p>对DL模型进行水平分割(即沿末端、边缘和云)是最常用的分割方法。挑战在于如何智能地选择分割点。如图14所示，确定分割点的一般过程可分为三个步骤[12]、[157]：1)测量和建模不同DNN层的资源成本和层间中间数据的大小；2)通过特定的层配置和网络带宽预测总成本；3)根据延迟、能量需求等从候选分割点中选择最佳分割点。另一种模型分割是专门针对CNN的垂直分割[156]。与水平划分不同的是，垂直划分将层进行融合，并以网格的方式垂直划分层，从而将CNN层划分为可独立分布的计算任务。</p>
<figure>
<img src= "/img/loading.gif" data-lazy-src="/2021/04/11/Paper/%E8%BE%B9%E7%BC%98%E8%AE%A1%E7%AE%97%E4%B8%8E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9A%84%E8%9E%8D%E5%90%88/image-20210407131435737.png" alt="image-20210407131435737"><figcaption aria-hidden="true">image-20210407131435737</figcaption>
</figure>
<h2 id="c.提前退出推理eeoi">C.提前退出推理(EEoI)</h2>
<p>为了在模型精度和处理时延之间达到最佳折衷，可以为每个DL服务维护具有不同模型性能和资源成本的多个DL模型。然后，通过智能地选择最佳模型，实现所需的自适应推理[159]。尽管如此，这个想法还可以通过出现的EEOI[160]得到进一步改进。DNN中附加层的性能提高是以增加前馈推理的延迟和能量消耗为代价的。随着DNN规模的扩大和深度的加深，这些成本将使边缘设备无法运行实时、节能的DL应用。通过附加的侧枝分类器，对于部分样本，EEoI允许推理在置信度较高的情况下通过这些分支提前退出。对于较难的样本，EEoI将使用更多或所有DNN层来提供最佳预测。</p>
<p>如图15所示，通过利用EEoI，可以在边缘设备处启用使用DL模型的浅部分的快速和本地化推理。通过这种方法，边缘设备上的浅模型可以快速地进行初始特征提取，并且如果有把握，可以直接给出推断结果。否则，部署在云中的额外的大型DL模型执行进一步的处理和最终推理。与直接将DL计算卸载到云中相比，该方法具有更低的通信成本，并且可以获得比边缘设备上的剪枝或量化DL模型更高的推理精度[113]，[161]。此外，由于只将即时功能而不是原始数据发送到云，因此提供了更好的隐私保护。然而，EEoI不应被视为独立于模型优化(第V-A2节)和分段(第V-B节)。在终端、边缘和云上的分布式DL的设想应该考虑它们的协作，例如，开发用于自适应DNN划分和EEoI的协作和按需协同推理框架[162]。</p>
<figure>
<img src= "/img/loading.gif" data-lazy-src="/2021/04/11/Paper/%E8%BE%B9%E7%BC%98%E8%AE%A1%E7%AE%97%E4%B8%8E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9A%84%E8%9E%8D%E5%90%88/image-20210407131417473.png" alt="image-20210407131417473"><figcaption aria-hidden="true">image-20210407131417473</figcaption>
</figure>
<h2 id="d.共享dl计算">D.共享DL计算</h2>
<p>来自边缘节点覆盖范围内的附近用户的请求可以表现出时空局部性[163]。例如，同一区域内的用户可能请求针对同一感兴趣对象的识别任务，并且这可能引入DL推理的冗余计算。在这种情况下，基于对应用的离线分析和对网络状况的在线估计，Cachier[163]建议在边缘节点中缓存用于识别应用的相关DL模型，并通过动态调整其缓存大小来最小化预期的端到端延迟。基于第一人称视频中连续帧之间的相似性，DeepMon[164]和DeepCache[165]利用CNN层的内部处理结构，重用前一帧的中间结果来计算当前帧，即在CNN层内缓存内部处理的数据，以减少连续视觉应用的处理延迟。</p>
<p>然而，要继续进行有效的缓存和结果重用，必须解决对可重用结果的准确查找，即缓存框架必须系统地容忍这些变化并评估关键的相似性。DeepCache[165]执行缓存键查找来解决此问题。具体地说，它将每个视频帧划分为细粒度区域，并在视频运动启发式的特定模式中从缓存的帧中搜索相似区域。对于同样的挑战，F oggyCache[166]首先将异构的原始输入数据嵌入到具有通用表示的特征向量中。然后，提出了一种用于索引高维数据的自适应局部敏感散列(A-LSH)，它是LSH的一种变体，用于索引这些向量以实现快速准确的查找。最后，在KNN的基础上实现了同质化的KNN，利用缓存的值剔除孤立点，确保初始选择的k条记录中的优势簇，以确定A-LSH查找到的记录的重用输出。</p>
<p>与共享推理结果不同，主流[167]提出在并发视频处理应用程序之间自适应地编排DNN词干共享(几个专门的DL模型的共同部分)。通过利用从公共DNN主干通过TL训练的应用程序之间的专用模型的计算共享，可以显著减少每帧的聚合计算时间。尽管更专业的DL模型意味着更高的模型精度和更少的共享DNN词干，但随着使用不太专业的DL模型，模型精度会缓慢下降(除非专门的模型比例非常小)。因此，该特性使得DL模型的大部分可以在主流中以低精度损失共享。</p>
<h1 id="六-深度学习的边缘计算">六 深度学习的边缘计算</h1>
<p>数字图书馆服务的广泛部署，尤其是移动数字图书馆，需要边缘计算的支持。这种支持不仅仅是在网络架构层面，边缘硬件和软件的设计、调整和优化也同样重要。具体地说，1)定制EDGE硬件和相应的优化软件框架和库可以帮助DL更高效地执行；2)边缘计算架构可以实现DL计算的减负；3)设计良好的边缘计算框架可以更好地维护边缘上运行的DL服务；4)公平的Edge DL性能评估平台有助于进一步发展上述实现。</p>
<h2 id="a.用于dl的边缘硬件">A.用于DL的边缘硬件</h2>
<ol type="1">
<li><p><strong>移动CPU和GPU：</strong>如果在靠近活动地点的轻量级边缘设备(如手机、可穿戴设备和监控摄像头)上直接启用DL应用，则DL应用更有价值。低功耗物联网边缘设备可用于进行轻量级DL计算，从而避免与云通信，但仍需要面对有限的计算资源、内存占用和能源消耗。为了突破这些瓶颈，在[143]中，作者专注于ARM CortexM微控制器，并开发了CMSIS-NN，这是一组高效的NN内核。通过CMSIS-NN，可以最小化网络在ARM Cortex-M处理器核上的存储空间，从而可以将DL模型适配到物联网设备中，同时获得正常的性能和能效。</p>
<p>​ 针对在移动GPU上运行CNN层的瓶颈问题，DeepMon[164]对CNN层中使用的矩阵进行了分解，以加速高维矩阵之间的乘法运算。通过这种方式，CNN层中的高维矩阵运算(特别是乘法)可以在移动GPU中使用，并且可以加速。有鉴于此，已经部署在EDGE设备中的各种移动GPU可以通过特定的DL型号进行潜在的开发，并在启用EDGE DL方面发挥更重要的作用。</p>
<p>​ 除了DL推理[143]、[164]之外，在[168]中还讨论了影响移动CPU和GPU上DL训练性能的重要因素。由于常用的DL模型(例如VGG[169])对于主流边缘设备的存储器大小来说太大，因此采用相对较小的指导者网络[170]来评估DL训练。评估结果表明，DL模型的大小是影响训练性能的关键因素，移动CPU和GPU的有效融合对于加快训练过程具有重要意义。</p></li>
<li><p><strong>基于FPGA的解决方案：</strong>虽然GPU解决方案在云中被广泛用于DL训练和推理，但受边缘严格的功率和成本预算的限制，这些解决方案可能无法使用。此外，边缘节点应该能够同时服务于多个DL计算请求，这使得简单地使用轻量级CPU和GPU是不现实的。为此，本文研究了基于现场可编程门阵列(FPGA)的EDGE硬件实现EDGE DL的可行性。</p>
<p>​ 基于FPGA的边缘设备可以通过任意大小的卷积和可重新配置的池实现CNN加速[143]，在基于RNN的语音识别应用方面，它们比最先进的CPU和GPU实现更快[145]，同时实现更高的能效。在[52]中，开发了一个基于FPGA的EDGE平台的设计和设置，以允许DL计算从移动设备上卸载。在实现基于FPGA的边缘平台时，将无线路由器和FPGA板结合在一起。基于FPGA的EDGE平台以典型的视觉应用对该初步系统进行了测试，结果表明，与基于GPU(或CPU)的EDGE平台相比，基于FPGA的EDGE平台在能耗和硬件成本方面都具有优势。</p>
<p>​ 然而，如表IV所示，FPGA和GPU/CPU哪一个更适合于边缘计算仍有待确定。文献[171]中进行了详细的实验，以考察FPGA相对于GPU的优势：1)能够提供对工作负载不敏感的吞吐量；2)保证高并发DL计算的一致高性能；3)更高的能效。然而，FPGA的缺点在于在FPGA上开发高效的DL算法对大多数程序员来说并不熟悉。虽然像Xilinx SDSoC这样的工具可以大大降低难度[52]，但至少目前，要将针对GPU编程的最先进的DL模型移植到FPGA平台上，还需要做更多的工作。</p>
<figure>
<img src= "/img/loading.gif" data-lazy-src="/2021/04/11/Paper/%E8%BE%B9%E7%BC%98%E8%AE%A1%E7%AE%97%E4%B8%8E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9A%84%E8%9E%8D%E5%90%88/image-20210407132149249.png" alt="image-20210407132149249"><figcaption aria-hidden="true">image-20210407132149249</figcaption>
</figure></li>
</ol>
<h2 id="b.edge-dl的通信和计算方式">B.Edge DL的通信和计算方式</h2>
<p>虽然设备上的DL计算(如第五节所示)可以满足轻量级DL服务的需求。然而，独立的终端设备仍然无法承担密集的DL计算任务。边缘计算的概念可以通过将DL计算从终端设备卸载到边缘或(和)云来潜在地解决这一困境。伴随着边缘架构的出现，以DL为中心的边缘节点可以成为云计算基础设施处理海量DL任务的重要延伸。在本节中，我们对Edge DL计算的四种模式进行分类，如图16所示。</p>
<figure>
<img src= "/img/loading.gif" data-lazy-src="/2021/04/11/Paper/%E8%BE%B9%E7%BC%98%E8%AE%A1%E7%AE%97%E4%B8%8E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9A%84%E8%9E%8D%E5%90%88/image-20210408093616099.png" alt="image-20210408093616099"><figcaption aria-hidden="true">image-20210408093616099</figcaption>
</figure>
<figure>
<img src= "/img/loading.gif" data-lazy-src="/2021/04/11/Paper/%E8%BE%B9%E7%BC%98%E8%AE%A1%E7%AE%97%E4%B8%8E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9A%84%E8%9E%8D%E5%90%88/image-20210407132318809.png" alt="image-20210407132318809"><figcaption aria-hidden="true">image-20210407132318809</figcaption>
</figure>
<ol type="1">
<li><p><strong>整体卸载：</strong>DL计算卸载的最自然模式类似于现有的“端-云”计算，即终端设备将其计算请求发送到云以获取DL推理结果(如图16(A)所示)。这种卸载方法直接从DL任务分解和资源优化组合问题中解脱出来，可能会带来额外的计算代价和调度延迟，因此实现简单。[172]在中，建议的分布式基础设施DeepDecision将功能强大的边缘节点与功能较弱的终端设备捆绑在一起。在DeepDecision中，DL推理可以在末端或边缘执行，具体取决于推理准确性、推理延迟、DL模型大小、电池电量和网络条件之间的权衡。对于每个DL任务，终端设备决定是本地处理还是将其卸载到边缘节点。</p>
<p>​ 此外，在卸载问题中，边缘节点之间的负载优化不应被忽视，因为与云相比，边缘节点通常是资源受限的。为了满足在有限的边缘资源下完成DL任务的时延和能量需求，可以采用在边缘提供不同模型大小和性能的DL模型来完成一种任务。因此，可以在边缘节点上部署多个单独承担不同DL模型的虚拟机或容器来处理DL请求。具体地说，当复杂度较低的DL模型能够满足要求时，选择它作为服务模型。例如，通过优化虚拟机的工作负载分配权重和计算能力，MASM[173]可以在保证DL推理准确性的同时降低能量开销和延迟。</p></li>
<li><p><strong>部分卸载：</strong>将DL任务部分卸载到边缘也是可行的(如图16(B)所示)。可以开发卸载系统以实现DL任务的在线细粒度划分，并确定如何将这些划分的任务分配给终端设备和边缘节点。如文献[178]所示，MAUI能够自适应地划分通用计算机程序，在网络约束下，通过优化任务分配策略可以节省数量级的能量。更重要的是，该解决方案可以在运行时分解整个程序，而不是在程序部署之前手动划分程序员。</p>
<p>​ 此外，特别是对于DL计算，DeepWear[174]将DL模型抽象为有向无环图(DAG)，其中每个节点代表一个层，每条边代表那些层之间的数据流。为了有效地确定部分卸载决策，DeepWear首先通过仅保留计算密集型节点，然后对重复的子DAG进行分组来修剪DAG。以这种方式，可以将复杂的DAG转换成线性的且简单得多的DAG，从而实现用于选择要卸载的最佳分区的线性复杂性解决方案。</p>
<p>​ 然而，将DL模型的一部分上传到边缘节点仍可能严重延迟卸载DL计算的整个过程。为了应对这一挑战，在[175]中提出了一种增量式卸载系统IONN。与打包整个DL模型进行上传不同，IONN将准备上传的DL模型分成多个分区，依次上传到边缘节点。接收到分区模型的边缘节点在每个分区模型到达时递增地构建DL模型，同时甚至能够在上传整个DL模型之前执行卸载的部分DL计算。因此，关键在于确定DL模型的最佳分区和上传顺序。具体地说，一方面，优先上传性能收益高、上传开销低的DNN层，使得边缘节点快速构建部分DNN，达到最好的预期查询性能。另一方面，不会上载不会带来任何性能提升的不必要的DNN层，从而避免卸载。</p></li>
<li><p><strong>垂直协作：</strong>在VI-B1和VI-B2节中讨论的“端-边”体系结构之间的预期卸载策略对于支持计算密集度较低的DL服务和小规模并发DL查询是可行的。然而，当需要一次处理大量DL查询时，单个边缘节点肯定是不够的。</p>
<p>​ 协作的自然选择是，当DL任务被卸载时，EDGE执行数据预处理和初步学习。然后，将中间数据(即，边缘架构的输出)传输到云以进行进一步的DL计算[176]。然而，DNN的层次结构还可以进一步挖掘，以适应垂直协作。在[12]中，根据数据和计算特性在终端设备和边缘节点上分析DNN的所有层，以便生成性能预测模型。基于这些预测模型、无线条件和服务器负载水平，建议的神经外科医生根据端到端延迟或移动能耗来评估每个候选点，并将DNN划分为最佳的。然后，它决定DNN分区的分配，即在实现终端设备的最佳延迟和能耗的同时，将哪个部分部署在终端、边缘还是云上。</p>
<p>​ 通过利用EEOI(第V-C节)，可以更好地适应垂直协作。DNN的分区可以映射到分布式计算分层结构(即，末端、边缘和云)上，并且可以用多个早期出口点进行训练[161]。因此，端和边可以对自己执行一部分DL推理，而不是直接请求云。使用推断后的出口点，可以在不向云发送任何信息的情况下给出本地设备确信的DL任务的结果。为了提供更准确的DL推理，中间DNN输出将通过使用额外的DNN层发送到云中进行进一步推理。然而，中间输出(例如高分辨率监控视频流)应精心设计为比原始输入小得多，因此大大减少了终端和边缘(或边缘和云)之间所需的网络流量。</p>
<p>​ 虽然垂直协作可以被认为是云计算的一种演变，即“端-云”战略。与纯粹的“端-边”策略相比，垂直协作的过程可能会延迟，因为它需要与云进行额外的通信。然而，垂直协作有其自身的优势。一方面，当边缘体系结构本身无法承受DL查询的洪流时，云体系结构可以分担部分计算任务，从而确保服务于这些查询。另一方面，原始数据在传输到云之前必须在边缘进行预处理。如果这些操作可以大大减少中间数据的大小，从而减少网络流量，则可以缓解骨干网络的压力。</p></li>
<li><p><strong>横向协作：</strong>在第VI-B3节中，讨论了纵向协作。但是，边缘或终端之间的设备也可以在没有云的情况下统一起来，以处理需要资源的DL应用，即水平协作。通过这种方式，训练好的DNN模型或整个DL任务可以被分割并分配给多个终端设备或边缘节点，从而通过减轻每个终端设备或边缘节点的资源开销来加速DL计算。文献[177]中提出的MoDNN通过无线局域网(WLAN)在本地分布式移动计算系统中执行DL。DNN的每一层都被划分成片，以提高并行度和减少内存占用，并且这些片是逐层执行的。通过多个终端设备之间的执行并行性，可以显著加速DL计算。</p>
<p>​ 关于特定的DNN结构，例如CNN，可以应用更精细的网格划分来最小化通信、同步和存储器开销[130]。在[156]中，提出了一种融合瓦片划分(FTP)方法，能够将每个CNN层划分成可独立分配的任务。与[12]中仅按层分区DNN不同，FTP可以融合各层并以网格方式垂直分区，从而最大限度地减少参与的边缘设备所需的内存占用，而不考虑分区和设备的数量，同时还降低了通信和任务迁移成本。此外，为了支持FTP，分布式工作窃取运行时系统，即空闲边缘设备从具有活动工作项的其他设备窃取任务[156]，可以自适应地分配FTP分区以平衡协作边缘设备的工作负载。</p></li>
</ol>
<h2 id="c.为dl定制edge框架">C.为DL定制Edge框架</h2>
<p>虽然DL所需的计算复杂度和能效与EDGE硬件的容量之间存在差距[179]，但定制的EDGE DL框架可以帮助高效地1)匹配EDGE平台和DL模型；2)在性能和功率方面开发底层硬件；3)自动协调和维护DL服务。</p>
<p>首先，应该确定在边缘计算(蜂窝)网络中在哪里部署DL服务。在[180]中引入了部署在边缘节点的RAN控制器来收集数据并运行DL服务，而放置在云中的网络控制器协调RAN控制器的操作。这样，在运行分析并将相关指标提取到DL模型之后，这些控制器可以向网络边缘的用户提供DL服务。</p>
<p>第二，由于DL模型的部署环境和需求可能与模型开发过程中的部署环境和需求有很大的不同，所以在使用(Py)Torch、TensorFlow等开发DL模型时采用的自定义运算符可能不会直接与边缘的DL框架一起执行。为了弥合部署和开发之间的差距，[181]的作者建议使用部署工具和部署在边缘的DL框架中的操作员库来指定开发中的DL模型。此外，为了自动化DL模型的选择和优化，ALOHA[182]制定了一个工具流：1)自动化模型设计。它综合考虑目标任务、约束集和目标体系结构，生成最优的模型配置；2)优化模型配置。它划分DL模型，并相应地生成不同推理任务和可用资源之间的体系结构感知映射信息。3)模型移植自动化。它将映射信息转换为对目标体系结构公开的计算和通信原语的适当调用。</p>
<p>第三，应该解决部署在边缘的DL模型的协调问题。OpenEI[183]将每个DL算法定义为一个四元组&lt;Accuracy，Latency，Energy，Memory Footprint&gt;，以评估目标硬件平台的Edge DL能力。基于这样的元组，OpenEI可以在线的方式根据不同的Edge DL能力为特定的Edge平台选择匹配的模型。ZOO[184]提供了一种简明的领域特定语言(DSL)，以支持简单且类型安全的DL服务组合。此外，为了支持广泛的地理分布拓扑、分析引擎和DL服务，ECO[185]使用了基于图形的覆盖网络方法来1)对管道和依赖项进行建模和跟踪，然后2)将它们映射到从小型基于边的引擎到强大的基于云的多节点引擎等各种地理上分布的分析引擎。通过这种方式，DL计算可以根据需要进行分布，以管理成本和性能，同时还支持其他实际情况，如发动机异构性和不连续操作。</p>
<p>然而，这些开创性的工作还没有准备好从本质上支持第VI-B节中讨论的有价值的和具有挑战性的功能，如计算卸载和协作，这些功能仍然需要进一步开发。</p>
<h2 id="d.edge-dl的性能评估">D.Edge DL的性能评估</h2>
<p>在选择合适的边缘硬件和相关软件堆栈以部署不同类型的边缘DL服务的整个过程中，有必要对其性能进行评估。公正的评估方法可以指出针对特定边缘硬件优化软件堆栈的可能方向。[186]在[186]中，首次通过在资源受限的边缘设备上执行DL推断来评估DL库的性能，这些推断与延迟、内存占用和能量等指标有关。此外，特别是Android智能手机，作为一种配备移动CPU或GPU的边缘设备，AI Benchmark[54]广泛评估了各种设备配置上的DL计算能力。实验结果表明，没有一个单独的DL库或硬件平台能够完全超越其他库或硬件平台，并且DL模型的加载可能比执行它所需的时间更长。这些发现意味着仍然有进一步优化EDGE硬件、EDGE软件堆栈和DL库融合的机会。</p>
<p>然而，目前还没有针对Edge DL的标准试验床，这阻碍了对Edge体系结构的研究。要评估Edge DL服务的端到端性能，不仅需要建立边缘计算架构，还需要建立其与终端设备和云的组合，例如OpenLEON[187]和CA VBENCH[188]，特别是针对车载场景。此外，对管理DL服务的控制面板的模拟仍未涉足。一个由无线链路和网络模型、服务请求模拟、边缘计算平台、云计算架构等组成的综合试验台，对于推动“数字图书馆边缘计算”的发展具有重要意义。</p>
<h1 id="七-边缘深度学习训练">七 边缘深度学习训练</h1>
<p>目前云数据中心的DL训练(分布式或非分布式)，即云训练或云边训练[50]，即训练数据在边缘进行预处理，然后传输到云端，并不适用于所有的DL业务，特别是对于需要局部性和持续性训练的DL模型。此外，如果需要将大量数据从分布式终端设备或边缘节点持续传输到云端，将消耗大量的通信资源，从而加剧无线和骨干网络。例如，对于集成了目标检测和目标跟踪的监控应用，如果终端设备直接将海量实时监控数据发送到云端进行持续训练，将会带来高昂的组网成本。此外，将所有数据合并到云中可能会违反隐私问题。所有这些挑战都提出了针对现有云培训的新培训方案的需求。</p>
<p>自然，由大量计算资源有限的边缘节点组成的边缘体系结构可以通过自身的数据处理或训练来满足缓解网络压力的需要。边缘训练或潜在的“端-边-云”训练，将边缘作为训练的核心架构，称为“边缘DL训练”。这种DL训练可能需要大量资源来消化分布式数据和交换更新。尽管如此，FL正在崛起，并被承诺要解决这些问题。我们在表VI中总结了精选的关于外语的研究成果。</p>
<h2 id="a.edge的分布式训练">A.Edge的分布式训练</h2>
<p>边缘的分布式训练可以追溯到[189]的工作，其中提出了一种用于边缘计算网络的分散随机梯度下降(SGD)方法来解决大型线性回归问题。然而，这种方法是为地震成像应用而设计的，不能推广到未来的DL训练中，因为训练大规模DL模型的通信成本非常高。[190]在这篇文章中，针对边缘计算环境提出了两种不同的分布式学习方案。如图17所示，一种解决方案是每个终端设备基于本地数据训练模型，然后在边缘节点聚集这些模型更新。另一种是边缘节点训练自己的局部模型，通过交换和细化模型更新来构建全局模型。虽然大规模的边缘分布式训练避免了将庞大的原始数据集传输到云中，但不可避免地引入了边缘设备之间梯度交换的通信开销。此外，在实际应用中，EDGE设备可能会遭受较高的时延、较低的传输速率和间歇性连接，从而进一步阻碍了属于不同EDGE设备的DL模型之间的梯度交换。</p>
<figure>
<img src= "/img/loading.gif" data-lazy-src="/2021/04/11/Paper/%E8%BE%B9%E7%BC%98%E8%AE%A1%E7%AE%97%E4%B8%8E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9A%84%E8%9E%8D%E5%90%88/image-20210407140529450.png" alt="image-20210407140529450"><figcaption aria-hidden="true">image-20210407140529450</figcaption>
</figure>
<p>大多数梯度交换是冗余的，因此可以压缩更新的梯度以在保持训练精度的同时降低通信成本(例如[191]中的DGC)。首先，DGC规定只交换重要的梯度，即只传输大于启发式给定阈值的梯度。为了避免信息丢失，其余的梯度被局部累加，直到超过阈值。需要注意的是，无论是立即发送的梯度还是为稍后交换积累的梯度都将被编码和压缩，从而节省了通信成本。其次，考虑到梯度的稀疏更新可能会影响DL训练的收敛，采用动量校正和局部梯度裁剪的方法来降低潜在风险。通过动量校正，稀疏更新可以近似等价于密集更新。在将当前梯度局部添加到每个边缘设备上的先前累加之前，执行梯度裁剪，以避免梯度累加可能引入的爆炸性梯度问题。当然，由于部分梯度被延迟更新，这可能会减慢收敛速度。因此，为了防止陈旧的动量危害训练性能，在训练开始时，停止延迟梯度的动量，并采用不那么激进的学习率和梯度稀疏性，以减少延迟的极值梯度的数量。</p>
<p>出于降低分布式训练期间同步梯度和参数的通信成本的相同目的，可以将两种机制组合在一起[192]。第一种是通过利用稀疏训练梯度来仅传输重要的梯度[193]。保持隐含权值以记录梯度坐标参与梯度同步的次数，隐含权值大的梯度坐标被认为是重要的梯度，更有可能在下一轮训练中被选择。另一方面，如果直接忽略残差梯度坐标(即不太重要的梯度)，则训练收敛会受到很大的损害，因此在每轮训练中都会积累较小的梯度值。然后，为了避免这些过时的梯度对训练的影响很小，采用动量校正，即设置一个折现因子来校正残差梯度积累。</p>
<p>具体地，当训练大的DL模型时，交换相应的模型更新可能会消耗更多的资源。使用KD的在线版本可以降低此类通信成本[194]。换句话说，模型输出而不是每个设备上更新的模型参数被交换，使得大型本地模型的训练成为可能。除了通信成本，隐私问题也应该被关注。例如，在[195]中，通过利用训练分类器的隐私泄露，可以从训练数据中有目的地获得个人信息。文献[196]研究了边缘训练数据集的隐私保护问题。与[190]-[192]不同，在[196]场景中，训练数据在边缘节点进行训练，并上传到云端进行进一步的数据分析。因此，拉普拉斯噪声[197]被添加到这些可能暴露的训练数据以增强训练数据隐私保证。</p>
<figure>
<img src= "/img/loading.gif" data-lazy-src="/2021/04/11/Paper/%E8%BE%B9%E7%BC%98%E8%AE%A1%E7%AE%97%E4%B8%8E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9A%84%E8%9E%8D%E5%90%88/image-20210408093648926.png" alt="image-20210408093648926"><figcaption aria-hidden="true">image-20210408093648926</figcaption>
</figure>
<h2 id="b.边缘的联合学习">B.边缘的联合学习</h2>
<p>在第七节中，整体网络体系结构被明确地分开，具体地说，训练被限制在终端设备或独立的边缘节点，而不是在它们之间。当然，通过这种方式，编排培训过程很简单，因为不需要处理终端和边缘之间的异构计算能力和网络环境。尽管如此，描述语言训练应该和描述语言推理一样无处不在。联合学习(FL) [198]，[199]作为端、边、云之间的一种实用的DL训练机制应运而生。虽然是在原生外语的框架下，但现代移动设备是作为客户端进行本地培训的。自然，这些设备可以在边缘计算[200]，[201]中得到更广泛的扩展。云中的终端设备、边缘节点和服务器可以等效地视为FL中的客户端。这些客户被假定能够处理不同级别的DL培训任务，并因此将他们的更新贡献给全局DL模型。在这一节中，将讨论外语的基础知识。</p>
<p>在不需要上传数据进行中心云训练的情况下，FL [198]、[199]可以允许边缘设备用自己收集的数据训练本地DL模型，而只上传更新的模型。如图18所示，FL迭代地请求一组随机的边缘设备1)从聚合服务器下载全局DL模型(在下文中使用“服务器”)，2)用它们自己的数据在下载的全局模型上训练它们的本地模型，以及3)仅将更新的模型上传到服务器用于模型平均。通过将训练数据仅限制在设备端，可以显著降低隐私和安全风险，从而避免了[195]中因将训练数据上传到云中而引起的隐私问题。此外，FL引入了联合平均，将每个设备上的本地SGD与执行模型平均的服务器相结合。实验结果证实了联邦平均法对不平衡和非IID数据是稳健的，并且可以促进训练过程，即。，减少了培训DL模型所需的沟通次数。</p>
<figure>
<img src= "/img/loading.gif" data-lazy-src="/2021/04/11/Paper/%E8%BE%B9%E7%BC%98%E8%AE%A1%E7%AE%97%E4%B8%8E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9A%84%E8%9E%8D%E5%90%88/image-20210407140459305.png" alt="image-20210407140459305"><figcaption aria-hidden="true">image-20210407140459305</figcaption>
</figure>
<p>综上所述，FL可以应对边缘计算网络中的几个关键挑战:1)非IID训练数据。每个设备上的训练数据都是自己感知和收集的。因此，设备的任何单个训练数据都不能代表全局数据。在佛罗里达，这可以通过联邦平均来实现；2)沟通有限。设备可能离线或位于不良的通信环境中。然而，在资源充足的设备上执行更多的训练计算可以减少全局模型训练所需的通信回合。此外，FL只选择一部分设备一轮上传更新，成功处理了设备不可预测离线的情况；3)贡献不平衡。这可以通过联合平均来解决，具体来说，一些设备可能具有较少的自由资源用于FL，导致设备之间的训练数据量和训练能力不同；4)隐私和安全。FL需要上传的数据只是更新后的DL模型。此外，安全聚合和差异隐私[197]，这有助于避免泄露包含在本地更新中的隐私敏感数据，可以自然地应用。</p>
<h2 id="c.通信有效的fl">C.通信有效的FL</h2>
<p>在FL中，不需要上传原始培训数据，从而在很大程度上降低了通信成本。但是，FL仍然需要将本地更新的模型传输到中央服务器。假设DL模型尺寸足够大，从边缘设备到中央服务器的更新（例如模型权重）也可能也可能消耗非资格的通信资源。为满足这一点，我们可以让FL客户定期与中央服务器（相当不断）与中央服务器进行通信，以寻求共享DL模型的共识[202]。此外，结构化更新，速写更新可以帮助提高客户端的更新到服务器时提高通信效率。结构化更新装置限制模型更新以具有预先指定的结构，具体地，1）低秩矩阵;或2）稀疏矩阵[202]，[203]。另一方面，对于速写更新，维护完整的模型更新。但是在上传它们进行模型聚合之前，执行分配，概率量化和结构化随机旋转的组合操作以压缩完整更新[203]。 FEDPAQ [204]同时结合这些特征，并为两种强度凸起和非凸损函数提供近乎最佳的理论保证，同时凭经验展示通信计算权衡。</p>
<p>仅考虑到上行链路上降低通信成本的缩短通信成本（下行）和服务器到服务器（上行链路）通信的不同。对于下行链路，将全局DL模型的权重被重新装入向量中，然后应用分配和量化[203]。当然，这种类型的模型压缩是有损的，并且与上行链路不同（多个边缘设备上传其平均模型），通过在下行链路上平均来减轻损耗。在将kashin的表示[206]中可以使用，作为基础变换以减轻随后的压缩操作产生的错误。此外，对于上行链路，每个边缘设备不需要基于本地全局模型训练模型，而是仅培训较小的子模型或修剪模型[207]。由于子模型和修剪模型比全局模型更轻，因此更新上载中的数据量减少了。</p>
<p>与云相比，边缘设备的计算资源是稀缺的。应考虑提高通信效率的额外挑战：1）计算资源是异构的和限制在边缘器件; 2）边缘设备的训练数据可以分布不均匀[208] - [210]。对于更强大的边缘设备，ADSP [211]让他们在以战略决定间隔进行模型聚合的同时继续培训。对于一般情况，基于使用非IID数据分布的分布式学习的推导的收敛，所有参与设备之间的给定资源预算下的聚合频率可以通过理论保证优化[208]。 Astraea [212]通过设计基于Mediator的多客户重新安排策略来降低92％的通信流量。一方面，Astraea利用数据增强[5]来缓解非统一分布式培训数据的缺陷。另一方面，Astraea设计了一种贪婪的基于中介的重新安排策略，以便为调解员分配客户。每个介体都遍历所有未分配客户端的数据分布，以选择适当的参与客户端，旨在使Mediator的数据分布最接近均匀分布，即，最小化介质数据分布与均匀分布之间的Kullbackleibler分解[213]。当中间器达到最大分配的客户端限制时，中央服务器将创建一个新的中介并重复该过程，直到所有客户端都分配培训任务。</p>
<p>旨在加速FL的全球聚集，[214]利用过空气计算[215] - [217]，其中原理是探索无线多址通道的叠加特性以计算所需的通过多边设备的并发传输功能。可以利用无线信道的干扰，而不是仅仅克服它们。在传输期间，来自边缘设备的并发模拟信号可以通过信道系数自然地称重。然后，服务器只需要将这些重新绘制的权重叠加为聚合结果，仍然没有其他聚合操作。</p>
<h2 id="d.资源优化fl">D.资源优化FL</h2>
<p>当FL将相同的神经网络模型部署到异构边缘设备时，计算功率弱（踩踏器）的设备可能大大延迟全局模型聚合。虽然可以优化训练模型以加速陷阱器，但由于异构设备的资源有限，优化的模型通常导致分叉结构并严重缺陷协作会聚。 Elfish [218]首先在时间成本，内存使用情况和计算工作负载方面分析模型训练的计算消耗。在模型分析的指导下，需要在每层中掩盖哪些神经元以确保可以确定模型训练的计算消耗满足特定的资源约束。其次，与发散的结构产生的确定系统优化模型不同，在每个训练期间将在每个训练周期中动态掩蔽不同的神经元并在随后的聚合期间恢复和更新，从而确保了全面的模型更新加班。值得注意的是，尽管通过资源优化将Elfish提高了2次的训练速度，但Elfish的想法是使所有陷阱器同步地工作，其同步聚合可能无法处理极端情况。</p>
<p>当FL部署在移动边缘计算场景中时，FL的壁钟时间将主要取决于客户端的数量及其计算能力。具体地，FL的总壁时钟时间不仅包括计算时间，还包括所有客户端的通信时间。一方面，客户端的计算时间取决于客户端和本地数据大小的计算能力。另一方面，通信时间与客户端的频道增益，传输功率和本地数据大小相关联。因此，为了最小化FL的壁时钟训练时间，FL的适当资源分配需要考虑不仅考虑计算 - 通信权衡的精度水平，还需要在客户端进行资源分配，如电源和CPU周期。</p>
<p>然而，最小化客户端的能量消耗和FL壁钟时间是冲突的。例如，客户可以通过始终以低频维持其CPU来节省能源，但这绝对会增加培训时间。因此，为了在能量成本和培训时间之间取得平衡，[219]的作者首先设计一个新的FL算法FEDL，为每个客户端才能解决其局部问题大致直到达到局部精度水平。然后，通过使用Pareto效率模型[224]，它们为FEDL的无线网络制定了非透露资源分配问题，以捕获客户的能源成本与FL壁钟时间之间的权衡。最后，通过利用该问题的特殊结构，它们将其分解为三个子问题，因此导出闭合形式解决方案，并表征静态控制旋钮对最佳的影响。</p>
<p>由于用于传输模型更新的上行链路带宽是有限的，因此BS必须优化其资源分配，而用户必须优化其发射功率分配以减少每个用户的分组错误率，从而提高流程。为此，[220]的作者将资源分配和用户选择配制到联合优化问题，其目标是最小化遇到延迟和能量消耗要求的同时降低流失功能的值。为了解决这个问题，他们首先导出了FL的预期收敛速率的闭合表达式，以便在分组误差率和流性能之间建立明确的关系。基于这种关系，可以将优化问题减少到混合整数非线性编程问题，然后解决如下：首先，在给定的用户选择和资源块分配下找到最佳发射功率;然后，将原始优化问题转换为二进制匹配问题;最后，使用匈牙利算法[225]找到最佳的用户选择和资源块分配策略。</p>
<p>FL的设备数量通常很大，从数百到数百万。只需最小化这种大型网络中的平均损失可能不适合某些设备上所需的模型性能。事实上，虽然香草FL下的平均精度很高，但不保证各个设备所需的模型精度。为此，基于本实用函数α - 公平[226]在无线网络中使用的公平资源分配，[221]的作者定义了一个面向公平的目标Q-FFL，用于联合资源优化。 Q-FFL最小化Q参数化的聚合重新加权损失，使得具有较高损耗的设备具有更高的相对重量，从而在准确性分布中令人鼓舞的方差越差（即，更公平）。自适应地最小化Q-FFL避免了手工制作的公平限制的负担，并且可以根据所需的公平动态调整目标，从而实现降低参与设备之间的准确性分布方差的效果。</p>
<h2 id="e.增强安全性的fl">E.增强安全性的FL</h2>
<p>在普通FL中，本地数据样本在每个边缘设备上进行处理。这种方式可以防止设备向服务器泄露私有数据。但是，服务器也不应该完全信任边缘设备，因为行为异常的设备可能会伪造或毒化它们的训练数据，从而导致毫无价值的模型更新，从而损害全局模型。为了使FL能够容忍少量设备在有毒数据集上进行训练，稳健的联合优化[201]定义了修剪的均值操作。通过过滤掉中毒设备产生的值和正常设备中的自然异常值，实现了保护全局模型免受数据中毒的稳健聚合。</p>
<p>除了蓄意攻击之外，不可预测的网络条件和计算能力给安全带来的消极负面影响也值得关注。FL必须对边缘设备的意外掉线保持健壮性，否则一旦设备断开连接，FL的一轮同步将会失败。为了解决这一问题，在[222]中提出了安全聚合协议，以实现对多达三分之一的设备无法及时处理本地训练或上传更新的健壮性。</p>
<p>反过来，FL中聚合服务器的故障可能导致不准确的全局模型更新，从而扭曲所有本地模型更新。此外，边缘设备(具有较大数量的数据样本)可能不太愿意与其他设备一起参与FL(贡献较小)。因此，在[223]中提出将BlockChain和FL结合作为BlockFL来实现：1)在每个边缘设备而不是特定的服务器上实现局部全局模型更新，确保设备故障在更新全局模型时不影响其他局部更新；2)适当的奖励机制来激励边缘设备参与FL。</p>
<h1 id="八-优化edge的深度学习">八 优化EDGE的深度学习</h1>
<p>DNN(一般DL模型)可以提取潜在的数据特征，而DRL可以通过与环境的交互来学习处理决策问题。边缘节点的计算和存储能力，以及云的协作，使得使用DL优化边缘计算网络和系统成为可能。对于边缘缓存、卸载、通信、安全保护等各种边缘管理问题，1)DNN可以处理网络中的用户信息和数据度量，感知无线环境和边缘节点的状态；2)基于这些信息，可以应用DRL来学习长期最优的资源管理和任务调度策略，从而实现对边缘的智能管理，即表VII所示的智能边缘。</p>
<h2 id="a.自适应边缘缓存的dl">A.自适应边缘缓存的DL</h2>
<p>从内容交付网络（CDN）[227]在蜂窝网络中缓存内容，多年来已经调查了网络中的缓存，以处理对多媒体服务的飙升的需求[228]。与推动用户附近的内容的概念对齐，边缘缓存[229]被认为是进一步减少冗余数据传输的有希望的解决方案，缓解云数据中心的压力并改善QoE。</p>
<p>边缘缓存面临两个挑战：1)边缘节点覆盖范围内的内容热度分布很难估计，因为它可能是不同的，并且随时空变化而变化[230]；2)针对边缘计算环境中的海量异构设备，层次化的缓存体系结构和复杂的网络特性进一步困扰了内容缓存策略的设计[231]。具体地说，只有在已知内容热度分布的情况下，才能推导出最优的边缘缓存策略。然而，用户对内容的偏好实际上是未知的，因为他们的移动性、个人偏好和连接性可能一直在变化。在本节中，将讨论用于确定边缘缓存策略的DL，如图19所示。</p>
<figure>
<img src= "/img/loading.gif" data-lazy-src="/2021/04/11/Paper/%E8%BE%B9%E7%BC%98%E8%AE%A1%E7%AE%97%E4%B8%8E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9A%84%E8%9E%8D%E5%90%88/image-20210407133956736.png" alt="image-20210407133956736"><figcaption aria-hidden="true">image-20210407133956736</figcaption>
</figure>
<ol type="1">
<li><p><strong>DNNS的使用案例：</strong>传统的缓存方法通常计算复杂度很高，因为它们需要大量的在线优化迭代来确定1)用户和内容的特征，2)内容放置和交付的策略。</p>
<p>​ 对于第一个目的，DL可以用于处理从用户的移动设备收集的原始数据，从而提取用户和内容的特征作为基于特征的内容热度矩阵。通过这种方式，通过将基于特征的协作过滤应用于流行度矩阵来估计核心网络处的流行度内容[232]。</p>
<p>​ 对于第二个目的，在使用DNNs优化边缘缓存策略时，可以通过离线训练来避免在线繁重的计算迭代。由用于数据正则化的编码器和随后的隐藏层组成的DNN可以用由最优或启发式算法生成的解来训练，并被部署以确定高速缓存策略[233]，从而避免在线优化迭代。类似地，在[234]中，受关于部分缓存刷新的优化问题的输出具有一定模式的启发，训练MLP接受当前内容热度和最后的内容放置概率作为输入，以生成缓存刷新策略。</p>
<p>​ 如文献[233]、[234]所示，优化算法的复杂性可以转移到DNN的训练上，从而突破了实际应用的限制。在这种情况下，DL用于学习输入-解关系，而基于DNN的方法只有在存在原始缓存问题的优化算法时才可用。因此，基于DNN的方法的性能受限于固定的优化算法，并且不是自适应的。</p>
<p>​ 此外，DL还可用于定制边缘缓存。例如，为了最小化自动驾驶汽车中的内容下载延迟，在云中部署MLP来预测要请求的内容的热度，然后将MLP的输出传送到边缘节点(即在[235]中的RSU的MEC服务器)。根据这些输出，每个边缘节点缓存最有可能被请求的内容。在自动驾驶汽车方面，CNN被用来预测车主的年龄和性别。一旦识别了所有者的这些特征，就使用k-均值聚类[236]和二进制分类算法来确定哪些已经缓存在边缘节点中的内容应该进一步从边缘节点下载和缓存到CAR。此外，关于充分利用用户的特点，[237]指出，用户在不同的环境中访问内容的意愿是不同的。受此启发，RNN被用来预测用户的轨迹。然后基于这些预测，在每个预测位置的边缘节点预取并缓存用户兴趣的所有内容。</p></li>
<li><p><strong>DRL用例：</strong>第VIII-A1节中描述的DNN的功能可以视为整个边缘缓存解决方案的一部分，即DNN本身并不处理整个优化问题。与这些基于DNN的边缘缓存不同的是，DRL能够充分利用用户和网络的上下文，并以最大化长期缓存性能的自适应策略[238]作为优化方法的主体。传统的RL算法受到手工特征要求的限制，以及难以处理高维观测数据和动作的缺陷[239]。与传统的与DL无关的RL(如Q学习[240]和多臂Bandit(MAB)学习[230])相比，DRL的优势在于DNN可以从原始观测数据中学习关键特征。结合RL和DL的集成DRL代理可以直接从高维观测数据优化其在边缘计算网络中的缓存管理策略。</p>
<p>​ [241]DDPG用于训练DRL代理，以最大化长期缓存命中率，从而做出正确的缓存替换决策。这项工作考虑了具有单个BS的场景，其中DRL代理决定是缓存所请求的内容还是替换缓存的内容。在训练DRL代理时，奖励被设计为缓存命中率。此外，利用Wolpertinger体系结构[242]来应对大动作空间的挑战。具体地，首先为DRL代理设置主要动作集合，然后使用KNN将实际动作输入映射到该集合中的一个。以这种方式，动作空间被有意地缩小，而不会错过最佳的缓存策略。与基于DQL搜索整个动作空间的算法相比，采用DDPG和Wolpertinger结构的训练好的DRL代理能够在减少运行时间的同时获得具有竞争力的缓存命中率。</p>
<figure>
<img src= "/img/loading.gif" data-lazy-src="/2021/04/11/Paper/%E8%BE%B9%E7%BC%98%E8%AE%A1%E7%AE%97%E4%B8%8E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9A%84%E8%9E%8D%E5%90%88/image-20210408093717009.png" alt="image-20210408093717009"><figcaption aria-hidden="true">image-20210408093717009</figcaption>
</figure></li>
</ol>
<h2 id="b.用于优化边缘任务卸载的dl">B.用于优化边缘任务卸载的DL</h2>
<p>边缘计算允许边缘设备在能量、延迟、计算能力等约束下将其计算任务的一部分卸载到边缘节点[243]。如图20所示，这些约束提出了识别1)哪些边缘节点应该接收任务、2)边缘设备应该卸载多大比例的任务以及3)应该为这些任务分配多少资源的挑战。要解决这类任务卸载问题是NP-hard[244]，因为至少需要通信和计算资源的组合优化以及边缘设备的争用。特别地，优化既要考虑时变的无线环境(如变化的信道质量)，又要考虑任务卸载的要求，因此要注意使用学习方法[245]-[255]。在所有与基于学习的优化方法相关的工作中，当多个边缘节点和无线信道可用于计算卸载时，基于DL的方法比其他方法更具优势。在这种背景下，整个卸载问题中状态空间和动作空间较大，使得传统的学习算法[245]、[256]、[247]实际上都不可行。</p>
<figure>
<img src= "/img/loading.gif" data-lazy-src="/2021/04/11/Paper/%E8%BE%B9%E7%BC%98%E8%AE%A1%E7%AE%97%E4%B8%8E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9A%84%E8%9E%8D%E5%90%88/image-20210407134252750.png" alt="image-20210407134252750"><figcaption aria-hidden="true">image-20210407134252750</figcaption>
</figure>
<ol type="1">
<li><p><strong>DNNs的用例：</strong>在[249]中，计算卸载问题被描述为一个多标签分类问题。通过离线穷举搜索，得到的最优解可以用来训练以边缘计算网络的组合状态为输入、卸载决策为输出的DNN。通过这种方法，不需要在线求解最优解，避免了迟来的卸货决策，并且可以将计算复杂度转移到DL训练上。</p>
<p>​ 此外，在[252]中研究了关于区块链的特定卸载场景。边缘设备上挖掘任务的计算和能源消耗可能会限制区块链在边缘计算网络中的实际应用。当然，这些挖掘任务可以从边缘设备卸载到边缘节点，但这可能会导致边缘资源分配不公平。因此，所有可用的资源都以拍卖的形式进行分配，以最大化边缘计算服务提供商(ECSP)的收入。基于最优拍卖的解析解，可以构建[252]MLP，并用矿工(即边缘设备)的估值进行训练，以最大化ECSP的预期收入。</p></li>
<li><p><strong>DRL的使用案例：</strong>虽然将计算任务卸载到边缘节点可以提高计算任务的处理效率，但卸载的可靠性受到无线环境质量可能较低的影响。[248]为了使卸载效用最大化，作者首先量化了各种通信方式对任务卸载性能的影响，并据此提出应用DQL在线选择最优的目标边缘节点和传输方式。为了优化总卸载成本，修改Duling-and Double-DQL[263]的DRL代理可以为终端设备分配边缘计算和带宽资源。</p>
<p>​ 此外，卸载可靠性也是值得关注的问题。传输数据的编码率对于使卸载达到所需的可靠性水平至关重要。因此，在[250]中，为了提高平均卸载可靠性，研究了编码块长度的影响，并提出了一个关于资源分配的MDP，然后用DQL进行求解。在[257]中，DoubleDQL[89]对边缘设备的细粒度计算资源调度进行了进一步的探索，目的是确定最佳的动态电压和频率缩放(DVFS)算法。实验结果表明，与DQL相比，双DQL可以节省更多的能量，达到更高的训练效率。然而，随着边缘设备的增加，基于DQL的方法的动作空间可能会迅速增加。在这种情况下，可以在学习[253]之前执行预分类步骤以缩小动作空间。</p>
<p>​ 由能量收集(EH)提供动力的物联网边缘环境在[251]、[254]中进行了研究。在EH环境中，能量收集使卸载问题变得更加复杂，因为物联网边缘设备可以从周围的射频信号中收集能量。因此，CNN被用来压缩学习过程中的状态空间[254]。此外，在文献[251]中，受奖励函数加性结构的启发，将Q函数分解应用于双DQL，改进了普通双DQL。然而，基于值的DRL只能处理离散动作空间。为了对本地执行和任务卸载执行更细粒度的功率控制，应该考虑基于策略梯度的DRL。例如，与基于DQL的离散功率控制策略相比，DDPG能够以更细的粒度自适应地分配边缘设备的功率[255]。</p>
<p>​ 随意让DRL代理接管整个计算卸载过程可能会导致巨大的计算复杂度。因此，只有采用DNN进行部分决策，才能大大降低复杂度。例如，在[258]中，最大化加权和计算率的问题被分解为两个子问题，即卸载决策和资源分配。通过只使用DRL来处理NP-Hard卸载决策问题，而不是同时使用DRL和DRL，既缩小了DRL代理的动作空间，又不影响卸载性能，因为资源分配问题得到了最优解决。</p></li>
</ol>
<h2 id="c.用于边缘管理和维护的dl">C.用于边缘管理和维护的DL</h2>
<p>EDGE DL服务设想部署在蜂窝网络中的BSS上，如[264]中实施的那样。因此，边缘管理和维护需要从多个角度(包括沟通角度)进行优化。许多工作都集中在将下行链路应用于无线通信[265]-[267]。然而，边缘的管理和维护应该考虑更多的方面。</p>
<ol type="1">
<li><p><strong>边缘通信：</strong>当边缘节点服务于移动设备(用户)时，边缘计算网络中的移动性问题应该得到解决。基于DL的方法可用于辅助设备和边缘节点之间的连接的平滑过渡。为了最小化每比特的能量消耗，在[268]中，用DNN近似最优设备关联策略。同时，在中心服务器上建立网络环境的数字孪生节点，对该DNN进行离线训练。为了最小化移动设备在其整个移动轨迹中从边缘节点移动到下一个边缘节点的中断，可以使用MLP来预测给定位置和时间处的可用边缘节点[259]。此外，确定移动设备应该与之关联的最佳边缘节点仍然需要评估移动设备与每个边缘节点之间的交互的成本(服务请求的等待时间)。尽管如此，对这些交互的成本进行建模需要一个功能更强大的学习模型。因此，实现了一个带有LSTM单元的两层堆叠RNN，用于建模交互成本。最后，基于预测可用边缘节点的能力和相应的潜在代价，移动设备可以关联到最好的边缘节点，从而将中断的可能性降至最低。</p>
<p>​ 在具有多种模式(服务于各种物联网服务)的通信场景中，即云无线接入网络(CRAN)模式、设备到设备(D2D)模式和雾无线接入点(FAP)模式，以最小化长期系统功耗为目标，DQL可用于控制边缘设备的通信模式和整个通信过程中处理器的开关状态[260]。在确定给定边缘设备的通信模式和处理器的ON-OFF状态后，整个问题可以降级为远程无线头部(RRH)发射功率最小化问题并得到解决。此外，TL与DQL集成在一起，以减少DQL培训过程中所需的与环境的交互，同时在没有TL的情况下保持类似的性能。</p></li>
<li><p><strong>边缘安全：</strong>由于边缘设备的计算、能量和无线资源一般有限，与云计算相比，边缘设备与边缘节点之间的传输更容易受到各种攻击，如干扰攻击、分布式拒绝服务(DDoS)攻击等。因此，需要提高边缘计算系统的安全性。首先，系统应该能够主动检测未知攻击，例如，使用DL技术提取窃听和干扰攻击的特征[269]。系统根据检测到的攻击模式确定安全防护策略。当然，安全保护通常需要额外的能源消耗以及计算和通信开销。因此，每个边缘设备都应该在不违反其资源限制的情况下优化其防御策略，即选择发射功率、信道和时间。由于边缘计算网络的攻击模型和动态模型很难估计，因此优化是具有挑战性的。</p>
<p>​ 基于DRL的安全解决方案可以提供安全卸载(从边缘设备到边缘节点)以抵御干扰攻击[261]或保护用户位置隐私和使用模式隐私[270]。边缘设备通过观察边缘节点的状态和攻击特征，确定安全协议中的防御级别和关键参数。通过将奖励设置为抗干扰通信效率，如信号的信干噪比、接收消息的误码率和保护开销，可以训练基于DQL的安全代理来应对各种类型的攻击。</p></li>
<li><p><strong>联合边缘优化：</strong>边缘计算可以满足智能设备的快速增长以及大量计算密集型和数据消耗型应用的出现。尽管如此，它也使未来网络的运营变得更加复杂[271]。管理复杂网络的综合资源优化[16]是具有挑战性的，特别是在考虑未来网络的关键推动因素的前提下，包括软件定义网络(SDN)[272]、物联网(IoTS)、车联网(IOVS)。</p>
<p>​ 通常，SDN的设计目的是将控制平面与数据平面分离，从而允许在整个网络上以全局视图进行操作。与边缘计算网络的分布式特性相比，SDN是一种集中式的方法，直接将SDN应用于边缘计算网络是一项具有挑战性的工作。[273]研究了一种支持SDN的智能城市边缘计算网络。为了提高该原型网络的服务性能，在其控制平面中部署了DQL，以协调网络、缓存和计算资源。</p>
<p>​ 边缘计算可以为物联网系统提供更多计算密集型和延迟敏感型服务，但同时也对存储、计算和通信资源的高效管理和协同提出了挑战。为了最小化平均端到端服务延迟，基于策略梯度的DRL结合AC体系结构可以处理边缘节点的分配、关于是否存储请求内容的决定、执行计算任务的边缘节点的选择以及计算资源的分配[262]。</p>
<p>​ IoVs是物联网的特例，专注于联网车辆。与在[262]中考虑的集成网络、缓存和计算类似，具有更健壮性能的DoubleDueling DQL(即结合双DQL和Dueling DQL)可用于协调可用资源以提高未来IOVS的性能[110]。此外，考虑到车辆在IOVS中的机动性，硬服务截止日期的限制很容易被打破，而且由于高度的复杂性，这一挑战往往被忽视或解决得不够充分。为了应对移动性挑战，在[112]中，首先将车辆的移动性建模为离散随机跳跃，并将时间维划分为历元，每个历元包含若干个时隙。然后，针对时隙的粒度，设计了一个小时间尺度的DQL模型，在精心设计的即时奖励函数中考虑了车辆机动性的影响。最后，针对每个时段，提出了一个大时间尺度的DQL模型。通过使用这种多时间尺度的DRL，既解决了移动性的直接影响，又解决了资源分配优化中无法承受的巨大行动空间的问题。</p></li>
</ol>
<h1 id="九-吸取的教训和开放的挑战">九 吸取的教训和开放的挑战</h1>
<p>为了识别存在的挑战和避免潜在的误导，我们简要介绍了“边缘上的DL应用”的潜在场景，并分别讨论了与我们关注的四种使能技术相关的公开问题，即“边缘中的DL推理”、“用于DL的边缘计算”、“在边缘的DL训练”和“用于优化边缘的DL”。</p>
<h2 id="a.更有前途的应用">A.更有前途的应用</h2>
<p>如果DL和EDGE能够很好地结合在一起，它们可以为创新应用的开发提供巨大的潜力。要为运营商、供应商和第三方提供新的商机和收入来源，还有许多领域需要探索。</p>
<p>例如，随着越来越多的DL技术被普遍嵌入到这些新兴应用中，引入的处理延迟和额外的计算成本使得云游戏架构难以满足延迟要求。靠近用户的边缘计算架构可以与云结合，形成混合游戏架构。此外，智能驾驶涉及语音识别、图像识别、智能决策等。智能驾驶中的各种DL应用，如碰撞警告，都需要边缘计算平台保证毫秒级的交互延迟。此外，边缘感知更有利于分析车辆周围的交通环境，从而提高驾驶安全性。</p>
<h2 id="b.用于推理的通用dl模型">B.用于推理的通用DL模型</h2>
<p>在边缘设备中部署DL时，需要通过模型优化来加速DL推理。在这一部分中，讨论了“边缘DL推理”在模型压缩、模型分割和用于优化DL模型的EEoI方面的经验教训和未来发展方向。</p>
<ol type="1">
<li><strong>不明确的性能指标：</strong>对于特定任务的Edge DL服务，通常有一系列候选DL模型可以完成该任务。然而，服务提供商很难为每项服务选择正确的DL模型。由于边缘计算网络的不确定特性(变化的无线信道质量、不可预测的并发服务请求等)，常用的标准性能指标(如top-k精度[138]或平均平均精度[164])不能反映边缘DL模型推理的运行时性能。对于Edge DL服务，除了模型准确性，推断延迟、资源消耗和服务收入也是关键指标。因此，我们需要识别Edge DL的关键性能指标，定量分析影响它们的因素，并探索这些指标之间的权衡，以帮助提高Edge DL的部署效率。</li>
<li><strong>EEoI的推广：</strong>目前，EEoI可以应用于DL[160]中的分类问题，但对于更广泛的DL应用还没有通用的解决方案。此外，为了构建智能边缘并支持边缘智能，不仅应该探索DL，而且应该探索将EEoI应用于DRL的可能性，因为将DRL应用于边缘的实时资源管理，如在第八节中所讨论的，需要严格的响应速度。</li>
<li><strong>混合模型修改：</strong>应该考虑与模型优化、模型分段和EEoI相关的协调问题。这些定制的DL模型通常是独立使用的，以实现“端-边-云”协作。可能需要在末端和边缘进行模型量化和修剪等模型优化，但由于有足够的计算资源，云不需要冒模型精度的风险来使用这些优化。因此，如何设计一种混合精度方案，即如何将边缘的简化DL模型和云中的原始DL模型有效地结合起来是非常重要的。</li>
<li><strong>训练和推理之间的协调：</strong>修剪、量化和将EEoI引入训练的原始DL模型需要重新训练，以使它们获得所需的推理性能。一般来说，定制模型可以在云中进行离线培训。然而，边缘计算的优势在于它的响应速度，而且可能会因为延迟的DL训练而被抵消。而且，由于边缘存在大量异构设备，网络环境动态变化，对DL型号的定制需求并不单调。那么，这种持续的模型训练要求是否合理，会不会影响模型推理的时效性？如何设计一种机制来避免这些副作用？</li>
</ol>
<h2 id="c.dl的完整边缘架构">C.DL的完整边缘架构</h2>
<p>EDGE智能和智能EDGE需要一个完整的系统框架，涵盖数据采集、业务部署和任务处理。在这一部分中，我们将讨论“面向DL的边缘计算”在构建完整的DL边缘计算框架方面所面临的挑战。</p>
<ol type="1">
<li><p><strong>EDGE用于数据处理：</strong>无论是在EDGE上广泛部署的DL服务，还是优化EDGE的DL算法，都离不开数据采集。EDGE架构应该能够高效地获取和处理由EDGE设备感知或收集的原始数据，然后将其提供给DL模型。</p>
<p>​ 自适应地在边缘获取数据，然后将其传输到云(如[7]中所做的)是减轻边缘设备工作量和减少潜在资源开销的自然方式。此外，更好的是进一步压缩数据，这样可以缓解网络的带宽压力，同时可以降低传输时延，提供更好的QoS。大多数已有的工作只关注视觉应用[102]。然而，各种基于DL的服务的异构数据结构和特性还没有得到很好的解决。因此，为各种DL服务开发一种异构、并行和协作的边缘数据处理体系结构将是有帮助的。</p></li>
<li><p><strong>边缘DL服务的微服务：</strong>边缘和云服务最近开始经历从单一实体到数百个松散耦合微服务的图表的重大转变[274]。执行DL计算可能需要一系列软件依赖，这需要一种解决方案来隔离共享资源上的不同DL服务。目前，部署在边缘用于托管DL服务的微服务框架还处于初级阶段[275]，原因是几个关键挑战：1)灵活地处理DL部署和管理；2)实现微服务的实时迁移，以减少迁移时间和DL服务由于用户移动性而导致的不可用；3)协调云和分布式边缘基础设施之间的资源，以获得更好的性能，如第VI-B3节所示。</p></li>
<li><p><strong>DL激励和值得信赖的卸载机制：</strong>资源有限的终端设备上的繁重DL计算可以卸载到附近的边缘节点(第VI-B节)。但是，仍然存在几个问题，1)需要建立激励机制来激励边缘节点接管DL计算；2)需要保证安全性，以避免匿名边缘节点带来的风险[276]。</p>
<p>​ 区块链作为跨参与设备存储交易记录的去中心化公共数据库，可以避免记录被篡改的风险[277]。通过利用这些特性，可以潜在地解决与计算卸载相关的激励和信任问题。具体地说，所有终端设备和边缘节点都要先向区块链交押金才能参与。终端设备请求边缘节点帮助进行DL计算，同时向区块链发送带赏金的“请求”事务。一旦边缘节点完成计算，它就会将结果返回给终端设备，并向区块链发送“完整”事务。一段时间后，其他参与的边缘节点也执行卸载任务，并验证先前记录的结果。最后，作为激励，首先记录的边缘节点赢得比赛并获得奖励[278]。然而，这种关于区块链边缘的想法还处于初级阶段。现有的区块链如Etherum[279]不支持执行复杂的DL计算，这就提出了调整区块链结构和协议以打破这一限制的挑战。</p></li>
<li><p><strong>与优化边缘的DL融合：</strong>未来边缘计算网络中的终端设备、边缘节点、基站都将运行各种DL模型，并部署相应的服务。为了充分利用分散的边缘计算资源，并与现有的云计算基础设施建立连接，将计算密集型的DL模型划分为子任务，并在边缘设备之间有效地卸载这些任务以进行协作是至关重要的。由于Edge DL的部署环境通常是高度动态的，边缘计算框架需要良好的在线资源编排和参数配置来支持大量的DL服务。异构计算资源、通信和缓存资源的实时联合优化以及高维系统参数配置是关键。我们在第八节中介绍了使用DL技术优化边缘计算框架(网络)的各种理论方法，但目前还没有相关的工作深入研究在实际的边缘计算网络或试验台中部署和使用这些DL技术进行长期在线资源编排的性能分析。我们认为，《用于DL的边缘计算》应该继续关注如何将《用于优化边缘的DL》融入到边缘计算框架中来实现上述愿景。</p></li>
</ol>
<h2 id="d.edge的实践训练原则">D.EDGE的实践训练原则</h2>
<p>与EDGE中的DL推理相比，EDGE中的DL训练目前主要受限于EDGE设备的弱性能，以及大多数Edge DL框架或库仍然不支持训练。目前，大多数研究都是在理论层面上进行的，即在边缘模拟DL训练过程。在这一部分中，我们指出了在“边缘数字图书馆培训”中学到的教训和面临的挑战。</p>
<ol type="1">
<li><p>数据并行性与模型并行性：DL模型需要大量的计算和内存。当它们变得更深或更大时，用单个设备获取它们的推理结果或对它们进行很好的训练是不可行的。因此，根据数据并行性、模型并行性或它们的组合，大型DL模型在数千个CPU或GPU核心上以分布式方式进行训练(第III-C节)。但是，与在云中通过总线或交换机连接的CPU或GPU进行并行培训不同，在分布式边缘设备上执行模型培训应进一步考虑无线环境、设备配置、隐私等。</p>
<p>​ 目前FL只将整个DL模型复制到每个参与的边缘设备，即数据并行的方式。因此，考虑到边缘设备有限的计算能力(至少目前)，将一个大规模的DL模型进行分区，并将这些片段分配到不同的边缘设备进行训练，可能是一个更可行和实用的解决方案。当然，这并不意味着放弃FL的原生数据并行性，而是提出了混合数据并行性和模型并行性的挑战，特别是对于边缘训练DL模型，如图21所示。</p>
<figure>
<img src= "/img/loading.gif" data-lazy-src="/2021/04/11/Paper/%E8%BE%B9%E7%BC%98%E8%AE%A1%E7%AE%97%E4%B8%8E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9A%84%E8%9E%8D%E5%90%88/image-20210407135730398.png" alt="image-20210407135730398"><figcaption aria-hidden="true">image-20210407135730398</figcaption>
</figure></li>
<li><p><strong>训练数据是从哪里来的？：</strong>目前，边缘的DL训练框架大多是针对有监督的学习任务，并用完整的数据集测试它们的性能。然而，在实际场景中，我们不能假设边缘计算网络中的所有数据都有标签，并且都有正确的保证。对于DRL这样的无监督学习任务，我们当然不需要过多关注训练数据的产生。例如，DRL所需的训练数据由观察到的状态向量和通过与环境交互获得的奖励组成。这些训练数据可以在系统运行时自动生成。但是对于范围更广的有监督学习任务，边缘节点和设备如何找到准确的训练数据进行模型训练呢？香草FL的应用是使用RNN进行下一词预测[199]，其中训练数据可以与用户的日常输入一起获得。尽管如此，对于与视频分析相关的大量Edge DL服务，其培训数据从何而来。如果所有训练数据都是人工标注上传到云数据中心，再通过云端分发到边缘设备，显然违背了FL的初衷。一种可能的解决方案是使边缘设备能够通过相互学习“标签数据”来构建它们的标签数据。我们认为，未来应首先明确训练数据的产生和边缘DL模型训练的应用场景，并探讨边缘DL模型训练的必要性和可行性。</p></li>
<li><p><strong>边缘异步FL：</strong>现有FL方法[198]、[199]侧重于同步训练，只能并行处理数百台设备。然而，这种同步更新模式潜在地不能很好地扩展，并且鉴于FL的两个关键属性，该模式是低效和不灵活的，具体地说，1)训练任务不频繁，因为边缘设备通常具有较弱的计算能力和有限的电池续航能力，因此无法承担密集的训练任务；2)与云中典型的分布式训练相比，边缘设备之间的通信有限且不确定。</p>
<p>​ 因此，每当全局模型更新时，服务器被限制为从可用边缘设备的子集中选择以触发训练任务。此外，由于计算能力和电池续航时间有限，不同设备的任务调度各不相同，因此很难在每个时代结束时同步选定的设备。某些设备在应该同步时可能不再可用，因此服务器必须确定超时阈值才能丢弃落后设备。如果幸存设备的数量太少，服务器必须丢弃整个时段，包括所有接收到的更新。外语中的这些瓶颈可能可以通过异步训练机制[280]-[282]来解决。在每个资源受限的培训期间充分选择客户也可能有所帮助。通过为客户端设置下载、更新和上传DL模型的特定期限，中央服务器可以确定哪些客户端执行本地训练，使得它可以在每个周期中聚集尽可能多的客户端更新，从而允许服务器加速DL模型中的性能改进[283]。</p></li>
<li><p><strong>基于迁移学习的训练：</strong>由于资源限制，在手机等边缘设备上培训和部署计算密集型DL模型具有挑战性。为了便于在这种资源受限的边缘设备上学习，可以利用TL。例如，为了减少训练数据量并加快训练过程，可以采用使用未标记数据在边缘设备之间传递知识[284]。通过在边缘设备跨不同传感模式的学习中使用跨模式迁移，所需的标记数据和训练过程可以分别大大减少和加快。</p>
<p>​ 此外，KD作为TL的一种方法，也有几个优点[136]：1)利用训练有素的大型DL模型(教师)的信息，帮助轻量级DL模型(学生)更快地收敛；2)提高学生的准确性；3)帮助学生变得更通用，而不是被某一组数据过度拟合。虽然文献[136]、[284]的研究结果显示出一定的发展前景，但如何将基于目标词的训练方法推广到具有不同类型感知数据的数字图书馆应用中还需要进一步的研究。</p></li>
</ol>
<h2 id="e.智能边缘的部署和改进">E.智能边缘的部署和改进</h2>
<p>已经有很多尝试使用DL来优化和调度边缘计算网络中的资源。在这一点上，存在许多可以应用DL的潜在领域，包括在线内容流[285]、路由和流量控制[286]、[287]等。然而，由于DL解决方案不完全依赖于网络和设备的准确建模，所以找到可以应用DL的场景不是最重要的考虑因素。此外，如果应用DL优化实时边缘计算网络，DL模型或DRL算法的训练和推理可能会带来一定的副作用，如训练数据传输所消耗的额外带宽和DL推理的延迟。</p>
<p>已经有很多尝试使用DL来优化和调度边缘计算网络中的资源。在这一点上，存在许多可以应用DL的潜在领域，包括在线内容流[285]、路由和流量控制[286]、[287]等。然而，由于DL解决方案不完全依赖于网络和设备的准确建模，所以找到可以应用DL的场景不是最重要的考虑因素。此外，如果应用DL优化实时边缘计算网络，DL模型或DRL算法的训练和推理可能会带来一定的副作用，如训练数据传输所消耗的额外带宽和DL推理的延迟。</p>
<figure>
<img src= "/img/loading.gif" data-lazy-src="/2021/04/11/Paper/%E8%BE%B9%E7%BC%98%E8%AE%A1%E7%AE%97%E4%B8%8E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9A%84%E8%9E%8D%E5%90%88/image-20210407140201358.png" alt="image-20210407140201358"><figcaption aria-hidden="true">image-20210407140201358</figcaption>
</figure>
<ul>
<li>考虑到DL和DRL的资源开销和实时管理边缘计算网络的需求，DL和DRL应该部署在哪里？</li>
<li>在使用DL确定缓存策略或优化任务分流时，DL本身带来的带宽消耗和处理延迟会抵消DL的优势吗？</li>
<li>如何探索和改进第六节中的边缘计算体系结构，以支持“用于优化边缘的DL”？</li>
<li>第五节介绍的定制DL模型的想法是否有助于实际部署？</li>
<li>如何修改第七节中的培训原则以提高DL培训的绩效，以满足边缘管理的时效性？</li>
</ul>
<p>此外，最先进的DL或DRL的能力，如多Agent深度强化学习[288]-[290]，图神经网络(GNNs)[291]，[292]，也可以被用来促进这一过程。例如，终端设备、边缘节点和云可以被视为单独的代理。通过这种方式，每个智能体根据其局部的不完全观察来训练自己的策略，所有参与的智能体共同优化边缘计算网络。此外，跨越终端、边缘和云的边缘计算网络的结构实际上是一个巨大的图，其中包含大量的潜在结构信息，例如设备之间的连接和带宽。为了更好地理解边缘计算网络，GNNs专注于从图结构中提取特征，而不是从二维网格和一维序列中提取特征，这可能是一种很有前途的方法。</p>
<h1 id="十结论">十、结论</h1>
<p>DL作为人工智能的一项关键技术，与边缘计算有望实现互惠互利。本次调研全面介绍和讨论了边缘智能和智能边缘的各种适用场景和基础使能技术。综上所述，将DL从云扩展到网络边缘的关键问题是：在网络、通信、计算能力和能耗的多重约束下，如何设计和开发边缘计算体系结构，以实现DL训练和推理的最佳性能。随着边缘计算能力的增强，边缘智能将变得普遍，智能边缘将对提升边缘智能的性能起到重要的支撑作用。我们希望本次调查将增加关于DL/Edge集成的讨论和研究力度，从而推动未来的通信应用和服务。</p>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="mailto:undefined">刘 可</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="https://1iuke.github.io/2021/04/11/Paper/%E8%BE%B9%E7%BC%98%E8%AE%A1%E7%AE%97%E4%B8%8E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9A%84%E8%9E%8D%E5%90%88/">https://1iuke.github.io/2021/04/11/Paper/%E8%BE%B9%E7%BC%98%E8%AE%A1%E7%AE%97%E4%B8%8E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9A%84%E8%9E%8D%E5%90%88/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="https://1iuke.github.io" target="_blank">Mr.Liu</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"></div><div class="post_share"><div class="social-share" data-image="/img/002.jpg" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/social-share.js/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/social-share.js/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/2021/04/11/C++/C-%E8%BE%93%E5%85%A5%E8%BE%93%E5%87%BA/"><img class="prev-cover" data-lazy-src="/img/003.jpg" onerror="onerror=null;src='/img/404.jpg'" alt="cover of previous post"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">C++输入输出</div></div></a></div><div class="next-post pull-right"><a href="/2021/04/08/Paper/%E8%AE%AD%E7%BB%83%E8%BF%98%E6%98%AF%E4%B8%8D%E8%AE%AD%E7%BB%83%EF%BC%9F%E5%9F%BA%E4%BA%8ESSVEP%E7%9A%84%E8%84%91%E6%9C%BA%E6%8E%A5%E5%8F%A3%E7%89%B9%E5%BE%81%E6%8F%90%E5%8F%96%E6%96%B9%E6%B3%95%E8%AE%AD%E7%BB%83%E7%A0%94%E7%A9%B6%E7%BB%BC%E8%BF%B0/"><img class="next-cover" data-lazy-src="/img/003.jpg" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">To train or not to train? A survey on training of feature extraction methods for SSVEP-based BCIs</div></div></a></div></nav><hr/><div id="post-comment"><div class="comment-head"><div class="comment-headline"><i class="fas fa-comments fa-fw"></i><span> 评论</span></div><div id="comment-switch"><span class="first-comment">Valine</span><span class="switch-btn"></span><span class="second-comment">Gitalk</span></div></div><div class="comment-wrap"><div><div class="vcomment" id="vcomment"></div></div><div><div id="gitalk-container"></div></div></div></div></div><div class="aside-content" id="aside-content"><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#%E4%B8%80-%E5%AF%BC%E8%A8%80"><span class="toc-text">一 导言</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E4%BA%8C-%E8%BE%B9%E7%BC%98%E8%AE%A1%E7%AE%97%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86"><span class="toc-text">二 边缘计算基础知识</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#a.%E8%BE%B9%E7%BC%98%E8%AE%A1%E7%AE%97%E7%9A%84%E8%8C%83%E4%BE%8B"><span class="toc-text">A.边缘计算的范例</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#b.%E7%94%A8%E4%BA%8E%E8%BE%B9%E7%BC%98%E8%AE%A1%E7%AE%97%E7%9A%84%E7%A1%AC%E4%BB%B6"><span class="toc-text">B.用于边缘计算的硬件</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#c.%E8%99%9A%E6%8B%9F%E5%8C%96%E8%BE%B9%E7%BC%98"><span class="toc-text">C.虚拟化边缘</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E4%B8%89-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9A%84%E5%9F%BA%E7%A1%80"><span class="toc-text">三 深度学习的基础</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#a.%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%AD%E7%9A%84%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C"><span class="toc-text">A.深度学习中的神经网络</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#b.%E6%B7%B1%E5%BA%A6%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0drl"><span class="toc-text">B.深度强化学习(DRL)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#c.%E5%88%86%E5%B8%83%E5%BC%8Fdl%E8%AE%AD%E7%BB%83"><span class="toc-text">C.分布式DL训练</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#d.%E8%BE%B9%E7%BC%98%E7%9A%84%E6%BD%9C%E5%9C%A8dl%E5%BA%93"><span class="toc-text">D.边缘的潜在DL库</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%9B%9B-%E8%BE%B9%E7%BC%98%E7%9A%84%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%BA%94%E7%94%A8"><span class="toc-text">四 边缘的深度学习应用</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#a.%E5%AE%9E%E6%97%B6%E8%A7%86%E9%A2%91%E5%88%86%E6%9E%90"><span class="toc-text">A.实时视频分析</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#b.%E8%87%AA%E4%B8%BB%E8%BD%A6%E8%81%94%E7%BD%91iovs"><span class="toc-text">B.自主车联网(IoVs)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#c.%E6%99%BA%E8%83%BD%E5%88%B6%E9%80%A0"><span class="toc-text">C.智能制造</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#d.%E6%99%BA%E8%83%BD%E5%AE%B6%E5%B1%85%E5%92%8C%E5%9F%8E%E5%B8%82"><span class="toc-text">D.智能家居和城市</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E4%BA%94-edge%E4%B8%AD%E7%9A%84%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%8E%A8%E7%90%86"><span class="toc-text">五 EDGE中的深度学习推理</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#a.%E8%BE%B9%E7%95%8C%E4%B8%8Adl%E6%A8%A1%E5%9E%8B%E7%9A%84%E4%BC%98%E5%8C%96"><span class="toc-text">A.边界上DL模型的优化</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#b.dl%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%88%86%E6%AE%B5"><span class="toc-text">B.DL模型的分段</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#c.%E6%8F%90%E5%89%8D%E9%80%80%E5%87%BA%E6%8E%A8%E7%90%86eeoi"><span class="toc-text">C.提前退出推理(EEoI)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#d.%E5%85%B1%E4%BA%ABdl%E8%AE%A1%E7%AE%97"><span class="toc-text">D.共享DL计算</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%85%AD-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9A%84%E8%BE%B9%E7%BC%98%E8%AE%A1%E7%AE%97"><span class="toc-text">六 深度学习的边缘计算</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#a.%E7%94%A8%E4%BA%8Edl%E7%9A%84%E8%BE%B9%E7%BC%98%E7%A1%AC%E4%BB%B6"><span class="toc-text">A.用于DL的边缘硬件</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#b.edge-dl%E7%9A%84%E9%80%9A%E4%BF%A1%E5%92%8C%E8%AE%A1%E7%AE%97%E6%96%B9%E5%BC%8F"><span class="toc-text">B.Edge DL的通信和计算方式</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#c.%E4%B8%BAdl%E5%AE%9A%E5%88%B6edge%E6%A1%86%E6%9E%B6"><span class="toc-text">C.为DL定制Edge框架</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#d.edge-dl%E7%9A%84%E6%80%A7%E8%83%BD%E8%AF%84%E4%BC%B0"><span class="toc-text">D.Edge DL的性能评估</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E4%B8%83-%E8%BE%B9%E7%BC%98%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%AE%AD%E7%BB%83"><span class="toc-text">七 边缘深度学习训练</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#a.edge%E7%9A%84%E5%88%86%E5%B8%83%E5%BC%8F%E8%AE%AD%E7%BB%83"><span class="toc-text">A.Edge的分布式训练</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#b.%E8%BE%B9%E7%BC%98%E7%9A%84%E8%81%94%E5%90%88%E5%AD%A6%E4%B9%A0"><span class="toc-text">B.边缘的联合学习</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#c.%E9%80%9A%E4%BF%A1%E6%9C%89%E6%95%88%E7%9A%84fl"><span class="toc-text">C.通信有效的FL</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#d.%E8%B5%84%E6%BA%90%E4%BC%98%E5%8C%96fl"><span class="toc-text">D.资源优化FL</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#e.%E5%A2%9E%E5%BC%BA%E5%AE%89%E5%85%A8%E6%80%A7%E7%9A%84fl"><span class="toc-text">E.增强安全性的FL</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%85%AB-%E4%BC%98%E5%8C%96edge%E7%9A%84%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0"><span class="toc-text">八 优化EDGE的深度学习</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#a.%E8%87%AA%E9%80%82%E5%BA%94%E8%BE%B9%E7%BC%98%E7%BC%93%E5%AD%98%E7%9A%84dl"><span class="toc-text">A.自适应边缘缓存的DL</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#b.%E7%94%A8%E4%BA%8E%E4%BC%98%E5%8C%96%E8%BE%B9%E7%BC%98%E4%BB%BB%E5%8A%A1%E5%8D%B8%E8%BD%BD%E7%9A%84dl"><span class="toc-text">B.用于优化边缘任务卸载的DL</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#c.%E7%94%A8%E4%BA%8E%E8%BE%B9%E7%BC%98%E7%AE%A1%E7%90%86%E5%92%8C%E7%BB%B4%E6%8A%A4%E7%9A%84dl"><span class="toc-text">C.用于边缘管理和维护的DL</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E4%B9%9D-%E5%90%B8%E5%8F%96%E7%9A%84%E6%95%99%E8%AE%AD%E5%92%8C%E5%BC%80%E6%94%BE%E7%9A%84%E6%8C%91%E6%88%98"><span class="toc-text">九 吸取的教训和开放的挑战</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#a.%E6%9B%B4%E6%9C%89%E5%89%8D%E9%80%94%E7%9A%84%E5%BA%94%E7%94%A8"><span class="toc-text">A.更有前途的应用</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#b.%E7%94%A8%E4%BA%8E%E6%8E%A8%E7%90%86%E7%9A%84%E9%80%9A%E7%94%A8dl%E6%A8%A1%E5%9E%8B"><span class="toc-text">B.用于推理的通用DL模型</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#c.dl%E7%9A%84%E5%AE%8C%E6%95%B4%E8%BE%B9%E7%BC%98%E6%9E%B6%E6%9E%84"><span class="toc-text">C.DL的完整边缘架构</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#d.edge%E7%9A%84%E5%AE%9E%E8%B7%B5%E8%AE%AD%E7%BB%83%E5%8E%9F%E5%88%99"><span class="toc-text">D.EDGE的实践训练原则</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#e.%E6%99%BA%E8%83%BD%E8%BE%B9%E7%BC%98%E7%9A%84%E9%83%A8%E7%BD%B2%E5%92%8C%E6%94%B9%E8%BF%9B"><span class="toc-text">E.智能边缘的部署和改进</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%8D%81%E7%BB%93%E8%AE%BA"><span class="toc-text">十、结论</span></a></li></ol></div></div></div></div></main><footer id="footer" style="background-image: url('/img/002.jpg')"><div id="footer-wrap"><div class="copyright">&copy;2020 - 2021 By 刘 可</div><div class="footer_custom_text">Hi, welcome to my <a href="https://1iuke.github.io/">blog</a>!</div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="font-plus" type="button" title="放大字体"><i class="fas fa-plus"></i></button><button id="font-minus" type="button" title="缩小字体"><i class="fas fa-minus"></i></button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><a id="to_comment" href="#post-comment" title="直达评论"><i class="fas fa-comments"></i></a><button id="go-up" type="button" title="回到顶部"><i class="fas fa-arrow-up"></i></button></div></div><div id="local-search"><div class="search-dialog"><div class="search-dialog__title" id="local-search-title">本地搜索</div><div id="local-input-panel"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"/></div></div></div><hr/><div id="local-search-results"></div><span class="search-close-button"><i class="fas fa-times"></i></span></div><div id="search-mask"></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/instant.page/instantpage.min.js" type="module"></script><script src="https://cdn.jsdelivr.net/npm/vanilla-lazyload/dist/lazyload.iife.min.js"></script><script>function panguFn () {
  if (typeof pangu === 'object') pangu.autoSpacingPage()
  else {
    getScript('https://cdn.jsdelivr.net/npm/pangu/dist/browser/pangu.min.js')
      .then(() => {
        pangu.autoSpacingPage()
      })
  }
}

function panguInit () {
  if (false){
    GLOBAL_CONFIG_SITE.isPost && panguFn()
  } else {
    panguFn()
  }
}

document.addEventListener('DOMContentLoaded', panguInit)</script><script src="/js/search/local-search.js"></script><script>var preloader = {
  endLoading: () => {
    document.body.style.overflow = 'auto';
    document.getElementById('loading-box').classList.add("loaded")
  },
  initLoading: () => {
    document.body.style.overflow = '';
    document.getElementById('loading-box').classList.remove("loaded")

  }
}
window.addEventListener('load',preloader.endLoading())</script><div class="js-pjax"><script>if (!window.MathJax) {
  window.MathJax = {
    loader: {
      source: {
        '[tex]/amsCd': '[tex]/amscd'
      }
    },
    tex: {
      inlineMath: [ ['$','$'], ["\\(","\\)"]],
      tags: 'ams'
    },
    options: {
      renderActions: {
        findScript: [10, doc => {
          for (const node of document.querySelectorAll('script[type^="math/tex"]')) {
            const display = !!node.type.match(/; *mode=display/)
            const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display)
            const text = document.createTextNode('')
            node.parentNode.replaceChild(text, node)
            math.start = {node: text, delim: '', n: 0}
            math.end = {node: text, delim: '', n: 0}
            doc.math.push(math)
          }
        }, ''],
        addClass: [200,() => {
          document.querySelectorAll('mjx-container:not([display=\'true\']').forEach( node => {
            const target = node.parentNode
            if (!target.classList.contains('has-jax')) {
              target.classList.add('mathjax-overflow')
            }
          })
        }, '', false]
      }
    }
  }
  
  const script = document.createElement('script')
  script.src = 'https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js'
  script.id = 'MathJax-script'
  script.async = true
  document.head.appendChild(script)
} else {
  MathJax.startup.document.state(0)
  MathJax.texReset()
  MathJax.typeset()
}</script><script>if (document.getElementsByClassName('mermaid').length) {
  if (window.mermaidJsLoad) mermaid.init()
  else {
    getScript('https://cdn.jsdelivr.net/npm/mermaid/dist/mermaid.min.js').then(() => {
      window.mermaidJsLoad = true
      mermaid.initialize({
        theme: 'default',
      })
      false && mermaid.init()
    })
  }
}</script><script>function loadValine () {
  function initValine () {
    const valine = new Valine(Object.assign({
      el: '#vcomment',
      appId: 'vSfujIpDJKrOca7sGb77ez1y-gzGzoHsz',
      appKey: 'hUDhnXVije6ovDERpjufGzhX',
      placeholder: 'Please leave your footprints',
      avatar: 'monsterid',
      meta: 'nick,mail,link'.split(','),
      pageSize: '10',
      lang: 'zh-CN',
      recordIP: false,
      serverURLs: '',
      emojiCDN: '',
      emojiMaps: "",
      enableQQ: true,
      path: window.location.pathname,
      requiredFields: ["nick,mail"],
      visitor: false
    }, null))
  }

  if (typeof Valine === 'function') initValine() 
  else getScript('https://cdn.jsdelivr.net/npm/valine/dist/Valine.min.js').then(initValine)
}

if ('Valine' === 'Valine' || !false) {
  if (false) btf.loadComment(document.getElementById('vcomment'),loadValine)
  else setTimeout(loadValine, 0)
} else {
  function loadOtherComment () {
    loadValine()
  }
}</script><script>function addGitalkSource () {
  const ele = document.createElement('link')
  ele.rel = 'stylesheet'
  ele.href= 'https://cdn.jsdelivr.net/npm/gitalk/dist/gitalk.min.css'
  document.getElementsByTagName('head')[0].appendChild(ele)
}

function loadGitalk () {
  function initGitalk () {
    var gitalk = new Gitalk(Object.assign({
      clientID: '5da5e921d00d1718f27c',
      clientSecret: 'b329b24239d9a62af13002241e771e8493e2c497',
      repo: '1iuke.github.io',
      owner: '1iuke',
      admin: ['1iuke'],
      id: 'd2482d3046d59f30640ac9caafe0cc82',
      language: 'zh-CN',
      perPage: 10,
      distractionFreeMode: false,
      pagerDirection: 'last',
      createIssueManually: false,
      updateCountCallback: commentCount
    },null))

    gitalk.render('gitalk-container')
  }

  if (typeof Gitalk === 'function') initGitalk()
  else {
    addGitalkSource()
    getScript('https://cdn.jsdelivr.net/npm/gitalk@latest/dist/gitalk.min.js').then(initGitalk)
  }
}

function commentCount(n){
  let isCommentCount = document.querySelector('#post-meta .gitalk-comment-count')
  if (isCommentCount) {
    isCommentCount.innerHTML= n
  }
}

if ('Valine' === 'Gitalk' || !false) {
  if (false) btf.loadComment(document.getElementById('gitalk-container'), loadGitalk)
  else loadGitalk()
} else {
  function loadOtherComment () {
    loadGitalk()
  }
}</script></div><script defer="defer" id="fluttering_ribbon" mobile="false" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/dist/canvas-fluttering-ribbon.min.js"></script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></body></html>